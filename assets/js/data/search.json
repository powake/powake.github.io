[ { "title": "Output", "url": "/posts/output/", "categories": "", "tags": "", "date": "2022-09-27 00:00:00 +0700", "snippet": "from google.colab import drivedrive.mount('/content/drive')Giá»›i Thiá»‡u NgÃ´n Ngá»¯ PythonGiá»›i thiá»‡uCÃ i Ä‘áº·t Python trÃªn Windows, Linux vÃ  MacLinuxWindowsMacChá»n IDE vÃ  chÆ°Æ¡ng trÃ¬nh Python Ä‘áº§u tiÃªnChá»n IDEChÆ°Æ¡ng trÃ¬nh Python Ä‘áº§u tiÃªnPython CÆ¡ Báº£nCÃ¡c kiá»ƒu dá»¯ liá»‡u PythonPython numbersPython StringsPython Booleanspython containsListsTuplesSetsDictionariesArrayCÃ¡c loáº¡i biáº¿n trong PythonBiá»ƒu thá»©c Ä‘iá»u kiá»‡nVÃ²ng láº·pVÃ²ng láº·p forVÃ²ng láº·p whileKá»¹ thuáº­t vÃ²ng láº·pHÃ mHÃ m cÆ¡ báº£nHÃ m vÃ´ danh (Lambda)Module vÃ  Pakage trong PythonClass vÃ  Object trong PythonPython NÃ¢ng caoLÃ m viá»‡c vá»›i filePython cÅ©ng há»— trá»£ xá»­ lÃ½ tá»‡p vÃ  cho phÃ©p ngÆ°á»i dÃ¹ng xá»­ lÃ½ tá»‡p, tá»©c lÃ  Ä‘á»c vÃ  ghitá»‡p, cÃ¹ng vá»›i nhiá»u tÃ¹y chá»n xá»­ lÃ½ tá»‡p khÃ¡c, hoáº¡t Ä‘á»™ng trÃªn tá»‡p. KhÃ¡i niá»‡m xá»­ lÃ½tá»‡p Ä‘Ã£ tráº£i dÃ i trÃªn nhiá»u ngÃ´n ngá»¯ khÃ¡c, nhÆ°ng viá»‡c triá»ƒn khai phá»©c táº¡p hoáº·cdÃ i dÃ²ng, nhÆ°ng giá»‘ng nhÆ° cÃ¡c khÃ¡i niá»‡m khÃ¡c cá»§a Python, khÃ¡i niá»‡m nÃ y á»Ÿ Ä‘Ã¢ycÅ©ng dá»… dÃ ng vÃ  ngáº¯n gá»n. Python xá»­ lÃ½ cÃ¡c tá»‡p khÃ¡c nhau dÆ°á»›i dáº¡ng vÄƒn báº£n hoáº·cnhá»‹ phÃ¢n vÃ  Ä‘iá»u nÃ y ráº¥t quan trá»ng. Má»—i dÃ²ng mÃ£ bao gá»“m má»™t chuá»—i cÃ¡c kÃ½ tá»± vÃ chÃºng táº¡o thÃ nh má»™t tá»‡p vÄƒn báº£n.Má»Ÿ File trong Pythonf = open(filename, mode)VÃ­ dá»¥:file = open('/content/drive/MyDrive/Python3-Tutorial/Code/Python/files/test.txt', 'r')Äá»c File trong Pythonfile.read ()Äá»ƒ Ä‘á»c má»™t file ta cáº§n má»Ÿ file báº±ng cÃº phÃ¡p Ä‘á»ƒ Ä‘á»c, sá»­ dá»¥ng mode read â€˜râ€™.file = open('/content/drive/MyDrive/Python3-Tutorial/Code/Python/files/test.txt', 'r')file.read ()Ghi File trong Pythonf = write(filename, mode)Äá»ƒ ghi má»™t file ta cáº§n má»Ÿ file báº±ng cÃº phÃ¡p Ä‘á»ƒ ghi, sá»­ dá»¥ng mode write â€˜wâ€™,append â€˜aâ€™ hoáº·c mode táº¡o Ä‘á»™c quyá»n â€˜xâ€™Báº¡n cáº§n cáº©n tháº­n vá»›i cháº¿ Ä‘á»™ â€˜wâ€™, vÃ¬ nÃ³ ghi Ä‘Ã¨ lÃªn ná»™i dung náº¿u file Ä‘Ã£ tá»“n táº¡i,cÃ¡c dá»¯ liá»‡u trÆ°á»›c Ä‘Ã³ sáº½ bá»‹ xÃ³a.Náº¿u báº¡n ghi vÃ o file dáº¡ng nhá»‹ phÃ¢n cÃ¡c chuá»—i vÄƒn báº£n hoáº·c chuá»—i dáº¡ng byte thÃ¬káº¿t quáº£ tráº£ vá» sáº½ lÃ  sá»‘ kÃ­ tá»± Ä‘Æ°á»£c ghi vÃ o file.file = open('/content/drive/MyDrive/Python3-Tutorial/Code/Python/files/test.txt', 'w')file.write(\"toi la lap trinh vien\")file.close()Má»™t sá»‘ phÆ°Æ¡ng thá»©c khÃ¡cIterator, Generator, Closure, Decorator, Regex vÃ  @property trong pythonIteratorIterator lÃ  cÃ¡c Ä‘á»‘i tÆ°á»£ng cho phÃ©p ta láº¥y tá»«ng pháº§n tá»­ cá»§a nÃ³, hÃ nh Ä‘á»™ng nÃ y cÃ³thá»ƒ Ä‘Æ°á»£c láº·p Ä‘i láº·p láº¡i.TrÃ¬nh láº·p lÃ  má»™t Ä‘á»‘i tÆ°á»£ng cÃ³ thá»ƒ Ä‘Æ°á»£c láº·p láº¡i, cÃ³ nghÄ©alÃ  báº¡n cÃ³ thá»ƒ duyá»‡t qua táº¥t cáº£ cÃ¡c giÃ¡ trá»‹.Vá» máº·t ká»¹ thuáº­t, trong Python, má»™t trÃ¬nh vÃ²ng láº·p lÃ  má»™t Ä‘á»‘i tÆ°á»£ng thá»±c hiá»‡ngiao thá»©c trÃ¬nh vÃ²ng láº·p, bao gá»“m cÃ¡c phÆ°Æ¡ng thá»©c iter() vÃ  next().# ThÃ­ dá»¥mytuple = (\"apple\", \"banana\", \"cherry\")myit = iter(mytuple)print(next(myit))print(next(myit))print(next(myit))GeneratorClosureDecoratorRegex@propertyMa tráº­n trong PythonÄá»‘i tÆ°á»£ng Iterator trong PythonGenerator trong PythonClosure trong PythonDecorator trong Python@property trong PythonRegEx trong PythonNumpy, pandas vÃ  matplotlibNumpyPandasMatplotlibPython GUIPyySimpleGUIPython ToolsPython WebPython MobileappPython GamePython Machine - AI!pip install https://github.com/aaren/notedown/tarball/master!notedown /content/drive/MyDrive/Python3-Tutorial/Code/Python/all.ipynb --to test.md!notedown /content/drive/MyDrive/Python3-Tutorial/Code/Python/all.ipynb --to markdown --strip &gt; output.md" }, { "title": "Tá»•ng quan vá» xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn", "url": "/posts/T%E1%BB%95ng-quan-v%E1%BB%81-NLP/", "categories": "Python, Machine-learning", "tags": "ML, AI", "date": "2022-09-26 00:00:00 +0700", "snippet": " I. Giá»›i thiá»‡u vá» Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (Natural Language Proccessing)Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cung cáº¥p má»™t bá»™ cÃ´ng cá»¥ vÃ  thuáº­t toÃ¡n ráº¥t cáº§n thiáº¿t Ä‘á»ƒ hiá»ƒu vÃ  xá»­ lÃ½ khá»‘i lÆ°á»£ng lá»›n dá»¯ liá»‡u phi cáº¥u trÃºc trong tháº¿ giá»›i hiá»‡n nay. Hiá»‡n nay Deep learning Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i cho nhiá»u nhiá»‡m vá»¥ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn vÃ¬ hiá»‡u suáº¥t deep learning hiá»‡u quáº£ Ä‘Ã¡ng ká»ƒ trong cÃ¡c nhiá»‡m vá»¥ nhÆ° phÃ¢n loáº¡i hÃ¬nh áº£nh, nháº­n dáº¡ng giá»ng nÃ³i vÃ  táº¡o vÄƒn báº£n thá»±c táº¿,â€¦ Tensorflow lÃ  má»™t deep learning framework trá»±c quan vÃ  hiá»‡u quáº£ nháº¥t cho cÃ¡c nhiá»‡m vá»¥ nÃ y. 1.Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn lÃ  gÃ¬Má»¥c tiÃªu cá»§a xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn lÃ  lÃ m cho mÃ¡y mÃ³c hiá»ƒu cÃ¡c ngÃ´n ngá»¯ nÃ³i vÃ  viáº¿t cá»§a chÃºng ta. Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cÃ³ máº·t á»Ÿ kháº¯p nÆ¡i vÃ  Ä‘Ã£ lÃ  má»™t pháº§n lá»›n trong cuá»™c sá»‘ng cá»§a con ngÆ°á»i. Trá»£ lÃ½ áº£o (Virtual Assistants) cháº³ng háº¡n nhÆ° Google Assistant, Cortana, Alexa vÃ  Apple Siri,.. pháº§n lá»›n lÃ  cÃ¡c há»‡ thá»‘ng NLP.NLP lÃ  má»™t lÄ©nh vá»±c nghiÃªn cá»©u cá»±c ká»³ thÃ¡ch thá»©c vÃ¬ cÃ¡c tá»« vÃ  ngá»¯ nghÄ©a cÃ³ má»‘i quan há»‡ phi tuyáº¿n tÃ­nh ráº¥t phá»©c táº¡p. Váº¥n Ä‘á» cÃ²n khÃ³ khÄƒn hÆ¡n khi má»—i ngÃ´n ngá»¯ cÃ³ ngá»¯ phÃ¡p, cÃº phÃ¡p vÃ  tá»« vá»±ng riÃªng. Do Ä‘Ã³, xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n liÃªn quan Ä‘áº¿n cÃ¡c nhiá»‡m vá»¥ phá»©c táº¡o khÃ¡c nhau nhÆ° phÃ¢n tÃ­ch cÃº phÃ¡p vÄƒn báº£n, hiá»ƒu cáº¥u trÃºc ngá»¯ phÃ¡p cÆ¡ báº£n cá»§a ngÃ´n ngá»¯. VÃ­ dá»¥ trong hai cÃ¢u nÃ y,â€tÃ´i Ä‘i trÃªn Ä‘Æ°á»ngâ€ vÃ  â€œtÃ´i thÃªm Ä‘Æ°á»ng vÃ o nÆ°á»›c camâ€, tá»« â€œÄ‘Æ°á»ngâ€ cÃ³ hai Ã½ nghÄ©a hoÃ n toÃ n khÃ¡c nhau, do bá»‘i cáº£nh mÃ  nÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng.Äá»ƒ hiá»ƒu bá»‘i cáº£nh mÃ  tá»« Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng. Há»c mÃ¡y Ä‘Ã£ trá»Ÿ thÃ nh má»™t yáº¿u tá»‘ chÃ­nh cho NLP, giÃºp hoÃ n thÃ nh cÃ¡c nhiá»‡m vá»¥ Ä‘Ã£ nÃ³i á»Ÿ trÃªn thÃ´ng qua há»c mÃ¡y. 2. Nhiá»‡m vá»¥ cá»§a xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn Tokenization: lÃ  nhiá»‡m vá»¥ tÃ¡ch má»™t kho vÄƒn báº£n thÃ nh cÃ¡c Ä‘Æ¡n vá»‹ nhá» hÆ¡n (vÃ­ dá»¥: tá»« hoáº·c kÃ½ tá»±). Máº·c dÃ¹ nÃ³ cÃ³ váº» bÃ¬nh thÆ°á»ng Ä‘á»‘i vá»›i má»™t sá»‘ ngÃ´n ngá»¯ nhÆ° tiáº¿ng Anh nhÆ°ng láº¡i khÃ³ khÄƒn Ä‘á»‘i vá»›i cÃ¡c ngÃ´n ngá»¯ nhÆ° tiáº¿ng Nháº­t vÃ¬ cÃ¡c tá»« khÃ´ng Ä‘Æ°á»£c phÃ¢n Ä‘á»‹nh bá»Ÿi khoáº£ng cÃ¡ch hay dáº¥u cháº¥m cÃ¢u Word-Sense Disambiguation: lÃ  nhiá»‡m vá»¥ xÃ¡c Ä‘á»‹nh Ä‘Ãºng Ã½ nghÄ©a cá»§a tá»« Nháº­n dáº¡ng thá»±c thá»ƒ (Named Entity Recognition(NER)): cá»‘ gáº¯ng trÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ (vÃ­ dá»¥: ngÆ°á»i, vá»‹ trÃ­, tá»• chá»©c) tá»« má»™t pháº§n nháº¥t Ä‘á»‹nh cá»§a vÄƒn báº£n. VÃ­ dá»¥, máº«u cÃ¢u , â€œJohn gave Mary two apples at school on Mondayâ€ sáº½ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh â€œ[John]name gave [Mary]name [two]number apples at [school]organization on [Monday]timeâ€. NER lÃ  má»™t chá»§ Ä‘á» báº¯t buá»™c trong cÃ¡c lÄ©nh vá»±c nhÆ° truy xuáº¥t thÃ´ng tin. GÃ¡n nhÃ£n tá»« loáº¡i (Part-of-Speech tagging POS): lÃ  nhiá»‡m vá»¥ gÃ¡n cÃ¡c tá»« loáº¡i cho cÃ¡c pháº§n cá»§a vÄƒn báº£n. NÃ³ cÃ³ thá»ƒ lÃ  cÃ¡c tháº» danh tá»«, Ä‘á»™ng tá»«, tÃ­nh tá»«, tráº¡ng tá»« vÃ  giá»›i tá»«,â€¦ PhÃ¢n loáº¡i cÃ¢u/tÃ³m táº¯t vÄƒn báº£n: PhÃ¢n loáº¡i cÃ¢u hoáº·c báº£n tÃ³m táº¯t (vÃ­ dá»¥, Ä‘Ã¡nh giÃ¡ phim) cÃ³ nhiá»u trÆ°á»ng há»£p sá»­ dá»¥ng nhÆ° phÃ¡t hiá»‡n thÆ° rÃ¡c, phÃ¢n loáº¡i bÃ i bÃ¡o (vÃ­ dá»¥: chÃ­nh trá»‹, cÃ´ng nghá»‡ vÃ  thá»ƒ thao) vÃ  xáº¿p háº¡ng Ä‘Ã¡nh giÃ¡ sáº£n pháº©m (nghÄ©a lÃ  tÃ­ch cá»±c hoáº·c tiÃªu cá»±c). Äiá»u nÃ y Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch Ä‘Ã o táº¡o má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i vá»›i dá»¯ liá»‡u Ä‘Æ°á»£c dÃ¡n nhÃ£n (nghÄ©a lÃ  Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c chÃº thÃ­ch bá»Ÿi con ngÆ°á»i, vá»›i nhÃ£n tÃ­ch cá»±c hoáº·c tiÃªu cá»±c). Táº¡o vÄƒn báº£n: Trong táº¡o vÄƒn báº£n, má»™t mÃ´ hÃ¬nh há»c táº­p (vÃ­ dá»¥: máº¡ng tháº§n kinh) Ä‘Æ°á»£c Ä‘Ã o táº¡o báº±ng vÄƒn báº£n (má»™t bá»™ sÆ°u táº­p lá»›n cÃ¡c tÃ i liá»‡u vÄƒn báº£n) vÃ  sau Ä‘Ã³ nÃ³ dá»± Ä‘oÃ¡n vÄƒn báº£n má»›i.VÃ­ dá»¥, mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ thá»ƒ xuáº¥t hiá»‡n má»™t cÃ¢u chuyá»‡n khoa há»c viá»…n tÆ°á»Ÿng hoÃ n toÃ n má»›i báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c cÃ¢u chuyá»‡n khoa há»c viá»…n tÆ°á»Ÿng hiá»‡n cÃ³ Ä‘á»ƒ Ä‘Ã o táº¡o. Gáº§n Ä‘Ã¢y, Openai Ä‘Ã£ phÃ¡t hÃ nh má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c gá»i lÃ  Openai-GPT-2, cÃ³ thá»ƒ táº¡o ra vÄƒn báº£n cá»±c ká»³ thá»±c táº¿ Tráº£ lá»i cÃ¢u há»i (Question Answering): Ká»¹ thuáº­t QA cÃ³ giÃ¡ trá»‹ thÆ°Æ¡ng máº¡i cao vÃ  cÃ¡c ká»¹ thuáº­t nhÆ° váº­y Ä‘Æ°á»£c tÃ¬m tháº¥y táº¡i ná»n táº£ng cá»§a Chatbots vÃ  Virtual Assistant (vÃ­ dá»¥: Google Assistant vÃ  Apple Siri) Dá»‹ch mÃ¡y (Machine Translation): MT lÃ  nhiá»‡m vá»¥ chuyá»ƒn Ä‘á»•i cÃ¢u/cá»¥m tá»« tá»« ngÃ´n ngá»¯ nguá»“n (vÃ­ dá»¥: tiáº¿ng Äá»©c) sang ngÃ´n ngá»¯ Ä‘Ã­ch (vÃ­ dá»¥: tiáº¿ng Anh). ÄÃ¢y lÃ  má»™t nhiá»‡m vá»¥ ráº¥t khÃ³ khÄƒn, vÃ¬ cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau cÃ³ cÃ¡c cáº¥u trÃºc cÃº phÃ¡p khÃ¡c nhau, Ä‘iá»u Ä‘Ã³ cÃ³ nghÄ©a lÃ  nÃ³ khÃ´ng pháº£i lÃ  má»™t chuyá»ƒn Ä‘á»•i má»™t-má»™t. HÆ¡n ná»¯a, cÃ¡c má»‘i quan há»‡ tá»« ngá»¯ giá»¯a cÃ¡c ngÃ´n ngá»¯ cÃ³ thá»ƒ lÃ  má»™t-nhiá»u, má»™t-má»™t, nhiá»u-má»™t hoáº·c nhiá»u-nhiá»u.Trong hÃ¬nh dÆ°á»›i, ta cÃ³ thá»ƒ tháº¥y phÃ¢n loáº¡i phÃ¢n cáº¥p cá»§a cÃ¡c nhiá»‡m vá»¥ NLP khÃ¡c nhau Ä‘Æ°á»£c phÃ¢n loáº¡i thÃ nh nhiá»u loáº¡i khÃ¡c nhau. ÄÃ³ lÃ  má»™t nhiá»‡m vá»¥ khÃ³ khÄƒn Ä‘á»ƒ gÃ¡n má»™t nhiá»‡m vá»¥ NLP cho má»™t phÃ¢n loáº¡i duy nháº¥t. ChÃºng ta sáº½ chia cÃ¡c danh má»¥c thÃ nh hai loáº¡i chÃ­nh: dá»±a trÃªn ngÃ´n ngá»¯ (mÃ u sÃ¡ng vá»›i vÄƒn báº£n Ä‘en) vÃ  dá»±a trÃªn cÃ´ng thá»©c váº¥n Ä‘á» (mÃ u tá»‘i vá»›i vÄƒn báº£n tráº¯ng). Váº¥n Ä‘á» ngÃ´n ngá»¯ cÃ³ hai loáº¡i: cÃº phÃ¡p (dá»±a trÃªn cáº¥u trÃºc) vÃ  ngá»¯ nghÄ©a (dá»±a trÃªn Ã½ nghÄ©a). Váº¥n Ä‘á» dá»±a trÃªn cÃ´ng thá»©c cÃ³ váº¥n Ä‘á» cÃ³ ba loáº¡i: cÃ¡c nhiá»‡m vá»¥ tiá»n xá»­ lÃ½ (cÃ¡c tÃ¡c vá»¥ Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn dá»¯ liá»‡u vÄƒn báº£n trÆ°á»›c khi cung cáº¥p cho má»™t mÃ´ hÃ¬nh), nhiá»‡m vá»¥ phÃ¢n loáº¡i(nhiá»‡m vá»¥ mÃ  chÃºng ta cá»‘ gáº¯ng gÃ¡n vÄƒn báº£n Ä‘áº§u vÃ o cho má»™t hoáº·c nhiá»u danh má»¥c tá»« má»™t táº­p há»£p cÃ¡c danh má»¥c Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c) vÃ  cÃ¡c nhiá»‡m vá»¥ táº¡o ra (cÃ¡c nhiá»‡m vá»¥ mÃ  chÃºng tÃ´i cá»‘ gáº¯ng táº¡o ra má»™t Ä‘áº§u ra vÄƒn báº£n má»›i) 3. CÃ¡ch tiáº¿p cáº­n truyá»n thá»‘ng Ä‘á»ƒ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªnCÃ¡ch tiáº¿p cáº­n truyá»n thá»‘ng hoáº·c cá»• Ä‘iá»ƒn Ä‘á»ƒ giáº£i quyáº¿t NLP lÃ  má»™t luá»“ng tuáº§n tá»± cá»§a má»™t sá»‘ bÆ°á»›c chÃ­nh vÃ  Ä‘Ã³ lÃ  má»™t cÃ¡ch tiáº¿p cáº­n thá»‘ng kÃª. Khi chÃºng ta xem xÃ©t ká»¹ hÆ¡n vá» mÃ´ hÃ¬nh há»c táº­p NLP truyá»n thá»‘ng, chÃºng ta sáº½ cÃ³ thá»ƒ tháº¥y má»™t táº­p há»£p cÃ¡c tÃ¡c vá»¥ riÃªng biá»‡t Ä‘ang diá»…n ra, cháº³ng háº¡n nhÆ° tiá»n xá»­ lÃ½ dá»¯ liá»‡u báº±ng cÃ¡ch xÃ³a dá»¯ liá»‡u khÃ´ng mong muá»‘n,ká»¹ thuáº­t tÃ­nh nÄƒng (feature engineering) Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c cÃ¡c biá»ƒu diá»…n tá»‘t vá» dá»¯ liá»‡u vÄƒn báº£n, tÃ¬m hiá»ƒu Ä‘á»ƒ sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n há»c mÃ¡y vá»›i sá»± trá»£ giÃºp cá»§a dá»¯ liá»‡u Ä‘Ã o táº¡o vÃ  dá»± Ä‘oÃ¡n Ä‘áº§u ra cho dá»¯ liá»‡u. Trong Ä‘Ã³, ká»¹ thuáº­t tÃ­nh nÄƒng lÃ  bÆ°á»›c tá»‘n thá»i gian vÃ  quan trá»ng nháº¥t Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t trÃªn má»™t nhiá»‡m vá»¥ NLP nháº¥t Ä‘á»‹nh. 3.Hiá»ƒu cÃ¡ch tiáº¿p cáº­n truyá»n thá»‘ngÄáº§u tiÃªn,vÄƒn báº£n cáº§n Ä‘Æ°á»£c xá»­ lÃ½ trÆ°á»›c, táº­p trung vÃ o viá»‡c giáº£m tá»« vá»±ng vÃ  phÃ¢n tÃ¢m.Tiáº¿p Ä‘áº¿n Ä‘áº¿n lÃ  má»™t sá»‘ bÆ°á»›c ká»¹ thuáº­t tÃ­nh nÄƒng (feature engineering). Má»¥c tiÃªu chÃ­nh cá»§a ká»¹ thuáº­t tÃ­nh nÄƒng lÃ  lÃ m cho viá»‡c há»c dá»… dÃ ng hÆ¡n cho cÃ¡c thuáº­t toÃ¡n. ThÃ´ng thÆ°á»ng cÃ¡c tÃ­nh nÄƒng Ä‘Æ°á»£c thiáº¿t káº¿ báº±ng tay vÃ  thiÃªn vá»‹ Ä‘á»‘i vá»›i sá»± hiá»ƒu biáº¿t cá»§a con ngÆ°á»i vá» má»™t ngÃ´n ngá»¯. Ká»¹ thuáº­t tÃ­nh nÄƒng lÃ  vÃ´ cÃ¹ng quan trá»ng Ä‘á»‘i vá»›i cÃ¡c thuáº­t toÃ¡n NLP cá»• Ä‘iá»ƒn, vÃ  do Ä‘Ã³, cÃ¡c há»‡ thá»‘ng hiá»‡u suáº¥t tá»‘t nháº¥t thÆ°á»ng cÃ³ cÃ¡c tÃ­nh nÄƒng tá»‘t nháº¥t. VÃ­ dá»¥: Ä‘á»‘i vá»›i má»™t nhiá»‡m vá»¥ phÃ¢n loáº¡i tÃ¬nh cáº£m, báº¡n cÃ³ thá»ƒ biá»ƒu thá»‹ má»™t cÃ¢u cÃ³ cÃ¢y phÃ¢n tÃ­ch vÃ  gÃ¡n cÃ¡c nhÃ£n dÆ°Æ¡ng, Ã¢m hoáº·c trung tÃ­nh cho má»—i nÃºt/cÃ¢y con trong cÃ¢y Ä‘á»ƒ phÃ¢n loáº¡i cÃ¢u Ä‘Ã³ lÃ  dÆ°Æ¡ng hoáº·c Ã¢m. NgoÃ i ra, giai Ä‘oáº¡n ká»¹ thuáº­t tÃ­nh nÄƒng cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c tÃ i nguyÃªn bÃªn ngoÃ i nhÆ° WordNet (cÆ¡ sá»Ÿ dá»¯ liá»‡u tá»« vá»±ng cÃ³ thá»ƒ cung cáº¥p hiá»ƒu biáº¿t vá» cÃ¡ch cÃ¡c tá»« khÃ¡c nhau cÃ³ liÃªn quan vá»›i nhau - vÃ­ dá»¥: tá»« Ä‘á»“ng nghÄ©a) Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c tÃ­nh nÄƒng tá»‘t hÆ¡n. ChÃºng ta sáº½ sá»›m xem xÃ©t má»™t ká»¹ thuáº­t ká»¹ thuáº­t tÃ­nh nÄƒng Ä‘Æ¡n giáº£n Ä‘Æ°á»£c gá»i lÃ  bag-of-words.Tiáº¿p theo, thuáº­t toÃ¡n há»c táº­p há»c cÃ¡ch thá»±c hiá»‡n tá»‘t trong nhiá»‡m vá»¥ Ä‘Ã£ cho báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c tÃ­nh nÄƒng thu Ä‘Æ°á»£c vÃ  tÃ¹y chá»n cÃ¡c tÃ i nguyÃªn bÃªn ngoÃ i. VÃ­ dá»¥, Ä‘á»‘i vá»›i má»™t nhiá»‡m vá»¥ tÃ³m táº¯t vÄƒn báº£n, má»™t kho vÄƒn báº£n song song chá»©a cÃ¡c cá»¥m tá»« phá»• biáº¿n vÃ  cÃ¡c chÃº giáº£i cÃ´ Ä‘á»ng sáº½ lÃ  má»™t nguá»“n tÃ i nguyÃªn bÃªn ngoÃ i tá»‘t. Cuá»‘i cÃ¹ng, dá»± Ä‘oÃ¡n xáº£y ra. Dá»± Ä‘oÃ¡n ráº¥t Ä‘Æ¡n giáº£n, trong Ä‘Ã³ báº¡n sáº½ cung cáº¥p má»™t Ä‘áº§u vÃ o má»›i vÃ  chá»©a cÃ¡c dá»± Ä‘oÃ¡n báº±ng cÃ¡ch chuyá»ƒn tiáº¿p Ä‘áº§u vÃ o thÃ´ng qua mÃ´ hÃ¬nh há»c táº­p. ToÃ n bá»™ quÃ¡ trÃ¬nh cá»§a phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng Ä‘Æ°á»£c mÃ´ táº£ bÃªn dÆ°á»›i 4.Háº¡n cháº¿ cá»§a phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ngCÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ Ä‘Æ°á»£c sá»­ dá»¥ng trong NLP truyá»n thá»‘ng buá»™c Ä‘Ã¡nh Ä‘á»•i thÃ´ng tin cÃ³ kháº£ nÄƒng há»¯u Ã­ch Ä‘Æ°á»£c nhÃºng trong vÄƒn báº£n (vÃ­ dá»¥: dáº¥u cÃ¢u) Ä‘á»ƒ lÃ m cho viá»‡c há»c kháº£ thi báº±ng cÃ¡ch giáº£m tá»« vá»±ng.Ká»¹ thuáº­t tÃ­nh nÄƒng máº¥t ráº¥t nhiá»u thá»i gian. Äá»ƒ thiáº¿t káº¿ má»™t há»‡ thá»‘ng Ä‘Ã¡ng tin cáº­y, cÃ¡c tÃ­nh nÄƒng tá»‘t cáº§n pháº£i Ä‘Æ°á»£c nghÄ© ra. QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ ráº¥t táº» nháº¡t vÃ¬ cÃ¡c khÃ´ng gian tÃ­nh nÄƒng khÃ¡c nhau cáº§n Ä‘Æ°á»£c khÃ¡m phÃ¡ vÃ  Ä‘Ã¡nh giÃ¡ rá»™ng rÃ£i. NgoÃ i ra, Ä‘á»ƒ cÃ³ hiá»‡u quáº£ cÃ¡c tÃ­nh nÄƒng máº¡nh máº½, cáº§n cÃ³ chuyÃªn mÃ´n vá» miá»n, cÃ³ thá»ƒ khan hiáº¿m vÃ  tá»‘n kÃ©m cho má»™t sá»‘ nhiá»‡m vá»¥ NLP nháº¥t Ä‘á»‹nh.CÃ¡c tÃ i nguyÃªn bÃªn ngoÃ i khÃ¡c nhau lÃ  cáº§n thiáº¿t Ä‘á»ƒ nÃ³ hoáº¡t Ä‘á»™ng tá»‘t, vÃ  khÃ´ng cÃ³ nhiá»u tÃ i nguyÃªn miá»…n phÃ­. CÃ¡c tÃ i nguyÃªn bÃªn ngoÃ i nhÆ° váº­y thÆ°á»ng bao gá»“m thÃ´ng tin Ä‘Æ°á»£c táº¡o thá»§ cÃ´ng Ä‘Æ°á»£c lÆ°u trá»¯ trong cÆ¡ sá»Ÿ dá»¯ liá»‡u lá»›n. Táº¡o má»™t cho má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ cÃ³ thá»ƒ máº¥t vÃ i nÄƒm, phá»¥ thuá»™c vÃ o má»©c Ä‘á»™ nghiÃªm trá»ng cá»§a nhiá»‡m vá»¥. 5.PhÆ°Æ¡ng phÃ¡p há»c sÃ¢u Ä‘á»ƒ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªnCÃ¡c mÃ´ hÃ¬nh sÃ¢u Ä‘Ã£ táº¡o ra má»™t lÃ n sÃ³ng thay Ä‘á»•i mÃ´ hÃ¬nh trong nhiá»u lÄ©nh vá»±c trong há»c mÃ¡y, vÃ¬ cÃ¡c mÃ´ hÃ¬nh sÃ¢u Ä‘Ã£ há»c Ä‘Æ°á»£c cÃ¡c tÃ­nh nÄƒng phong phÃº tá»« dá»¯ liá»‡u thÃ´ thay vÃ¬ sá»­ dá»¥ng cÃ¡c tÃ­nh nÄƒng bá»‹ háº¡n cháº¿ do con ngÆ°á»i thiáº¿t káº¿. Äiá»u nÃ y do Ä‘Ã³ khiáº¿n ká»¹ thuáº­t tÃ­nh nÄƒng gÃ¢y phiá»n nhiá»…u vÃ  Ä‘áº¯t tiá»n bá»‹ lá»—i thá»i. Vá»›i Ä‘iá»u nÃ y, cÃ¡c mÃ´ hÃ¬nh sÃ¢u Ä‘Ã£ lÃ m cho quy trÃ¬nh lÃ m viá»‡c truyá»n thá»‘ng hiá»‡u quáº£ hÆ¡n, vÃ¬ cÃ¡c mÃ´ hÃ¬nh sÃ¢u thá»±c hiá»‡n há»c táº­p tÃ­nh nÄƒng vÃ  há»c táº­p nhiá»‡m vá»¥ má»™t cÃ¡ch Ä‘á»“ng thá»i. HÆ¡n ná»¯a, do sá»‘ lÆ°á»£ng lá»›n cÃ¡c tham sá»‘ (nghÄ©a lÃ  trá»ng sá»‘) trong má»™t mÃ´ hÃ¬nh sÃ¢u, nÃ³ cÃ³ thá»ƒ bao gá»“m nhiá»u tÃ­nh nÄƒng hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i con ngÆ°á»i cÃ³ thá»ƒ thiáº¿t káº¿. Tuy nhiÃªn, cÃ¡c mÃ´ hÃ¬nh sÃ¢u Ä‘Æ°á»£c coi lÃ  má»™t há»™p Ä‘en do kháº£ nÄƒng diá»…n giáº£i kÃ©m cá»§a mÃ´ hÃ¬nh. Má»™t máº¡ng lÆ°á»›i tháº§n kinh sÃ¢u vá» cÆ¡ báº£n lÃ  má»™t máº¡ng lÆ°á»›i tháº§n kinh nhÃ¢n táº¡o cÃ³ lá»›p Ä‘áº§u vÃ o, nhiá»u lá»›p áº©n Ä‘Æ°á»£c káº¿t ná»‘i vá»›i nhau á»Ÿ giá»¯a, vÃ  cuá»‘i cÃ¹ng, má»™t lá»›p Ä‘áº§u ra (vÃ­ dá»¥: phÃ¢n loáº¡i hoáº·c há»“i quy). NhÆ° báº¡n cÃ³ thá»ƒ tháº¥y, Ä‘iá»u nÃ y táº¡o thÃ nh má»™t mÃ´ hÃ¬nh tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i tá»« dá»¯ liá»‡u thÃ´ Ä‘áº¿n dá»± Ä‘oÃ¡n. CÃ¡c lá»›p áº©n nÃ y á»Ÿ giá»¯a cung cáº¥p sá»©c máº¡nh cho cÃ¡c mÃ´ hÃ¬nh sÃ¢u vÃ¬ chÃºng chá»‹u trÃ¡ch nhiá»‡m há»c cÃ¡c tÃ­nh nÄƒng tá»‘t tá»« dá»¯ liá»‡u thÃ´. 6.Hiá»ƒu má»™t mÃ´ hÃ¬nh sÃ¢u Ä‘Æ¡n giáº£n - má»™t máº¡ng lÆ°á»›i tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§BÃ¢y giá», hÃ£y Ä‘á»ƒ cÃ³ má»™t cÃ¡i nhÃ¬n ká»¹ hÆ¡n vá» má»™t máº¡ng lÆ°á»›i tháº§n kinh sÃ¢u Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c sá»± hiá»ƒu biáº¿t tá»‘t hÆ¡n. Máº·c dÃ¹ cÃ³ ráº¥t nhiá»u biáº¿n thá»ƒ khÃ¡c nhau cá»§a cÃ¡c mÃ´ hÃ¬nh sÃ¢u, hÃ£y nhÃ¬n vÃ o má»™t trong nhá»¯ng mÃ´ hÃ¬nh sá»›m nháº¥t cÃ³ tá»« nÄƒm 1950 mÃ´ táº£ má»™t a fully connected neural network (FCNN) cÃ³ ba lá»›p tiÃªu chuáº©nMá»¥c tiÃªu cá»§a FCNN lÃ  Ã¡nh xáº¡ Ä‘áº§u vÃ o (vÃ­ dá»¥: hÃ¬nh áº£nh hoáº·c cÃ¢u) Ä‘áº¿n má»™t nhÃ£n hoáº·c chÃº thÃ­ch nháº¥t Ä‘á»‹nh (vÃ­ dá»¥: danh má»¥c Ä‘á»‘i tÆ°á»£ng cho hÃ¬nh áº£nh). Äiá»u nÃ y Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch sá»­ dá»¥ng Ä‘áº§u vÃ o X Ä‘á»ƒ tÃ­nh toÃ¡n H - biá»ƒu diá»…n áº©n cá»§a X - sá»­ dá»¥ng má»™t phÃ©p biáº¿n Ä‘á»•i nhÆ° â„=ğœ(ğ‘Š * h + b); á» Ä‘Ã¢y, W lÃ  trá»ng sá»‘ vÃ  b lÃ  Ä‘á»™ lá»‡ch cá»§a FCNN, vÃ  ğœ lÃ  chá»©c nÄƒng kÃ­ch hoáº¡t sigmoid. Máº¡ng tháº§n kinh sá»­ dá»¥ng cÃ¡c chá»©c nÄƒng kÃ­ch hoáº¡t phi tuyáº¿n tÃ­nh á»Ÿ má»—i lá»›p. KÃ­ch hoáº¡t sigmoid lÃ  má»™t trong nhá»¯ng kÃ­ch hoáº¡t nhÆ° váº­y. NÃ³ lÃ  má»™t chuyá»ƒn Ä‘á»•i pháº§n tá»­ Ä‘Æ°á»£c Ã¡p dá»¥ng cho Ä‘áº§u ra cá»§a má»™t lá»›p, trong Ä‘Ã³ Ä‘áº§u ra sigmoidal cá»§a x Ä‘Æ°á»£c cho bá»Ÿi, ğœ(ğ‘¥) = 1/(1+ğ‘’-x).Tiáº¿p theo, má»™t trÃ¬nh phÃ¢n loáº¡i Ä‘Æ°á»£c Ä‘áº·t trÃªn Ä‘áº§u FCNN cung cáº¥p kháº£ nÄƒng táº­n dá»¥ng cÃ¡c tÃ­nh nÄƒng Ä‘Ã£ há»c trong cÃ¡c lá»›p áº©n Ä‘á»ƒ phÃ¢n loáº¡i Ä‘áº§u vÃ o. TrÃ¬nh phÃ¢n loáº¡i lÃ  má»™t pháº§n cá»§a FCNN vÃ  má»™t lá»›p áº©n khÃ¡c vá»›i má»™t sá»‘ trá»ng sá»‘ Ws vÃ  thiÃªn vá»‹ Bs. NgoÃ i ra, chÃºng ta cÃ³ thá»ƒ tÃ­nh toÃ¡n Ä‘áº§u ra cuá»‘i cÃ¹ng cá»§a FCNN lÃ  output =softmax(ğ‘Šğ‘  âˆ— â„+ Bğ‘ ).VÃ­ dá»¥, má»™t phÃ¢n loáº¡i SoftMax cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c váº¥n Ä‘á» phÃ¢n loáº¡i Ä‘a nhÃ£n. NÃ³ cung cáº¥p má»™t biá»ƒu diá»…n chuáº©n hÃ³a cá»§a Ä‘áº§u ra Ä‘iá»ƒm sá»‘ cá»§a lá»›p phÃ¢n loáº¡i. ÄÃ³ lÃ , nÃ³ sáº½ táº¡o ra má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t há»£p lá»‡ trÃªn cÃ¡c lá»›p trong lá»›p phÃ¢n loáº¡i. NhÃ£n Ä‘Æ°á»£c coi lÃ  nÃºt Ä‘áº§u ra cÃ³ giÃ¡ trá»‹ softmax cao nháº¥t. Sau Ä‘Ã³, vá»›i Ä‘iá»u nÃ y, chÃºng ta cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh tá»•n tháº¥t phÃ¢n loáº¡i Ä‘Æ°á»£c tÃ­nh lÃ  sá»± khÃ¡c biá»‡t giá»¯a nhÃ£n Ä‘áº§u ra dá»± Ä‘oÃ¡n vÃ  nhÃ£n Ä‘áº§u ra thá»±c táº¿. Má»™t vÃ­ dá»¥ vá» chá»©c nÄƒng máº¥t mÃ¡t nhÆ° váº­y lÃ  máº¥t bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh (mean squared loss).Tiáº¿p theo, cÃ¡c tham sá»‘ máº¡ng tháº§n kinh, W, B, WS vÃ  BS, Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a báº±ng trÃ¬nh tá»‘i Æ°u hÃ³a ngáº«u nhiÃªn tiÃªu chuáº©n (vÃ­ dá»¥: giáº£m Ä‘á»™ dá»‘c ngáº«u nhiÃªn) Ä‘á»ƒ giáº£m sá»± máº¥t phÃ¢n loáº¡i cá»§a táº¥t cáº£ cÃ¡c Ä‘áº§u vÃ o. HÃ¬nh dÆ°á»›i mÃ´ táº£ quÃ¡ trÃ¬nh Ä‘Æ°á»£c giáº£i thÃ­ch trong Ä‘oáº¡n nÃ y cho FCNN ba lá»›p.CÃ³ thá»ƒ sá»­ dá»¥ng máº¡ng tháº§n kinh (cÃ³ thá»ƒ sÃ¢u hoáº·c nÃ´ng, tÃ¹y thuá»™c vÃ o Ä‘á»™ khÃ³ cá»§a nhiá»‡m vá»¥) cho nhiá»‡m vá»¥ nÃ y báº±ng cÃ¡ch tuÃ¢n thá»§ quy trÃ¬nh lÃ m viá»‡c sau: MÃ£ thÃ´ng bÃ¡o (Tokenize) cÃ¢u thÃ nh cÃ¡c tá»«. Chuyá»ƒn Ä‘á»•i cÃ¡c cÃ¢u thÃ nh má»™t biá»ƒu diá»…n sá»‘ cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh (vÃ­ dá»¥: biá»ƒu diá»…n tÃºi cá»§a cÃ¡c tá»«). Má»™t biá»ƒu diá»…n cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh lÃ  cáº§n thiáº¿t vÃ¬ cÃ¡c máº¡ng tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§ Ä‘Ã²i há»i má»™t Ä‘áº§u vÃ o cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh. Cung cáº¥p cÃ¡c Ä‘áº§u vÃ o sá»‘ vÃ o máº¡ng tháº§n kinh, dá»± Ä‘oÃ¡n Ä‘áº§u ra (dÆ°Æ¡ng hoáº·c Ã¢m) vÃ  so sÃ¡nh vá»›i má»¥c tiÃªu thá»±c. Tá»‘i Æ°u hÃ³a máº¡ng lÆ°á»›i tháº§n kinh báº±ng cÃ¡ch sá»­ dá»¥ng chá»©c nÄƒng tá»•n tháº¥t mong muá»‘n. 7. Má»™t sá»‘ ná»n táº£ng tÃ­nh toÃ¡n dá»±a trÃªn Ä‘Ã¡m mÃ¢y phá»• biáº¿nâ€¢ Google Colab: https://colab.research.google.com/â€¢ Google Cloud Platform (GCP): https://cloud.google.com/â€¢ Amazon Web Services (AWS): https://aws.amazon.com/ II.Hiá»ƒu vá» Tensorflow 2 1.Tensorflow lÃ  gÃ¬?Tensorflow lÃ  má»™t nguá»“n má»Ÿ, Ä‘Æ°á»£c phÃ¡t hÃ nh bá»Ÿi Google, chá»§ yáº¿u nháº±m giáº£m bá»›t cÃ¡c chi tiáº¿t Ä‘au Ä‘á»›n khi thá»±c hiá»‡n máº¡ng lÆ°á»›i tháº§n kinh (vÃ­ dá»¥, tÃ­nh toÃ¡n cÃ¡c dáº«n xuáº¥t (derivatives) cá»§a trá»ng lÆ°á»£ng cá»§a máº¡ng lÆ°á»›i tháº§n kinh). TensorFlow tiáº¿n thÃªm má»™t bÆ°á»›c báº±ng cÃ¡ch cung cáº¥p cÃ¡c triá»ƒn khai hiá»‡u quáº£ cÃ¡c tÃ­nh toÃ¡n sá»‘ Ä‘Ã³ báº±ng cÃ¡ch sá»­ dá»¥ng kiáº¿n trÃºc thiáº¿t bá»‹ há»£p nháº¥t tÃ­nh toÃ¡n (CUDA), lÃ  má»™t ná»n táº£ng tÃ­nh toÃ¡n song song Ä‘Æ°á»£c NVIDIA giá»›i thiá»‡u. 2.Báº¯t Ä‘áº§u vá»›i TensorFlow 2BÃ¢y giá», hÃ£y Ä‘á»ƒ tÃ¬m hiá»ƒu vá» má»™t vÃ i thÃ nh pháº§n thiáº¿t yáº¿u trong khung TensorFlow báº±ng cÃ¡ch lÃ m viá»‡c thÃ´ng qua má»™t vÃ­ dá»¥ vá» mÃ£. HÃ£y Ä‘á»ƒ viáº¿t má»™t vÃ­ dá»¥ Ä‘á»ƒ thá»±c hiá»‡n tÃ­nh toÃ¡n sau, Ä‘iá»u nÃ y ráº¥t phá»• biáº¿n Ä‘á»‘i vá»›i cÃ¡c máº¡ng tháº§n kinh:TÃ­nh toÃ¡n nÃ y bao gá»“m nhá»¯ng gÃ¬ xáº£y ra trong má»™t lá»›p duy nháº¥t cá»§a má»™t máº¡ng nÆ¡-ron Ä‘Æ°á»£c káº¿t ná»‘i hoÃ n toÃ n. á» Ä‘Ã¢y W vÃ  x lÃ  ma tráº­n vÃ  b lÃ  má»™t vectÆ¡. Sau Ä‘Ã³,â€.â€™ biá»ƒu thá»‹ dot. sigmoid lÃ  má»™t phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n tÃ­nh Ä‘Æ°á»£c Ä‘Æ°a ra bá»Ÿi phÆ°Æ¡ng trÃ¬nh sau:Äáº§u tiÃªn, chÃºng ta sáº½ cáº§n nháº­p TensorFlow vÃ  Numpy. Numpy lÃ  má»™t khung tÃ­nh toÃ¡n khoa há»c khÃ¡c cung cáº¥p cÃ¡c hoáº¡t Ä‘á»™ng toÃ¡n há»c vÃ  cÃ¡c hoáº¡t Ä‘á»™ng khÃ¡c Ä‘á»ƒ thao tÃ¡c dá»¯ liá»‡u. Nháº­p vÃ o chÃºng lÃ  Ä‘iá»u cáº§n thiáº¿t trÆ°á»›c khi báº¡n cháº¡y báº¥t ká»³ loáº¡i hoáº¡t Ä‘á»™ng liÃªn quan Ä‘áº¿n TensorFlow hoáº·c Numpy trong Python:import tensorflow as tf import numpy as npÄáº§u tiÃªn, chÃºng tÃ´i sáº½ viáº¿t má»™t hÃ m cÃ³ thá»ƒ láº¥y cÃ¡c Ä‘áº§u vÃ o X, W vÃ  B vÃ  thá»±c hiá»‡n tÃ­nh toÃ¡n nÃ y cho chÃºng tÃ´i:def layer(x, W, b): # Building the graph h = tf.nn.sigmoid(tf.matmul(x,W) + b) # Operation to perform return hTiáº¿p theo, chÃºng tÃ´i thÃªm má»™t cÃ´ng cá»¥ trang trÃ­ Python cÃ³ tÃªn TF.Function nhÆ° sau@tf.functiondef layer(x, W, b): # Building the graph h = tf.nn.sigmoid(tf.matmul(x,W) + b) # Operation to perform return hNÃ³i má»™t cÃ¡ch Ä‘Æ¡n giáº£n, má»™t decorator Python chá»‰ lÃ  má»™t hÃ m khÃ¡c. Má»™t decorator Python cung cáº¥p má»™t cÃ¡ch sáº¡ch sáº½ Ä‘á»ƒ gá»i má»™t hÃ m khÃ¡c báº¥t cá»© khi nÃ o báº¡n gá»i hÃ m decorated. NÃ³i cÃ¡ch khÃ¡c, má»—i khi hÃ m layer() Ä‘Æ°á»£c gá»i, tf.function() Ä‘Æ°á»£c gá»i. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c má»¥c Ä‘Ã­ch khÃ¡c nhau, cháº³ng háº¡n nhÆ°:â€¢ Ghi nháº­t kÃ½ ná»™i dung vÃ  hoáº¡t Ä‘á»™ng trong má»™t hÃ mâ€¢ XÃ¡c thá»±c cÃ¡c Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra cá»§a hÃ m khÃ¡cKhi hÃ m layer() Ä‘i qua tf.function (), TensorFlow sáº½ theo dÃµi ná»™i dung (nÃ³i cÃ¡ch khÃ¡c, cÃ¡c hoáº¡t Ä‘á»™ng vÃ  dá»¯ liá»‡u) trong hÃ m vÃ  tá»± Ä‘á»™ng xÃ¢y dá»±ng biá»ƒu Ä‘á»“ tÃ­nh toÃ¡n.Biá»ƒu Ä‘á»“ tÃ­nh toÃ¡n (cÃ²n Ä‘Æ°á»£c gá»i lÃ  biá»ƒu Ä‘á»“ DataFlow) xÃ¢y dá»±ng DAG (biá»ƒu Ä‘á»“ acyclic cÃ³ hÆ°á»›ng) hiá»ƒn thá»‹ loáº¡i Ä‘áº§u vÃ o nÃ o Ä‘Æ°á»£c yÃªu cáº§u vÃ  loáº¡i tÃ­nh toÃ¡n cáº§n Ä‘Æ°á»£c thá»±c hiá»‡n trong chÆ°Æ¡ng trÃ¬nhTrong vÃ­ dá»¥ nÃ y, hÃ m layer() táº¡o ra H báº±ng cÃ¡ch sá»­ dá»¥ng Ä‘áº§u vÃ o X, W vÃ  B vÃ  má»™t sá»‘ phÆ°Æ¡ng tiá»‡n chuyá»ƒn Ä‘á»•i hoáº·c cÃ¡c operations nhÆ° + vÃ  tf.matmul ():Náº¿u chÃºng ta nhÃ¬n vÃ o má»™t sá»± tÆ°Æ¡ng tá»± cho má»™t DAG, náº¿u báº¡n nghÄ© vá» Ä‘áº§u ra nhÆ° má»™t chiáº¿c bÃ¡nh, thÃ¬ biá»ƒu Ä‘á»“ sáº½ lÃ  cÃ´ng thá»©c Ä‘á»ƒ lÃ m cho bÃ¡nh Ä‘Ã³ sá»­ dá»¥ng cÃ¡c thÃ nh pháº§n (nghÄ©a lÃ  Ä‘áº§u vÃ o).TÃ­nh nÄƒng xÃ¢y dá»±ng biá»ƒu Ä‘á»“ tÃ­nh toÃ¡n nÃ y tá»± Ä‘á»™ng trong TensorFlow Ä‘Æ°á»£c gá»i lÃ  AutoGraph. AutoGraph khÃ´ng chá»‰ nhÃ¬n vÃ o cÃ¡c operations trong hÃ m Ä‘Æ°á»£c thÃ´ng qua; NÃ³ cÅ©ng xem xÃ©t ká»¹ lÆ°á»¡ng dÃ²ng cháº£y cá»§a cÃ¡c hoáº¡t Ä‘á»™ng. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  báº¡n cÃ³ thá»ƒ cÃ³ náº¿u cÃ¡c cÃ¢u lá»‡nh if, hoáº·c cÃ¡c vÃ²ng láº·p for/while trong hÃ m cá»§a báº¡n vÃ  AutoGraph sáº½ quan tÃ¢m chÃºng khi xÃ¢y dá»±ng biá»ƒu Ä‘á»“.Tiáº¿p theo, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng chá»©c nÄƒng nÃ y ngay láº­p tá»©c, nhÆ° saux = np.array([[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]],dtype=np.float32)á» Ä‘Ã¢y, x lÃ  má»™t máº£ng numpy Ä‘Æ¡n giáº£ninit_w = tf.initializers.RandomUniform(minval=-0.1, maxval=0.1)(shape=[10,5])W = tf.Variable(init_w, dtype=tf.float32, name='W') init_b = tf.initializers.RandomUniform()(shape=[5])b = tf.Variable(init_b, dtype=tf.float32, name='b')W vÃ  B lÃ  cÃ¡c biáº¿n TensorFlow Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh báº±ng Ä‘á»‘i tÆ°á»£ng TF.Varable. W vÃ  B lÃ  tensor. Má»™t tensor vá» cÆ¡ báº£n lÃ  má»™t máº£ng N chiá»u. VÃ­ dá»¥, má»™t vectÆ¡ má»™t chiá»u hoáº·c ma tráº­n hai chiá»u Ä‘Æ°á»£c gá»i lÃ  tensor. tf.variable lÃ  má»™t cáº¥u trÃºc cÃ³ thá»ƒ thay Ä‘á»•i, cÃ³ nghÄ©a lÃ  cÃ¡c giÃ¡ trá»‹ trong tensor Ä‘Æ°á»£c lÆ°u trá»¯ trong biáº¿n Ä‘Ã³ cÃ³ thá»ƒ thay Ä‘á»•i theo thá»i gian. VÃ­ dá»¥, cÃ¡c biáº¿n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c trá»ng sá»‘ máº¡ng tháº§n kinh, thay Ä‘á»•i trong quÃ¡ trÃ¬nh tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh.NgoÃ i ra, lÆ°u Ã½ ráº±ng vá»›i W vÃ  B, chÃºng tÃ´i cung cáº¥p má»™t sá»‘ Ä‘á»‘i sá»‘ quan trá»ng, cháº³ng háº¡n nhÆ° sau:init_w = tf.initializers.RandomUniform(minval=-0.1, maxval=0.1)(shape=[10,5])init_b = tf.initializers.RandomUniform()(shape=[5])ChÃºng Ä‘Æ°á»£c gá»i lÃ  cÃ¡c bá»™ khá»Ÿi táº¡o biáº¿n vÃ  lÃ  cÃ¡c tensor sáº½ Ä‘Æ°á»£c gÃ¡n cho cÃ¡c biáº¿n W vÃ  B ban Ä‘áº§u. Má»™t biáº¿n pháº£i cÃ³ má»™t giÃ¡ trá»‹ ban Ä‘áº§u Ä‘Æ°á»£c cung cáº¥p. á» Ä‘Ã¢y, tf.initializer.randomuniform cÃ³ nghÄ©a lÃ  chÃºng ta thá»‘ng nháº¥t cÃ¡c giÃ¡ trá»‹ máº«u giá»¯a minval (-0.1) vÃ  maxval (0,1) Ä‘á»ƒ gÃ¡n cÃ¡c giÃ¡ trá»‹ cho cÃ¡c tensor. CÃ³ nhiá»u bá»™ khá»Ÿi táº¡o khÃ¡c nhau Ä‘Æ°á»£c cung cáº¥p trong TensorFlow (https: // www.tensorflow.org/api_docs/python/tf/keras/initializer). NÃ³ cÅ©ng ráº¥t quan trá»ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh hÃ¬nh dáº¡ng cá»§a bá»™ khá»Ÿi táº¡o cá»§a báº¡n khi báº¡n Ä‘ang xÃ¡c Ä‘á»‹nh chÃ­nh bá»™ khá»Ÿi táº¡o. Thuá»™c tÃ­nh hÃ¬nh dáº¡ng xÃ¡c Ä‘á»‹nh kÃ­ch thÆ°á»›c cá»§a tá»«ng chiá»u cá»§a tenxÆ¡ Ä‘áº§u ra. VÃ­ dá»¥: náº¿u hÃ¬nh dáº¡ng lÃ  [10, 5], Ä‘iá»u nÃ y cÃ³ nghÄ©a lÃ  nÃ³ sáº½ lÃ  cáº¥u trÃºc hai chiá»u vÃ  sáº½ cÃ³ 10 pháº§n tá»­ trÃªn trá»¥c 0 (hÃ ng) vÃ  5 pháº§n tá»­ trÃªn trá»¥c 1 (cá»™t):h = layer(x,W,b)Cuá»‘i cÃ¹ng, H Ä‘Æ°á»£c gá»i lÃ  tensorflow tensor nÃ³i chung. Má»™t tensorflow tensor lÃ  má»™t cáº¥u trÃºc báº¥t biáº¿n. Khi má»™t giÃ¡ trá»‹ Ä‘Æ°á»£c gÃ¡n cho tensorflow tensor, nÃ³ khÃ´ng thá»ƒ thay Ä‘á»•i.NhÆ° báº¡n cÃ³ thá»ƒ tháº¥y, thuáº­t ngá»¯ tensor Ä‘Æ°á»£c sá»­ dá»¥ng theo hai cÃ¡ch:â€¢ Ä‘á»ƒ chá»‰ má»™t máº£ng n chiá»uâ€¢ Ä‘á»ƒ tham kháº£o cáº¥u trÃºc dá»¯ liá»‡u báº¥t biáº¿n trong tensorflowCuá»‘i cÃ¹ng, báº¡n cÃ³ thá»ƒ tháº¥y ngay giÃ¡ trá»‹ cá»§a Hprint(f\"h = {h.numpy()}\")@tf.functiondef layer(x, W, b): # Building the graph h = tf.nn.sigmoid(tf.matmul(x,W) + b) # Operation to be performed return hx = np.array([[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]], dtype=np.float32) # Variableinit_w = tf.initializers.RandomUniform(minval=-0.1, maxval=0.1)(shape=[10,5])W = tf.Variable(init_w, dtype=tf.float32, name='W') # Variableinit_b = tf.initializers.RandomUniform()(shape=[5])b = tf.Variable(init_b, dtype=tf.float32, name='b') h = layer(x,W,b)print(f\"h = {h.numpy()}\") 3.Äáº§u vÃ o, biáº¿n, Ä‘áº§u ra vÃ  operationâ€¢ Äáº§u vÃ o: Dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã o táº¡o vÃ  kiá»ƒm tra cÃ¡c thuáº­t toÃ¡n cá»§a chÃºng tÃ´iâ€¢ Biáº¿n: Tensor cÃ³ thá»ƒ thay Ä‘á»•i, chá»§ yáº¿u xÃ¡c Ä‘á»‹nh cÃ¡c tham sá»‘ cá»§a thuáº­t toÃ¡n cá»§a chÃºng tÃ´iâ€¢ Äáº§u ra: CÃ¡c tensor báº¥t biáº¿n lÆ°u trá»¯ cáº£ Ä‘áº§u ra Ä‘áº§u cuá»‘i vÃ  Ä‘áº§u ra trung gianâ€¢ Operation: CÃ¡c phÃ©p biáº¿n Ä‘á»•i khÃ¡c nhau cho Ä‘áº§u vÃ o Ä‘á»ƒ táº¡o ra Ä‘áº§u ra mong muá»‘n Äá»‹nh nghÄ©a Ä‘áº§u vÃ o trong TensorflowCÃ³ ba cÃ¡ch khÃ¡c nhau mÃ  báº¡n cÃ³ thá»ƒ cung cáº¥p dá»¯ liá»‡u cho chÆ°Æ¡ng trÃ¬nh TensorFlow:â€¢ Táº¡o dá»¯ liá»‡u dÆ°á»›i dáº¡ng máº£ng Numpyâ€¢ Táº¡o dá»¯ liá»‡u dÆ°á»›i dáº¡ng tenorflow tensorsâ€¢ Sá»­ dá»¥ng API TF.DATA Ä‘á»ƒ táº¡o Ä‘Æ°á»ng á»‘ng Ä‘áº§u vÃ o Äá»‹nh nghÄ©a biáº¿n trong TensorflowCÃ¡c biáº¿n Ä‘Ã³ng má»™t vai trÃ² quan trá»ng trong tensorflow. Má»™t biáº¿n vá» cÆ¡ báº£n lÃ  má»™t tenxÆ¡ vá»›i hÃ¬nh dáº¡ng cá»¥ thá»ƒ xÃ¡c Ä‘á»‹nh cÃ³ bao nhiÃªu kÃ­ch thÆ°á»›c mÃ  biáº¿n sáº½ cÃ³ vÃ  kÃ­ch thÆ°á»›c cá»§a má»—i chiá»u. Tuy nhiÃªn, khÃ´ng giá»‘ng nhÆ° má»™t tenxÆ¡ tenorflow thÃ´ng thÆ°á»ng, cÃ¡c biáº¿n cÃ³ thá»ƒ thay Ä‘á»•i; nghÄ©a lÃ  giÃ¡ trá»‹ cá»§a cÃ¡c biáº¿n cÃ³ thá»ƒ thay Ä‘á»•i sau khi chÃºng Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh. ÄÃ¢y lÃ  má»™t thuá»™c tÃ­nh lÃ½ tÆ°á»Ÿng Ä‘á»ƒ pháº£i thá»±c hiá»‡n cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh há»c táº­p (vÃ­ dá»¥: trá»ng lÆ°á»£ng máº¡ng tháº§n kinh), trong Ä‘Ã³ cÃ¡c trá»ng sá»‘ thay Ä‘á»•i má»™t chÃºt sau má»—i bÆ°á»›c há»c táº­p. VÃ­ dá»¥: náº¿u báº¡n xÃ¡c Ä‘á»‹nh má»™t biáº¿n cÃ³ x = tf.varable (0, dtype = tf.int32), báº¡n cÃ³ thá»ƒ thay Ä‘á»•i giÃ¡ trá»‹ cá»§a biáº¿n Ä‘Ã³ báº±ng cÃ¡ch sá»­ dá»¥ng hoáº¡t Ä‘á»™ng tenorflow nhÆ° tf.assign (x, x+1). Tuy nhiÃªn, náº¿u báº¡n xÃ¡c Ä‘á»‹nh má»™t tenxÆ¡ nhÆ° x = tf.constant (0, dtype = tf.int32), báº¡n khÃ´ng thá»ƒ thay Ä‘á»•i giÃ¡ trá»‹ cá»§a tenxÆ¡, nhÆ° báº¡n cÃ³ thá»ƒ cho má»™t biáº¿n. NÃ³ sáº½ á»Ÿ láº¡i 0 cho Ä‘áº¿n khi káº¿t thÃºc viá»‡c thá»±c hiá»‡n chÆ°Æ¡ng trÃ¬nh.Táº¡o biáº¿n lÃ  khÃ¡ Ä‘Æ¡n giáº£n. Trong vÃ­ dá»¥ sigmoid cá»§a chÃºng ta, chÃºng ta Ä‘Ã£ táº¡o hai biáº¿n, W vÃ  b. Khi táº¡o ra má»™t biáº¿n, má»™t vÃ i Ä‘iá»u lÃ  vÃ´ cÃ¹ng quan trá»ng. ChÃºng ta sáº½ liá»‡t kÃª chÃºng á»Ÿ Ä‘Ã¢y vÃ  tháº£o luáº­n chi tiáº¿t trong cÃ¡c Ä‘oáº¡n sau: HÃ¬nh dáº¡ng biáº¿n GiÃ¡ trá»‹ ban Ä‘áº§u Kiá»ƒu dá»¯ liá»‡u TÃªn (TÃ¹y chá»n)HÃ¬nh dáº¡ng biáº¿n lÃ  má»™t danh sÃ¡ch cá»§a Ä‘á»‹nh dáº¡ng [x, y, z, â€¦]. Má»—i giÃ¡ trá»‹ trong danh sÃ¡ch cho biáº¿t kÃ­ch thÆ°á»›c hoáº·c trá»¥c tÆ°Æ¡ng á»©ng lá»›n nhÆ° tháº¿ nÃ o. Cháº³ng háº¡n, náº¿u báº¡n yÃªu cáº§u tenxÆ¡ 2D vá»›i 50 hÃ ng vÃ  10 cá»™t lÃ m biáº¿n, hÃ¬nh dáº¡ng sáº½ báº±ng [50,10].KÃ­ch thÆ°á»›c cá»§a biáº¿n (nghÄ©a lÃ  Ä‘á»™ dÃ i cá»§a vectÆ¡ hÃ¬nh dáº¡ng) Ä‘Æ°á»£c cÃ´ng nháº­n lÃ  thá»© háº¡ng cá»§a tensor trong tenorflow.Tiáº¿p theo, má»™t biáº¿n yÃªu cáº§u má»™t giÃ¡ trá»‹ ban Ä‘áº§u pháº£i Ä‘Æ°á»£c khá»Ÿi táº¡o. TensorFlow cung cáº¥p má»™t sá»‘ bá»™ khá»Ÿi táº¡o khÃ¡c nhau, bao gá»“m cÃ¡c bá»™ khá»Ÿi táº¡o khÃ´ng Ä‘á»•i vÃ  bá»™ khá»Ÿi táº¡o phÃ¢n phá»‘i bÃ¬nh thÆ°á»ng. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t vÃ i bá»™ khá»Ÿi táº¡o TensorFlow phá»• biáº¿n mÃ  báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ khá»Ÿi táº¡o cÃ¡c biáº¿n: tf.initializers.Zeros tf.initializers.Constant tf.initializers.RandomNormal tf.initializers.GlorotUniformHÃ¬nh dáº¡ng cá»§a biáº¿n cÃ³ thá»ƒ Ä‘Æ°á»£c cung cáº¥p nhÆ° lÃ  má»™t pháº§n cá»§a trÃ¬nh khá»Ÿi táº¡o nhÆ° sau:tf.initializers.RandomUniform(minval=-0.1, maxval=0.1)(shape=[10,5])Kiá»ƒu dá»¯ liá»‡u Ä‘Ã³ng má»™t vai trÃ² quan trá»ng trong viá»‡c xÃ¡c Ä‘á»‹nh kÃ­ch thÆ°á»›c cá»§a má»™t biáº¿n. CÃ³ nhiá»u loáº¡i dá»¯ liá»‡u khÃ¡c nhau, bao gá»“m TF.Bool, TF.Uint8, TF.Float32 vÃ  TF.INT32. Má»—i loáº¡i dá»¯ liá»‡u cÃ³ má»™t sá»‘ bit cáº§n thiáº¿t Ä‘á»ƒ biá»ƒu diá»…n má»™t giÃ¡ trá»‹ duy nháº¥t vá»›i loáº¡i Ä‘Ã³. VÃ­ dá»¥, tf.uint8 yÃªu cáº§u 8 bit, trong khi tf.float32 yÃªu cáº§u 32 bit. ÄÃ³ lÃ  thá»±c táº¿ phá»• biáº¿n Ä‘á»ƒ sá»­ dá»¥ng cÃ¡c loáº¡i dá»¯ liá»‡u tÆ°Æ¡ng tá»± cho cÃ¡c tÃ­nh toÃ¡n, vÃ¬ lÃ m cÃ¡ch khÃ¡c cÃ³ thá»ƒ dáº«n Ä‘áº¿n sá»± khÃ´ng phÃ¹ há»£p cá»§a kiá»ƒu dá»¯ liá»‡u. VÃ¬ váº­y, náº¿u báº¡n cÃ³ hai loáº¡i dá»¯ liá»‡u khÃ¡c nhau cho hai tenxor mÃ  báº¡n cáº§n chuyá»ƒn Ä‘á»•i, báº¡n pháº£i chuyá»ƒn Ä‘á»•i rÃµ rÃ ng má»™t tenxÆ¡ sang loáº¡i tenxÆ¡ khÃ¡c báº±ng cÃ¡ch sá»­ dá»¥ng thao tÃ¡c tf.cast (â€¦).Hoáº¡t Ä‘á»™ng tf.cast (â€¦) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘á»‘i phÃ³ vá»›i cÃ¡c tÃ¬nh huá»‘ng nhÆ° váº­y. VÃ­ dá»¥: náº¿u báº¡n cÃ³ biáº¿n X vá»›i loáº¡i tf.int32, cáº§n Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh tf.float32, sá»­ dá»¥ng tf.cast(x, dtype = tf.float32) Ä‘á»ƒ chuyá»ƒn Ä‘á»•i x thÃ nh tf.float32.Cuá»‘i cÃ¹ng, tÃªn cá»§a biáº¿n sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m ID Ä‘á»ƒ xÃ¡c Ä‘á»‹nh biáº¿n Ä‘Ã³ trong biá»ƒu Ä‘á»“. Náº¿u báº¡n Ä‘Ã£ tá»«ng trá»±c quan hÃ³a biá»ƒu Ä‘á»“ tÃ­nh toÃ¡n, biáº¿n sáº½ xuáº¥t hiá»‡n báº±ng Ä‘á»‘i sá»‘ Ä‘Æ°á»£c chuyá»ƒn Ä‘áº¿n tÃªn tá»« khÃ³a. Náº¿u báº¡n khÃ´ng chá»‰ Ä‘á»‹nh tÃªn, TensorFlow sáº½ sá»­ dá»¥ng sÆ¡ Ä‘á»“ Ä‘áº·t tÃªn máº·c Ä‘á»‹nh.a = tf.Variable(tf.zeros([5]),name='b')á» Ä‘Ã¢y, biá»ƒu Ä‘á»“ tensorflow sáº½ biáº¿t biáº¿n nÃ y báº±ng tÃªn b chá»© khÃ´ng pháº£i a Äá»‹nh nghÄ©a Ä‘áº§u ra trong TensorflowÄáº§u ra tenorflow thÆ°á»ng lÃ  tensor vÃ  káº¿t quáº£ cá»§a viá»‡c chuyá»ƒn Ä‘á»•i thÃ nh Ä‘áº§u vÃ o hoáº·c má»™t biáº¿n hoáº·c cáº£ hai. Trong vÃ­ dá»¥ cá»§a chÃºng ta, h lÃ  Ä‘áº§u ra, trong Ä‘Ã³ h = tf.nn.sigmoid (tf.matmul (x, w) + b). CÅ©ng cÃ³ thá»ƒ cung cáº¥p cÃ¡c Ä‘áº§u ra nhÆ° váº­y cho cÃ¡c hoáº¡t Ä‘á»™ng khÃ¡c, táº¡o thÃ nh má»™t táº­p há»£p cÃ¡c hoáº¡t Ä‘á»™ng chuá»—i. HÆ¡n ná»¯a, khÃ´ng nháº¥t thiáº¿t pháº£i lÃ  hoáº¡t Ä‘á»™ng tensorflow. Báº¡n cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng sá»‘ há»c python tiÃªu chuáº©n vá»›i tensorflow. ÄÃ¢y lÃ  má»™t vÃ­ dá»¥:x = tf.matmul(w,A)y = x + B Äá»‹nh nghÄ©a operations trong TensorFlowMá»™t hoáº¡t Ä‘á»™ng trong TensorFlow cÃ³ má»™t hoáº·c nhiá»u Ä‘áº§u vÃ o vÃ  táº¡o ra má»™t hoáº·c nhiá»u Ä‘áº§u ra. Náº¿u báº¡n xem API TensorFlow táº¡i https://www.tensorflow.org/api_docs/python/tf, báº¡n sáº½ tháº¥y TensorFlow cÃ³ má»™t bá»™ sÆ°u táº­p hoáº¡t Ä‘á»™ng lá»›n. á» Ä‘Ã¢y, chÃºng tÃ´i sáº½ xem xÃ©t má»™t vÃ i trong sá»‘ cÃ¡c hoáº¡t Ä‘á»™ng vÃ´ sá»‘ tenorflow. Hoáº¡t Ä‘á»™ng so sÃ¡nhHoáº¡t Ä‘á»™ng so sÃ¡nh ráº¥t há»¯u Ã­ch Ä‘á»ƒ so sÃ¡nh hai tensor. VÃ­ dá»¥ mÃ£ sau Ä‘Ã¢y bao gá»“m má»™t vÃ i hoáº¡t Ä‘á»™ng so sÃ¡nh há»¯u Ã­ch.import tensorflow as tfx = tf.constant([[1,2],[3,4]], dtype=tf.int32)y = tf.constant([[4,3],[3,2]], dtype=tf.int32)x_equal_y = tf.equal(x, y, name=None)x_less_y = tf.less(x, y, name=None)x_great_equal_y = tf.greater_equal(x, y, name=None)condition = tf.constant([[True,False],[True,False]],dtype=tf.bool)x_cond_y = tf.where(condition, x, y, name=None) Hoáº¡t Ä‘á»™ng toÃ¡n há»cTensorFlow cho phÃ©p báº¡n thá»±c hiá»‡n cÃ¡c thao tÃ¡c toÃ¡n há»c trÃªn cÃ¡c tenxÆ¡ tá»« Ä‘Æ¡n giáº£n Ä‘áº¿n phá»©c táº¡p. Bá»™ hoáº¡t Ä‘á»™ng hoÃ n chá»‰nh cÃ³ sáºµn táº¡i https://www.tensorflow.org/versions/r2.0/ api_docs/python/tf/math:x = tf.constant([[1,2],[3,4]], dtype=tf.float32)y = tf.constant([[4,3],[3,2]], dtype=tf.float32)x_add_y = tf.add(x, y)x_mul_y = tf.matmul(x, y)log_x = tf.log(x)x_sum_1 = tf.reduce_sum(x, axis=[1], keepdims=False)x_sum_2 = tf.reduce_sum(x, axis=[0], keepdims=True)data = tf.constant([1,2,3,4,5,6,7,8,9,10], dtype=tf.float32)segment_ids = tf.constant([0,0,0,1,1,2,2,2,2,2 ], dtype=tf.int32)x_seg_sum = tf.segment_sum(data, segment_ids) Cáº­p nháº­t giÃ¡ trá»‹ trong cÃ¡c tensorMá»™t hoáº¡t Ä‘á»™ng phÃ¢n tÃ¡n (scatter operation), Ä‘á» cáº­p Ä‘áº¿n viá»‡c thay Ä‘á»•i cÃ¡c giÃ¡ trá»‹ táº¡i má»™t sá»‘ chá»‰ sá»‘ nháº¥t Ä‘á»‹nh cá»§a má»™t tensor, lÃ  ráº¥t phá»• biáº¿n trong cÃ¡c váº¥n Ä‘á» Ä‘iá»‡n toÃ¡n khoa há»c. Chá»©c nÄƒng nÃ y ban Ä‘áº§u Ä‘Æ°á»£c cung cáº¥p thÃ´ng qua hÃ m tf.scatter_nd()Tuy nhiÃªn, trong cÃ¡c phiÃªn báº£n TensorFlow gáº§n Ä‘Ã¢y, báº¡n cÃ³ thá»ƒ thá»±c hiá»‡n cÃ¡c hoáº¡t Ä‘á»™ng phÃ¢n tÃ¡n thÃ´ng qua láº­p chá»‰ má»¥c máº£ng vÃ  cáº¯t báº±ng cÃº phÃ¡p giá»‘ng nhÆ° Numpy. HÃ£y cÃ¹ng xem má»™t vÃ i vÃ­ dá»¥. Giáº£ sá»­ báº¡n cÃ³ TensorFlow biáº¿n V, lÃ  ma tráº­n [3,2]:v = tf.Variable(tf.constant([[1,9],[3,10],[5,11]],dtype=tf.float32),name='ref') Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i hÃ ng thá»© 0 cá»§a tenxÆ¡ nÃ y báº±ng:v[0].assign([-1, -9])Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i giÃ¡ trá»‹ táº¡i Index [1,1] báº±ng:v[1,1].assign(-10)Báº¡n cÃ³ thá»ƒ thá»±c hiá»‡n cáº¯t hÃ ng vá»›i:v[1:,0].assign([-3,-5]) Thu tháº­p cÃ¡c giÃ¡ trá»‹ tá»« má»™t tenorMá»™t hoáº¡t Ä‘á»™ng táº­p há»£p (gather operation) ráº¥t giá»‘ng vá»›i má»™t hoáº¡t Ä‘á»™ng phÃ¢n tÃ¡n. HÃ£y nhá»› ráº±ng phÃ¢n tÃ¡n lÃ  vá» viá»‡c gÃ¡n cÃ¡c giÃ¡ trá»‹ cho cÃ¡c tensor, trong khi viá»‡c thu tháº­p láº¥y cÃ¡c giÃ¡ trá»‹ cá»§a má»™t tensor. HÃ£y Ä‘á»ƒ hiá»ƒu Ä‘iá»u nÃ y thÃ´ng qua má»™t vÃ­ dá»¥. Giáº£ sá»­ báº¡n cÃ³ tenorflow tenor, T:t = tf.constant([[1,9],[3,10],[5,11]],dtype=tf.float32)Báº¡n cÃ³ thá»ƒ cÃ³ Ä‘Æ°á»£c hÃ ng thá»© 0 cá»§a T vá»›i:t[0].numpy()Báº¡n cÅ©ng cÃ³ thá»ƒ thá»±c hiá»‡n trÆ°á»£t hÃ ng (row-slicing) vá»›i:t[1:,0].numpy()KhÃ´ng giá»‘ng nhÆ° hoáº¡t Ä‘á»™ng phÃ¢n tÃ¡n, hoáº¡t Ä‘á»™ng táº­p há»£p hoáº¡t Ä‘á»™ng cáº£ trÃªn cÃ¡c cáº¥u trÃºc TF.Varable vÃ  TF.Tensor. 4.Operation liÃªn quan Ä‘áº¿n máº¡ng tháº§n kinhBÃ¢y giá», hÃ£y xem xÃ©t má»™t sá»‘ hoáº¡t Ä‘á»™ng liÃªn quan Ä‘áº¿n máº¡ng tháº§n kinh há»¯u Ã­ch mÃ  chÃºng ta sáº½ sá»­ dá»¥ng ráº¥t nhiá»u trong cÃ¡c chÆ°Æ¡ng sau. CÃ¡c hoáº¡t Ä‘á»™ng mÃ  chÃºng tÃ´i sáº½ tháº£o luáº­n á»Ÿ Ä‘Ã¢y bao gá»“m tá»« cÃ¡c biáº¿n Ä‘á»•i pháº§n tá»­ Ä‘Æ¡n giáº£n (nghÄ©a lÃ  kÃ­ch hoáº¡t) Ä‘áº¿n tÃ­nh toÃ¡n cÃ¡c dáº«n xuáº¥t má»™t pháº§n cá»§a má»™t táº­p há»£p cÃ¡c tham sá»‘ Ä‘á»‘i vá»›i giÃ¡ trá»‹ khÃ¡c. ChÃºng ta cÅ©ng sáº½ triá»ƒn khai má»™t máº¡ng lÆ°á»›i tháº§n kinh Ä‘Æ¡n giáº£n. KÃ­ch hoáº¡t phi tuyáº¿n Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi cÃ¡c máº¡ng tháº§n kinhKÃ­ch hoáº¡t phi tuyáº¿n cho phÃ©p cÃ¡c máº¡ng tháº§n kinh hoáº¡t Ä‘á»™ng tá»‘t á»Ÿ nhiá»u nhiá»‡m vá»¥. ThÃ´ng thÆ°á»ng, cÃ³ má»™t phÃ©p biáº¿n Ä‘á»•i kÃ­ch hoáº¡t phi tuyáº¿n (nghÄ©a lÃ  lá»›p kÃ­ch hoáº¡t) sau má»—i Ä‘áº§u ra lá»›p trong máº¡ng tháº§n kinh (ngoáº¡i trá»« lá»›p cuá»‘i cÃ¹ng). Má»™t phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n giÃºp má»™t máº¡ng lÆ°á»›i tháº§n kinh tÃ¬m hiá»ƒu cÃ¡c máº«u phi tuyáº¿n khÃ¡c nhau cÃ³ trong dá»¯ liá»‡u. Äiá»u nÃ y ráº¥t há»¯u Ã­ch cho cÃ¡c váº¥n Ä‘á» trong tháº¿ giá»›i thá»±c phá»©c táº¡p, trong Ä‘Ã³ dá»¯ liá»‡u thÆ°á»ng cÃ³ cÃ¡c máº«u phi tuyáº¿n phá»©c táº¡p hÆ¡n, trÃ¡i ngÆ°á»£c vá»›i cÃ¡c máº«u tuyáº¿n tÃ­nh. Náº¿u khÃ´ng dÃ nh cho cÃ¡c kÃ­ch hoáº¡t phi tuyáº¿n giá»¯a cÃ¡c lá»›p, má»™t máº¡ng lÆ°á»›i tháº§n kinh sÃ¢u sáº½ lÃ  má»™t loáº¡t cÃ¡c lá»›p tuyáº¿n tÃ­nh Ä‘Æ°á»£c xáº¿p chá»“ng lÃªn nhau. NgoÃ i ra, má»™t táº­p há»£p cÃ¡c lá»›p tuyáº¿n tÃ­nh vá» cÆ¡ báº£n cÃ³ thá»ƒ Ä‘Æ°á»£c nÃ©n vÃ o má»™t lá»›p tuyáº¿n tÃ­nh lá»›n hÆ¡n.TÃ³m láº¡i, náº¿u khÃ´ng cho cÃ¡c kÃ­ch hoáº¡t phi tuyáº¿n, chÃºng ta khÃ´ng thá»ƒ táº¡o ra má»™t máº¡ng lÆ°á»›i tháº§n kinh vá»›i nhiá»u hÆ¡n má»™t lá»›p.Táº§m quan trá»ng cá»§a viá»‡c kÃ­ch hoáº¡t phi tuyáº¿n thÃ´ng qua má»™t vÃ­ dá»¥. Äáº§u tiÃªn, hÃ£y nhá»› láº¡i viá»‡c tÃ­nh toÃ¡n cho cÃ¡c máº¡ng tháº§n kinh mÃ  chÃºng ta Ä‘Ã£ tháº¥y trong vÃ­ dá»¥ SigMoid.h = sigmoid(W*x)Giáº£ sá»­ má»™t máº¡ng lÆ°á»›i tháº§n kinh ba lá»›p (cÃ³ W1, W2 vÃ  W3 lÃ m trá»ng sá»‘ lá»›p) trong Ä‘Ã³ má»—i lá»›p thá»±c hiá»‡n tÃ­nh toÃ¡n trÆ°á»›c Ä‘Ã³; ChÃºng ta cÃ³ thá»ƒ tÃ³m táº¯t tÃ­nh toÃ¡n Ä‘áº§y Ä‘á»§ nhÆ° sauh = sigmoid(W3*sigmoid(W2*sigmoid(W1*x)))Tuy nhiÃªn, náº¿u chÃºng ta loáº¡i bá» kÃ­ch hoáº¡t phi tuyáº¿n (nghÄ©a lÃ  sigmoid), chÃºng ta sáº½ nháº­n Ä‘Æ°á»£c Ä‘iá»u nÃ y:h = (W3 * (W2 * (W1 *x))) = (W3*W2*W1)*xVÃ¬ váº­y, khÃ´ng cÃ³ kÃ­ch hoáº¡t phi tuyáº¿n, ba lá»›p cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Æ°a xuá»‘ng má»™t lá»›p tuyáº¿n tÃ­nh duy nháº¥tBÃ¢y giá» chÃºng tÃ´i sáº½ liá»‡t kÃª hai kÃ­ch hoáº¡t phi tuyáº¿n ( nonlinear activations) thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c máº¡ng tháº§n kinh (nÃ³i cÃ¡ch khÃ¡c lÃ  SigMoid vÃ  Relu) vÃ  cÃ¡ch chÃºng cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n trong TensorFlow# Sigmoid : 1 / (1 + exp(-x))tf.nn.sigmoid(x,name=None)# ReLU activation : max(0,x)tf.nn.relu(x, name=None) Convolution operationMá»™t hoáº¡t Ä‘á»™ng tÃ­ch cháº­p lÃ  má»™t ká»¹ thuáº­t xá»­ lÃ½ tÃ­n hiá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i. Äá»‘i vá»›i hÃ¬nh áº£nh, tÃ­ch cháº­p Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ra cÃ¡c hiá»‡u á»©ng khÃ¡c nhau (nhÆ° lÃ m má») hoáº·c trÃ­ch xuáº¥t cÃ¡c tÃ­nh nÄƒng (nhÆ° cÃ¡c cáº¡nh) tá»« má»™t hÃ¬nh áº£nh. Má»™t vÃ­ dá»¥ vá» phÃ¡t hiá»‡n cáº¡nh báº±ng cÃ¡ch sá»­ dá»¥ng tÃ­ch cháº­p Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh dÆ°á»›i. Äiá»u nÃ y Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch chuyá»ƒn má»™t bá»™ lá»c tÃ­ch cháº­p cá»§a hÃ¬nh áº£nh Ä‘á»ƒ táº¡o ra má»™t Ä‘áº§u ra khÃ¡c nhau á»Ÿ má»—i vá»‹ trÃ­. Cá»¥ thá»ƒ, táº¡i má»—i vá»‹ trÃ­, chÃºng tÃ´i thá»±c hiá»‡n phÃ©p nhÃ¢n pháº§n tá»­ cá»§a cÃ¡c pháº§n tá»­ trong bá»™ lá»c tÃ­ch cháº­p vá»›i báº£n vÃ¡ hÃ¬nh áº£nh (image patch) (cÃ¹ng kÃ­ch thÆ°á»›c vá»›i bá»™ lá»c tÃ­ch cháº­p) trÃ¹ng vá»›i bá»™ lá»c tÃ­ch cháº­p vÃ  láº¥y tá»•ng cá»§a phÃ©p nhÃ¢nSau Ä‘Ã¢y lÃ  viá»‡c thá»±c hiá»‡n hoáº¡t Ä‘á»™ng tÃ­ch cháº­px = tf.constant( [[ [[1],[2],[3],[4]], [[4],[3],[2],[1]], [[5],[6],[7],[8]], [[8],[7],[6],[5]] ]], dtype=tf.float32)x_filter = tf.constant( [ [ [[0.5]],[[1]] ], [ [[0.5]],[[1]] ] ], dtype=tf.float32)x_stride = [1,1,1,1]x_padding = 'VALID'x_conv = tf.nn.conv2d( input=x, filters=x_filter, strides=x_stride, padding=x_padding)Äá»‘i vá»›i hoáº¡t Ä‘á»™ng tf.nn.conv2d (â€¦), TensorFlow yÃªu cáº§u Ä‘áº§u vÃ o, bá»™ lá»c vÃ  sáº£i bÆ°á»›c ( input, filters, and strides ) cÃ³ Ä‘á»‹nh dáº¡ng chÃ­nh xÃ¡c. BÃ¢y giá» chÃºng ta sáº½ Ä‘i qua tá»«ng Ä‘á»‘i sá»‘ trong tf.conv2d (Ä‘áº§u vÃ o, bá»™ lá»c, sáº£i chÃ¢n, Ä‘á»‡m) ((input, filters, strides, padding)) chi tiáº¿t hÆ¡n:Input : ÄÃ¢y thÆ°á»ng lÃ  má»™t tenxÆ¡ 4D trong Ä‘Ã³ cÃ¡c kÃ­ch thÆ°á»›c nÃªn Ä‘Æ°á»£c Ä‘áº·t dÆ°á»›i dáº¡ng [batch_size, height, width, channels]: Batch_Size: ÄÃ¢y lÃ  lÆ°á»£ng dá»¯ liá»‡u (vÃ­ dá»¥: cÃ¡c Ä‘áº§u vÃ o nhÆ° hÃ¬nh áº£nh vÃ  tá»«) trong má»™t lÃ´ dá»¯ liá»‡u. ChÃºng ta thÆ°á»ng xá»­ lÃ½ dá»¯ liá»‡u theo lÃ´ vÃ¬ cÃ¡c bá»™ dá»¯ liá»‡u lá»›n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ há»c. á» má»™t bÆ°á»›c Ä‘Ã o táº¡o nháº¥t Ä‘á»‹nh, chÃºng ta láº¥y máº«u ngáº«u nhiÃªn má»™t lÃ´ dá»¯ liá»‡u nhá» Ä‘áº¡i diá»‡n cho bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§. VÃ  lÃ m Ä‘iá»u nÃ y cho nhiá»u bÆ°á»›c cho phÃ©p chÃºng ta xáº¥p xá»‰ bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ khÃ¡ tá»‘t. Tham sá»‘ Batch_Size nÃ y giá»‘ng nhÆ° tham sá»‘ chÃºng ta Ä‘Ã£ tháº£o luáº­n trong vÃ­ dá»¥ Ä‘Æ°á»ng á»‘ng Ä‘áº§u vÃ o TensorFlow. Height and width: ÄÃ¢y lÃ  chiá»u cao vÃ  chiá»u rá»™ng cá»§a Ä‘áº§u vÃ o Chanels: ÄÃ¢y lÃ  Ä‘á»™ sÃ¢u cá»§a Ä‘áº§u vÃ o (vÃ­ dá»¥: Ä‘á»‘i vá»›i hÃ¬nh áº£nh RGB, sá»‘ lÆ°á»£ng kÃªnh sáº½ lÃ  3 kÃªnh, má»™t kÃªnh cho má»—i mÃ u).Bá»™ lá»c: ÄÃ¢y lÃ  má»™t tenxÆ¡ 4D Ä‘áº¡i diá»‡n cho cá»­a sá»• tÃ­ch cháº­p cá»§a hoáº¡t Ä‘á»™ng tÃ­ch cháº­p. KÃ­ch thÆ°á»›c bá»™ lá»c pháº£i lÃ  [height, width, in_channels, out_channels]: Height and width: ÄÃ¢y lÃ  chiá»u cao vÃ  chiá»u rá»™ng cá»§a bá»™ lá»c (thÆ°á»ng nhá» hÆ¡n so vá»›i Ä‘áº§u vÃ o) in_channels: ÄÃ¢y lÃ  sá»‘ lÆ°á»£ng kÃªnh Ä‘áº§u vÃ o cho lá»›p out_channels: ÄÃ¢y lÃ  sá»‘ lÆ°á»£ng kÃªnh Ä‘Æ°á»£c sáº£n xuáº¥t trong Ä‘áº§u ra cá»§a lá»›pstrides: ÄÃ¢y lÃ  danh sÃ¡ch vá»›i bá»‘n yáº¿u tá»‘, trong Ä‘Ã³ cÃ¡c pháº§n tá»­ lÃ  [batch_stride, height_stride, width_stride, channels_stride]. Äá»‘i sá»‘ Strides biá»ƒu thá»‹ cÃ³ bao nhiÃªu pháº§n tá»­ cáº§n bá» qua trong má»™t dá»‹ch chuyá»ƒn cá»§a cá»­a sá»• tÃ­ch cháº­p trÃªn Ä‘áº§u vÃ o. ThÃ´ng thÆ°á»ng, báº¡n khÃ´ng pháº£i lo láº¯ng vá» Batch_Stride vÃ  channels_stride. Náº¿u báº¡n khÃ´ng hoÃ n toÃ n hiá»ƒu strides (bÆ°á»›c tiáº¿n) lÃ  gÃ¬, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh lÃ  1.Padding: ÄÃ¢y cÃ³ thá»ƒ lÃ  má»™t trong sá»‘ [â€˜SAMEâ€™, â€˜VALIDâ€™]. NÃ³ quyáº¿t Ä‘á»‹nh lÃ m tháº¿ nÃ o Ä‘á»ƒ xá»­ lÃ½ hoáº¡t Ä‘á»™ng tÃ­ch cháº­p gáº§n ranh giá»›i cá»§a Ä‘áº§u vÃ o. CÃ¡c hoáº¡t Ä‘á»™ng há»£p lá»‡ (VALID) thá»±c hiá»‡n tÃ­ch cháº­p mÃ  khÃ´ng cáº§n Ä‘á»‡m (padding). Náº¿u chÃºng ta káº¿t há»£p má»™t Ä‘áº§u vÃ o cÃ³ Ä‘á»™ dÃ i n vá»›i má»™t cá»­a sá»• tÃ­ch cháº­p cÃ³ kÃ­ch thÆ°á»›c H, Ä‘iá»u nÃ y sáº½ dáº«n Ä‘áº¿n Ä‘áº§u ra cÃ³ kÃ­ch thÆ°á»›c (N-H+1 &lt;N). Viá»‡c giáº£m kÃ­ch thÆ°á»›c Ä‘áº§u ra cÃ³ thá»ƒ háº¡n cháº¿ nghiÃªm trá»ng Ä‘á»™ sÃ¢u cá»§a máº¡ng lÆ°á»›i tháº§n kinh. SAME thÃªm cÃ¡c sá»‘ 0 Ä‘áº¿n ranh giá»›i sao cho Ä‘áº§u ra sáº½ cÃ³ cÃ¹ng chiá»u cao vÃ  chiá»u rá»™ng vá»›i Ä‘áº§u vÃ o.Äá»ƒ hiá»ƒu rÃµ hÆ¡n vá» kÃ­ch thÆ°á»›c bá»™ lá»c, sáº£i chÃ¢n vÃ  Ä‘á»‡m (filter size, stride, and padding), tham kháº£o hÃ¬nh dÆ°á»›i Pooling operationMá»™t hoáº¡t Ä‘á»™ng gá»™p (pooling operation) hoáº¡t Ä‘á»™ng tÆ°Æ¡ng tá»± nhÆ° hoáº¡t Ä‘á»™ng tÃ­ch cháº­p, nhÆ°ng Ä‘áº§u ra cuá»‘i cÃ¹ng lÃ  khÃ¡c nhau. Thay vÃ¬ xuáº¥t tá»•ng sá»‘ nhÃ¢n cá»§a bá»™ lá»c vÃ  báº£n vÃ¡ hÃ¬nh áº£nh, giá» Ä‘Ã¢y chÃºng ta láº¥y pháº§n tá»­ tá»‘i Ä‘a cá»§a báº£n vÃ¡ hÃ¬nh áº£nh cho vá»‹ trÃ­ Ä‘Ã³.x = tf.constant( [[ [[1],[2],[3],[4]], [[4],[3],[2],[1]], [[5],[6],[7],[8]], [[8],[7],[6],[5]] ]], dtype=tf.float32)x_ksize = [1,2,2,1]x_stride = [1,2,2,1]x_padding = 'VALID'x_pool = tf.nn.max_pool2d( input=x, ksize=x_ksize, strides=x_stride, padding=x_padding)# Returns (out) =&gt; [[[[ 4.],[ 4.]],[[ 8.],[ 8.]]]] Äá»‹nh nghÄ©a máº¥t mÃ¡tChÃºng ta biáº¿t ráº±ng, Ä‘á»‘i vá»›i má»™t máº¡ng lÆ°á»›i tháº§n kinh Ä‘á»ƒ há»c má»™t cÃ¡i gÃ¬ Ä‘Ã³ há»¯u Ã­ch, má»™t máº¥t mÃ¡t cáº§n pháº£i Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh. Sá»± máº¥t mÃ¡t thá»ƒ hiá»‡n má»©c Ä‘á»™ gáº§n hoáº·c xa cÃ¡c dá»± Ä‘oÃ¡n tá»« cÃ¡c má»¥c tiÃªu thá»±c táº¿. CÃ³ má»™t sá»‘ chá»©c nÄƒng Ä‘á»ƒ tá»± Ä‘á»™ng tÃ­nh toÃ¡n tá»•n tháº¥t trong tensorflow, hai trong sá»‘ Ä‘Ã³ Ä‘Æ°á»£c hiá»ƒn thá»‹ trong mÃ£ sau. HÃ m tf.nn.l2_loss lÃ  máº¥t lá»—i bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh (mean squared error loss) vÃ  tf.nn.softmax_cross_entropy_with_logits lÃ  má»™t loáº¡i tá»•n tháº¥t khÃ¡c thá»±c sá»± mang láº¡i hiá»‡u suáº¥t tá»‘t hÆ¡n trong cÃ¡c tÃ¡c vá»¥ phÃ¢n loáº¡i.# Returns half of L2 norm of t given by sum(t**2)/2x = tf.constant([[2,4],[6,8]],dtype=tf.float32)x_hat = tf.constant([[1,2],[3,4]],dtype=tf.float32)# MSE = (1**2 + 2**2 + 3**2 + 4**2)/2 = 15MSE = tf.nn.l2_loss(x-x_hat)y = tf.constant([[1,0],[0,1]],dtype=tf.float32)y_hat = tf.constant([[3,1],[2,5]],dtype=tf.float32)CE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_hat,labels=y)) 5.Keras: API xÃ¢y dá»±ng mÃ´ hÃ¬nh cá»§a TensorflowKeras Ä‘Æ°á»£c phÃ¡t triá»ƒn nhÆ° má»™t thÆ° viá»‡n riÃªng biá»‡t cung cáº¥p cÃ¡c khá»‘i xÃ¢y dá»±ng cáº¥p cao Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh má»™t cÃ¡ch thuáº­n tiá»‡n. Ban Ä‘áº§u nÃ³ há»— trá»£ nhiá»u pháº§n má»m (vÃ­ dá»¥: Tensorflow vÃ  Theano). Tuy nhiÃªn, Tensorflow cÃ³ Ä‘Æ°á»£c Keras vÃ  bÃ¢y giá» lÃ  má»™t pháº§n khÃ´ng thá»ƒ thiáº¿u trong TensorFlow Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh má»™t cÃ¡ch dá»… dÃ ng.Trá»ng tÃ¢m chÃ­nh cá»§a Keras lÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh. VÃ¬ váº­y, Keras cung cáº¥p má»™t sá»‘ API khÃ¡c nhau vá»›i má»©c Ä‘á»™ linh hoáº¡t vÃ  phá»©c táº¡p khÃ¡c nhau. Chá»n API phÃ¹ há»£p cho cÃ´ng viá»‡c sáº½ yÃªu cáº§u kiáº¿n thá»©c há»£p lÃ½ vá» cÃ¡c háº¡n cháº¿ cá»§a má»—i API cÅ©ng nhÆ° kinh nghiá»‡m. CÃ¡c API Ä‘Æ°á»£c cung cáº¥p bá»Ÿi Keras lÃ : API tuáº§n tá»± (Sequential API) : API dá»… sá»­ dá»¥ng nháº¥t. Trong API nÃ y, báº¡n chá»‰ cáº§n xáº¿p cÃ¡c lá»›p lÃªn nhau Ä‘á»ƒ táº¡o má»™t mÃ´ hÃ¬nh. API chá»©c nÄƒng (Functional API) - API chá»©c nÄƒng cung cáº¥p tÃ­nh linh hoáº¡t hÆ¡n báº±ng cÃ¡ch cho phÃ©p báº¡n xÃ¡c Ä‘á»‹nh cÃ¡c mÃ´ hÃ¬nh tÃ¹y chá»‰nh cÃ³ thá»ƒ cÃ³ nhiá»u lá»›p Ä‘áº§u vÃ o/nhiá»u lá»›p Ä‘áº§u ra. API lá»›p phá»¥ (Sub-classing API) : API lá»›p phá»¥ cho phÃ©p báº¡n xÃ¡c Ä‘á»‹nh cÃ¡c lá»›p/ mÃ´ hÃ¬nh cÃ³ thá»ƒ tÃ¡i sá»­ dá»¥ng tÃ¹y chá»‰nh lÃ  cÃ¡c lá»›p Python. ÄÃ¢y lÃ  API linh hoáº¡t nháº¥t, nhÆ°ng nÃ³ Ä‘Ã²i há»i sá»± quen thuá»™c máº¡nh máº½ vá»›i cÃ¡c hoáº¡t Ä‘á»™ng API vÃ  tensorflow thÃ´ Ä‘á»ƒ sá»­ dá»¥ng nÃ³ má»™t cÃ¡ch chÃ­nh xÃ¡cMá»™t trong nhá»¯ng khÃ¡i niá»‡m báº©m sinh nháº¥t trong Keras lÃ  má»™t mÃ´ hÃ¬nh bao gá»“m má»™t hoáº·c nhiá»u lá»›p Ä‘Æ°á»£c káº¿t ná»‘i theo má»™t cÃ¡ch cá»¥ thá»ƒ. á» Ä‘Ã¢y, chÃºng ta sáº½ ngáº¯n gá»n vá» mÃ£ trÃ´ng nhÆ° tháº¿ nÃ o, sá»­ dá»¥ng cÃ¡c API khÃ¡c nhau Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh. Báº¡n khÃ´ng mong Ä‘á»£i hiá»ƒu Ä‘áº§y Ä‘á»§ mÃ£ dÆ°á»›i Ä‘Ã¢y. Thay vÃ o Ä‘Ã³, táº­p trung vÃ o kiá»ƒu mÃ£ Ä‘á»ƒ phÃ¡t hiá»‡n ra báº¥t ká»³ sá»± khÃ¡c biá»‡t nÃ o giá»¯a ba phÆ°Æ¡ng phÃ¡p Sequential APIKhi sá»­ dá»¥ng API tuáº§n tá»±, báº¡n chá»‰ cáº§n xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh cá»§a mÃ¬nh lÃ  danh sÃ¡ch cÃ¡c lá»›p. á» Ä‘Ã¢y, pháº§n tá»­ Ä‘áº§u tiÃªn trong danh sÃ¡ch lÃ  gáº§n nháº¥t vá»›i Ä‘áº§u vÃ o, trong Ä‘Ã³ pháº§n cuá»‘i lÃ  lá»›p Ä‘áº§u ra:model = tf.keras.Sequential([ tf.keras.layers.Dense(500, activation='relu', shape=(784, )), tf.keras.layers.Dense(250, activation='relu'), tf.keras.layers.Dense(10, activation='softmax') ])Trong mÃ£ trÆ°á»›c, chÃºng tÃ´i cÃ³ ba lá»›p. Lá»›p Ä‘áº§u tiÃªn cÃ³ 500 nÃºt Ä‘áº§u ra vÃ  láº¥y má»™t vectÆ¡ gá»“m 784 pháº§n tá»­ lÃ m Ä‘áº§u vÃ o. Lá»›p thá»© hai Ä‘Æ°á»£c tá»± Ä‘á»™ng káº¿t ná»‘i vá»›i lá»›p thá»© nháº¥t, trong khi lá»›p cuá»‘i cÃ¹ng Ä‘Æ°á»£c káº¿t ná»‘i vá»›i lá»›p thá»© hai. Táº¥t cáº£ cÃ¡c lá»›p nÃ y lÃ  cÃ¡c lá»›p Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§, trong Ä‘Ã³ táº¥t cáº£ cÃ¡c nÃºt Ä‘áº§u vÃ o Ä‘Æ°á»£c káº¿t ná»‘i vá»›i táº¥t cáº£ cÃ¡c nÃºt Ä‘áº§u ra. Functional APITrong API chá»©c nÄƒng, chÃºng ta lÃ m má»i thá»© khÃ¡c nhau. TrÆ°á»›c tiÃªn chÃºng ta xÃ¡c Ä‘á»‹nh má»™t hoáº·c nhiá»u lá»›p Ä‘áº§u vÃ o vÃ  cÃ¡c lá»›p khÃ¡c mang tÃ­nh toÃ¡n. Sau Ä‘Ã³, chÃºng tÃ´i káº¿t ná»‘i cÃ¡c Ä‘áº§u vÃ o vá»›i Ä‘áº§u ra, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong mÃ£ sau:inp = tf.keras.layers.Input(shape=(784,))out_1 = tf.keras.layers.Dense(500, activation='relu')(inp)out_2 = tf.keras.layers.Dense(250, activation='relu')(out_1)out = tf.keras.layers.Dense(10, activation='softmax')(out_2)model = tf.keras.models.Model(inputs=inp, outputs=out)Trong mÃ£, chÃºng ta báº¯t Ä‘áº§u vá»›i má»™t lá»›p Ä‘áº§u vÃ o cháº¥p nháº­n vectÆ¡ dÃ i 784 pháº§n tá»­. Äáº§u vÃ o Ä‘Æ°á»£c truyá»n Ä‘áº¿n má»™t lá»›p dÃ y Ä‘áº·c cÃ³ 500 nÃºt. Äáº§u ra cá»§a lá»›p Ä‘Ã³ Ä‘Æ°á»£c gÃ¡n cho out_1. Sau Ä‘Ã³ out_1 Ä‘Æ°á»£c chuyá»ƒn cho má»™t lá»›p dÃ y Ä‘áº·c khÃ¡c, xuáº¥t ra out_2. Tiáº¿p theo, má»™t lá»›p dÃ y Ä‘áº·c vá»›i 10 nÃºt Ä‘áº§u ra Ä‘áº§u ra cuá»‘i cÃ¹ng. Cuá»‘i cÃ¹ng, mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  Ä‘á»‘i tÆ°á»£ng tf.keras.models.Model cÃ³ hai Ä‘á»‘i sá»‘: inputs - má»™t hoáº·c nhiá»u lá»›p Ä‘áº§u vÃ o outputs - má»™t hoáº·c nhiá»u Ä‘áº§u ra Ä‘Æ°á»£c táº¡o bá»Ÿi báº¥t ká»³ tf.keras.layers loáº¡i Ä‘á»‘i tÆ°á»£ngMÃ´ hÃ¬nh giá»‘ng há»‡t vá»›i nhá»¯ng gÃ¬ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong pháº§n trÆ°á»›c. Má»™t trong nhá»¯ng lá»£i Ã­ch cá»§a API chá»©c nÄƒng lÃ  báº¡n cÃ³ thá»ƒ táº¡o cÃ¡c mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n nhiá»u vÃ¬ báº¡n khÃ´ng bá»‹ rÃ ng buá»™c Ä‘á»ƒ cÃ³ cÃ¡c lá»›p nhÆ° má»™t danh sÃ¡ch. VÃ¬ sá»± tá»± do nÃ y, báº¡n cÃ³ thá»ƒ cÃ³ nhiá»u Ä‘áº§u vÃ o káº¿t ná»‘i vá»›i nhiá»u lá»›p theo nhiá»u cÃ¡ch khÃ¡c nhau vÃ  cÃ³ kháº£ nÄƒng táº¡o ra nhiá»u Ä‘áº§u ra. Sub-classing APICuá»‘i cÃ¹ng, chÃºng ta sáº½ sá»­ dá»¥ng API lá»›p phá»¥ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh. Vá»›i lá»›p phá»¥, báº¡n xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh cá»§a mÃ¬nh lÃ  má»™t Ä‘á»‘i tÆ°á»£ng Python káº¿ thá»«a tá»« Ä‘á»‘i tÆ°á»£ng cÆ¡ sá»Ÿ tf.keras.model. Khi sá»­ dá»¥ng lá»›p phá»¥, báº¡n cáº§n xÃ¡c Ä‘á»‹nh hai hÃ m quan trá»ng: __init __ (), sáº½ chá»‰ Ä‘á»‹nh báº¥t ká»³ tham sá»‘, lá»›p Ä‘áº·c biá»‡t nÃ o, vÃ  do Ä‘Ã³ cáº§n thiáº¿t Ä‘á»ƒ thá»±c hiá»‡n thÃ nh cÃ´ng cÃ¡c tÃ­nh toÃ¡n vÃ  hÃ m call() xÃ¡c Ä‘á»‹nh cÃ¡c tÃ­nh toÃ¡n cáº§n pháº£i xáº£y ra trong mÃ´ hÃ¬nh:class MyModel(tf.keras.Model): def __init__(self, num_classes): super().__init__() self.hidden1_layer = tf.keras.layers.Dense(500, activation='relu') self.hidden2_layer = tf.keras.layers.Dense(250, activation='relu') self.final_layer = tf.keras.layers.Dense(num_classes, activation='softmax') def call(self, inputs): h = self.hidden1_layer(inputs) h = self.hidden2_layer(h) y = self.final_layer(h) return ymodel = MyModel(num_classes=10)á» Ä‘Ã¢y, báº¡n cÃ³ thá»ƒ tháº¥y ráº±ng mÃ´ hÃ¬nh cá»§a chÃºng ta cÃ³ ba lá»›p, giá»‘ng nhÆ° táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã³ chÃºng ta Ä‘Ã£ xÃ¡c Ä‘á»‹nh. Tiáº¿p theo, hÃ m call() xÃ¡c Ä‘á»‹nh cÃ¡ch cÃ¡c lá»›p nÃ y káº¿t ná»‘i Ä‘á»ƒ táº¡o ra Ä‘áº§u ra cuá»‘i cÃ¹ng. API lá»›p phá»¥ Ä‘Æ°á»£c coi lÃ  khÃ³ khÄƒn nháº¥t Ä‘á»ƒ lÃ m chá»§, chá»§ yáº¿u lÃ  do sá»± tá»± do. Tuy nhiÃªn, pháº§n thÆ°á»Ÿng lÃ  ráº¥t lá»›n khi báº¡n tÃ¬m hiá»ƒu API vÃ¬ nÃ³ cho phÃ©p báº¡n xÃ¡c Ä‘á»‹nh cÃ¡c mÃ´ hÃ¬nh/lá»›p ráº¥t phá»©c táº¡p lÃ  cÃ¡c tÃ­nh toÃ¡n Ä‘Æ¡n vá»‹ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng láº¡i sau Ä‘Ã³. BÃ¢y giá» báº¡n Ä‘Ã£ hiá»ƒu cÃ¡ch má»—i API hoáº¡t Ä‘á»™ng, hÃ£y Ä‘á»ƒ thá»±c hiá»‡n má»™t máº¡ng lÆ°á»›i tháº§n kinh báº±ng cÃ¡ch sá»­ dá»¥ng Keras vÃ  Ä‘Ã o táº¡o nÃ³ trÃªn má»™t bá»™ dá»¯ liá»‡u. 6.Thá»±c hiá»‡n máº¡ng neural network Ä‘áº§u tiÃªn cá»§a chÃºng taMá»™t trong nhá»¯ng bÆ°á»›c Ä‘á»‡m Ä‘á»ƒ giá»›i thiá»‡u cÃ¡c máº¡ng tháº§n kinh lÃ  triá»ƒn khai má»™t máº¡ng lÆ°á»›i tháº§n kinh cÃ³ kháº£ nÄƒng phÃ¢n loáº¡i cÃ¡c chá»¯ sá»‘. Äá»‘i vá»›i nhiá»‡m vá»¥ nÃ y, chÃºng tÃ´i sáº½ sá»­ dá»¥ng bá»™ dá»¯ liá»‡u MNIST ná»•i tiáº¿ng Ä‘Æ°á»£c cung cáº¥p táº¡i http://yann.lecun.com/exdb/mnist/.Báº¡n cÃ³ thá»ƒ cáº£m tháº¥y má»™t chÃºt hoÃ i nghi vá» viá»‡c chÃºng ta sá»­ dá»¥ng nhiá»‡m vá»¥ táº§m nhÃ¬n mÃ¡y tÃ­nh hÆ¡n lÃ  má»™t nhiá»‡m vá»¥ NLP. Tuy nhiÃªn, cÃ¡c nhiá»‡m vá»¥ táº§m nhÃ¬n cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n vá»›i Ã­t tiá»n xá»­ lÃ½ hÆ¡n vÃ  dá»… hiá»ƒu.VÃ¬ Ä‘Ã¢y lÃ  cuá»™c gáº·p gá»¡ Ä‘áº§u tiÃªn cá»§a chÃºng ta vá»›i cÃ¡c máº¡ng tháº§n kinh, chÃºng ta sáº½ tháº¥y cÃ¡ch thá»±c hiá»‡n mÃ´ hÃ¬nh nÃ y báº±ng cÃ¡ch sá»­ dá»¥ng Keras. Keras lÃ  mÃ´ hÃ¬nh con cáº¥p cao cung cáº¥p má»™t lá»›p trá»«u tÆ°á»£ng qua tensorflow. Do Ä‘Ã³, báº¡n cÃ³ thá»ƒ triá»ƒn khai cÃ¡c máº¡ng tháº§n kinh vá»›i Ã­t ná»— lá»±c hÆ¡n vá»›i Keras hÆ¡n lÃ  sá»­ dá»¥ng cÃ¡c hoáº¡t Ä‘á»™ng thÃ´ cá»§a TensorFlow. Chuáº©n bá»‹ dá»¯ liá»‡uÄáº§u tiÃªn, chÃºng ta cáº§n táº£i xuá»‘ng bá»™ dá»¯ liá»‡u. TensorFlow cung cáº¥p cÃ¡c chá»©c nÄƒng thuáº­n tiá»‡n Ä‘á»ƒ táº£i xuá»‘ng dá»¯ liá»‡u vÃ  MNIST lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c há»— trá»£ Ä‘Ã³. ChÃºng tÃ´i sáº½ thá»±c hiá»‡n bá»‘n bÆ°á»›c quan trá»ng trong quÃ¡ trÃ¬nh chuáº©n bá»‹ dá»¯ liá»‡u: Táº£i xuá»‘ng dá»¯ liá»‡u vÃ  lÆ°u trá»¯ nÃ³ dÆ°á»›i dáº¡ng cÃ¡c Ä‘á»‘i tÆ°á»£ng numpy.ndarray. Äá»‹nh hÃ¬nh láº¡i cÃ¡c hÃ¬nh áº£nh Ä‘á»ƒ hÃ¬nh áº£nh thang Ä‘á»™ xÃ¡m 2D trong bá»™ dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh vectÆ¡ 1D. TiÃªu chuáº©n hÃ³a cÃ¡c hÃ¬nh áº£nh cÃ³ trung bÃ¬nh khÃ´ng vÃ  Ä‘Æ¡n vá»‹ (zero-mean and unit-variance) (cÃ²n Ä‘Æ°á»£c gá»i lÃ  lÃ m tráº¯ng). One-hot encoding nhÃ£n lá»›p sá»‘ nguyÃªn. MÃ£ hÃ³a má»™t láº§n Ä‘á» cáº­p Ä‘áº¿n quÃ¡ trÃ¬nh biá»ƒu diá»…n nhÃ£n lá»›p sá»‘ nguyÃªn dÆ°á»›i dáº¡ng vectÆ¡. VÃ­ dá»¥: náº¿u báº¡n cÃ³ 10 lá»›p vÃ  nhÃ£n lá»›p 3 (trong Ä‘Ã³ cÃ¡c nhÃ£n náº±m trong khoáº£ng tá»« 0-9), vectÆ¡ Ä‘Æ°á»£c mÃ£ hÃ³a má»™t láº§n nÃ³ng (One-hot encoding) cá»§a báº¡n sáº½ lÃ  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0 , 0].MÃ£ sau Ä‘Ã¢y thá»±c hiá»‡n cÃ¡c chá»©c nÄƒng nÃ y cho chÃºng tÃ´i:os.makedirs('data', exist_ok=True)(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data( path=os.path.join(os.getcwd(), 'data', 'mnist.npz'))# Reshaping x_train and x_test tensors so that each image is represented# as a 1D vectorx_train = x_train.reshape(x_train.shape[0], -1)x_test = x_test.reshape(x_test.shape[0], -1)# Standardizing x_train and x_test tensorsx_train = ( x_train - np.mean(x_train, axis=1, keepdims=True))/np.std(x_train, axis=1, keepdims=True)x_test = ( x_test - np.mean(x_test, axis=1, keepdims=True))/np.std(x_test, axis=1, keepdims=True)# One hot encoding y_train and y_testy_onehot_train = np.zeros((y_train.shape[0], num_labels),dtype=np.float32)y_onehot_train[np.arange(y_train.shape[0]), y_train] = 1.0y_onehot_test = np.zeros((y_test.shape[0], num_labels), dtype=np.float32)y_onehot_test[np.arange(y_test.shape[0]), y_test] = 1.0Báº¡n cÃ³ thá»ƒ tháº¥y ráº±ng chÃºng ta Ä‘ang sá»­ dá»¥ng chá»©c nÄƒng tf.keras.datasets.mnist.load_data() do TensorFlow cung cáº¥p Ä‘á»ƒ táº£i xuá»‘ng dá»¯ liá»‡u Ä‘Ã o táº¡o vÃ  kiá»ƒm tra. Äiá»u nÃ y sáº½ cung cáº¥p bá»‘n tensors Ä‘áº§u ra- x_train - Má»™t tensor cÃ³ kÃ­ch thÆ°á»›c 60000 x 28 x 28 trong Ä‘Ã³ má»—i hÃ¬nh áº£nh lÃ  28 x 28- y_train - Má»™t vectÆ¡ cÃ³ kÃ­ch thÆ°á»›c 60000, trong Ä‘Ã³ má»—i pháº§n tá»­ lÃ  má»™t nhÃ£n lá»›p tá»« 0-9 - x_test - Tensor cÃ³ kÃ­ch thÆ°á»›c 10000 x 28 x 28 - y_test - VectÆ¡ cÃ³ kÃ­ch thÆ°á»›c 10000Khi dá»¯ liá»‡u Ä‘Æ°á»£c táº£i xuá»‘ng, chÃºng ta Ä‘á»‹nh hÃ¬nh láº¡i hÃ¬nh áº£nh cÃ³ kÃ­ch thÆ°á»›c 28 x 28 thÃ nh má»™t vectÆ¡ 1D. Äiá»u nÃ y lÃ  do chÃºng ta sáº½ triá»ƒn khai má»™t máº¡ng lÆ°á»›i tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§. CÃ¡c máº¡ng tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§ láº¥y má»™t vectÆ¡ 1D lÃ m Ä‘áº§u vÃ o. Do Ä‘Ã³, táº¥t cáº£ cÃ¡c pixel trong hÃ¬nh áº£nh sáº½ Ä‘Æ°á»£c sáº¯p xáº¿p nhÆ° má»™t chuá»—i cÃ¡c pixel Ä‘á»ƒ Ä‘Æ°a vÃ o mÃ´ hÃ¬nh. Cuá»‘i cÃ¹ng, náº¿u báº¡n nhÃ¬n vÃ o pháº¡m vi cá»§a cÃ¡c giÃ¡ trá»‹ cÃ³ trong cÃ¡c tensor X_Train vÃ  X_Test, chÃºng sáº½ náº±m trong pháº¡m vi 0-255 (pháº¡m vi thang Ä‘á»™ xÃ¡m Ä‘iá»ƒn hÃ¬nh). ChÃºng ta sáº½ Ä‘Æ°a cÃ¡c giÃ¡ trá»‹ nÃ y vÃ o pháº¡m vi phÆ°Æ¡ng sai Ä‘Æ¡n vá»‹ trung bÃ¬nh báº±ng khÃ´ng báº±ng cÃ¡ch trá»« trung bÃ¬nh cá»§a má»—i hÃ¬nh áº£nh vÃ  chia cho Ä‘á»™ lá»‡ch chuáº©n. Triá»ƒn khai neural network vá»›i KerasMáº¡ng tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§ vá»›i 3 lá»›p cÃ³ 500, 250 vÃ  10 nÃºt tÆ°Æ¡ng á»©ng. Hai lá»›p Ä‘áº§u tiÃªn sáº½ sá»­ dá»¥ng kÃ­ch hoáº¡t Relu, trong khi lá»›p cuá»‘i cÃ¹ng sá»­ dá»¥ng SoftMax. Äá»ƒ thá»±c hiá»‡n Ä‘iá»u nÃ y, chÃºng tÃ´i sáº½ sá»­ dá»¥ng cÃ¡c API KERAS Ä‘Æ¡n giáº£n nháº¥t cÃ³ sáºµn cho chÃºng ta - API tuáº§n tá»±.model = tf.keras.Sequential([ tf.keras.layers.Dense(500, activation='relu'), tf.keras.layers.Dense(250, activation='relu'), tf.keras.layers.Dense(10, activation='softmax') ])Báº¡n cÃ³ thá»ƒ tháº¥y ráº±ng táº¥t cáº£ nhá»¯ng gÃ¬ nÃ³ cáº§n lÃ  má»™t dÃ²ng duy nháº¥t trong API tuáº§n tá»± Keras Ä‘á»ƒ xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh mÃ  chÃºng ta vá»«a xÃ¡c Ä‘á»‹nh. Keras cung cáº¥p nhiá»u loáº¡i lá»›p khÃ¡c nhau. Báº¡n cÃ³ thá»ƒ tháº¥y danh sÃ¡ch Ä‘áº§y Ä‘á»§ cÃ¡c lá»›p cÃ³ sáºµn cho báº¡n táº¡i https://www.tensorflow.org/api_docs/python/tf/keras/layers. Äá»‘i vá»›i má»™t máº¡ng Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§, chÃºng ta chá»‰ cáº§n cÃ¡c lá»›p dÃ y Ä‘áº·c báº¯t chÆ°á»›c cÃ¡c tÃ­nh toÃ¡n cá»§a má»™t lá»›p áº©n trong má»™t máº¡ng Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§. Vá»›i mÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh, báº¡n cáº§n biÃªn dá»‹ch mÃ´ hÃ¬nh nÃ y vá»›i chá»©c nÄƒng tá»•n tháº¥t phÃ¹ há»£p, trÃ¬nh tá»‘i Æ°u hÃ³a vÃ  hiá»‡u suáº¥t:optimizer = tf.keras.optimizers.RMSprop()loss_fn = tf.keras.losses.CategoricalCrossentropy()model.compile(optimizer=optimizer, loss=loss_fn, metrics=['acc'])Vá»›i mÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh vÃ  biÃªn dá»‹ch, giá» Ä‘Ã¢y chÃºng ta cÃ³ thá»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh cá»§a mÃ¬nh trÃªn dá»¯ liá»‡u Ä‘Ã£ chuáº©n bá»‹. Training the modelÄÃ o táº¡o má»™t mÃ´ hÃ¬nh khÃ´ng thá»ƒ dá»… dÃ ng hÆ¡n vá»›i Keras. Khi dá»¯ liá»‡u Ä‘Æ°á»£c chuáº©n bá»‹, táº¥t cáº£ nhá»¯ng gÃ¬ báº¡n cáº§n lÃ m lÃ  gá»i hÃ m model.fit () vá»›i cÃ¡c Ä‘á»‘i sá»‘ cáº§n thiáº¿t:batch_size = 100num_epochs = 10train_history = model.fit( x=x_train, y=y_onehot_train, batch_size=batch_size, epochs= num_epochs, validation_split=0.2)model.fit () cháº¥p nháº­n má»™t sá»‘ Ä‘á»‘i sá»‘ quan trá»ng. ChÃºng ta sáº½ Ä‘i qua chÃºng chi tiáº¿t hÆ¡n á»Ÿ Ä‘Ã¢y: X - Má»™t tenxÆ¡ Ä‘áº§u vÃ o. Trong trÆ°á»ng há»£p cá»§a chÃºng ta, Ä‘Ã¢y lÃ  má»™t tenxÆ¡ cÃ³ kÃ­ch thÆ°á»›c 60000 x 784. Y - NhÃ£n Ä‘Æ°á»£c mÃ£ hÃ³a má»™t láº§n nÃ³ng (one-hot encoded). Trong trÆ°á»ng há»£p cá»§a chÃºng ta, Ä‘Ã¢y lÃ  má»™t tenxÆ¡ cÃ³ kÃ­ch thÆ°á»›c 60000 x 10. batch_size - CÃ¡c mÃ´ hÃ¬nh há»c táº­p sÃ¢u Ä‘Æ°á»£c Ä‘Ã o táº¡o vá»›i cÃ¡c lÃ´ dá»¯ liá»‡u (nÃ³i cÃ¡ch khÃ¡c, má»™t cÃ¡ch ngáº«u nhiÃªn) trÃ¡i ngÆ°á»£c vá»›i viá»‡c cung cáº¥p cho bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ cÃ¹ng má»™t lÃºc. KÃ­ch thÆ°á»›c lÃ´ xÃ¡c Ä‘á»‹nh cÃ³ bao nhiÃªu vÃ­ dá»¥ Ä‘Æ°á»£c bao gá»“m trong má»™t lÃ´. KÃ­ch thÆ°á»›c lÃ´ cÃ ng lá»›n, Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh cá»§a báº¡n sáº½ cÃ ng tá»‘t. Epochs - CÃ¡c mÃ´ hÃ¬nh há»c táº­p sÃ¢u láº·p láº¡i thÃ´ng qua bá»™ dá»¯ liá»‡u theo cÃ¡c lÃ´ nhiá»u láº§n. Sá»‘ láº§n láº·p láº¡i thÃ´ng qua bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c gá»i lÃ  sá»‘ lÆ°á»£ng ká»· nguyÃªn. Trong vÃ­ dá»¥ cá»§a chÃºng ta, Ä‘iá»u nÃ y Ä‘Æ°á»£c Ä‘áº·t thÃ nh 10. validation_split - Khi Ä‘Ã o táº¡o cÃ¡c mÃ´ hÃ¬nh há»c táº­p sÃ¢u, má»™t bá»™ xÃ¡c nháº­n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ theo dÃµi hiá»‡u suáº¥t, trong Ä‘Ã³ bá»™ xÃ¡c thá»±c hoáº¡t Ä‘á»™ng nhÆ° má»™t proxy cho hiá»‡u suáº¥t trong tháº¿ giá»›i thá»±c. validation_split xÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m táº­p há»£p con xÃ¡c thá»±c. Trong vÃ­ dá»¥ cá»§a chÃºng ta, Ä‘iá»u nÃ y Ä‘Æ°á»£c Ä‘áº·t thÃ nh 20% tá»•ng kÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡uá» Ä‘Ã¢y, nhá»¯ng gÃ¬ training loss vÃ  validation accuracy trÃ´ng giá»‘ng nhÆ° sá»‘ lÆ°á»£ng ká»· nguyÃªn mÃ  chÃºng ta Ä‘Ã£ Ä‘Ã o táº¡o mÃ´ hÃ¬nhTiáº¿p theo lÃ  kiá»ƒm tra mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i trÃªn má»™t sá»‘ dá»¯ liá»‡u chÆ°a tá»«ng tháº¥y Kiá»ƒm tra modelKiá»ƒm tra mÃ´ hÃ¬nh cÅ©ng Ä‘Æ¡n giáº£n. Trong quÃ¡ trÃ¬nh thá»­ nghiá»‡m, chÃºng ta Ä‘o lÆ°á»ng sá»± máº¥t mÃ¡t vÃ  Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trÃªn bá»™ dá»¯ liá»‡u thá»­ nghiá»‡m. Äá»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn bá»™ dá»¯ liá»‡u, cÃ¡c mÃ´ hÃ¬nh Keras cung cáº¥p chá»©c nÄƒng thuáº­n tiá»‡n gá»i lÃ  evaluate():test_res = model.evaluate( x=x_test, y=y_onehot_test, batch_size=batch_size)CÃ¡c Ä‘á»‘i sá»‘ Ä‘Æ°á»£c mong Ä‘á»£i bá»Ÿi hÃ m evaluate() Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» cáº­p trong quÃ¡ trÃ¬nh tháº£o luáº­n cá»§a chÃºng ta vá» model.fit (): X - má»™t tenxÆ¡ Ä‘áº§u vÃ o. Trong trÆ°á»ng há»£p cá»§a chÃºng ta, Ä‘Ã¢y lÃ  má»™t tenxÆ¡ cÃ³ kÃ­ch thÆ°á»›c 10000 x 784. Y - NhÃ£n Ä‘Æ°á»£c mÃ£ hÃ³a má»™t láº§n nÃ³ng. Trong trÆ°á»ng há»£p cá»§a chÃºng ta, Ä‘Ã¢y lÃ  má»™t tensor kÃ­ch thÆ°á»›c 10000 x 10. Batch_size - KÃ­ch thÆ°á»›c lÃ´ xÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng vÃ­ dá»¥ Ä‘Æ°á»£c bao gá»“m trong má»™t lÃ´. KÃ­ch thÆ°á»›c lÃ´ cÃ ng lá»›n thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh cá»§a báº¡n sáº½ cÃ ng tá»‘tBáº¡n sáº½ bá»‹ loss 0,138 vÃ  Ä‘á»™ chÃ­nh xÃ¡c lÃ  98%. Báº¡n sáº½ khÃ´ng nháº­n Ä‘Æ°á»£c cÃ¡c giÃ¡ trá»‹ chÃ­nh xÃ¡c giá»‘ng nhau do sá»± ngáº«u nhiÃªn khÃ¡c nhau trong mÃ´ hÃ¬nh, cÅ©ng nhÆ° trong quÃ¡ trÃ¬nh Ä‘Ã o táº¡o III.Word2vec 1.Giá»›i thiá»‡uWord2vec lÃ  má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n vÃ  ná»•i tiáº¿ng giÃºp táº¡o ra cÃ¡c biá»ƒu diá»…n embedding cá»§a tá»« trong má»™t khÃ´ng gian cÃ³ sá»‘ chiá»u tháº¥p hÆ¡n nhiá»u láº§n so vá»›i sá»‘ tá»« trong tá»« Ä‘iá»ƒn.Ã tÆ°á»Ÿng cÆ¡ báº£n cá»§a word2vec cÃ³ thá»ƒ Ä‘Æ°á»£c gÃ³i gá»n trong cÃ¡c Ã½ sau: Hai tá»« xuáº¥t hiá»‡n trong nhá»¯ng vÄƒn cáº£nh giá»‘ng nhau thÆ°á»ng cÃ³ Ã½ nghÄ©a gáº§n vá»›i nhau. Ta cÃ³ thá»ƒ Ä‘oÃ¡n Ä‘Æ°á»£c má»™t tá»« náº¿u biáº¿t cÃ¡c tá»« xung quanh nÃ³ trong cÃ¢u. VÃ­ dá»¥, vá»›i cÃ¢u â€œHÃ  Ná»™i lÃ  â€¦ cá»§a Viá»‡t Namâ€ thÃ¬ tá»« trong dáº¥u ba cháº¥m kháº£ nÄƒng cao lÃ  â€œthá»§ Ä‘Ã´â€. Vá»›i cÃ¢u hoÃ n chá»‰nh â€œHÃ  Ná»™i lÃ  thá»§ Ä‘Ã´ cá»§a Viá»‡t Namâ€, mÃ´ hÃ¬nh word2vec sáº½ xÃ¢y dá»±ng ra embeding cá»§a cÃ¡c tá»« sao cho xÃ¡c suáº¥t Ä‘á»ƒ tá»« trong dáº¥u ba cháº¥m lÃ  â€œthá»§ Ä‘Ã´â€ lÃ  cao nháº¥t. 2.Má»™t vÃ i Ä‘á»‹nh nghÄ©aTrong vÃ­ dá»¥ trÃªn Ä‘Ã¢y, tá»« â€œthá»§ Ä‘Ã´â€ Ä‘ang Ä‘Æ°á»£c xÃ©t vÃ  Ä‘Æ°á»£c gá»i lÃ  target word hay tá»« Ä‘Ã­ch. Nhá»¯ng tá»« xung quanh nÃ³ Ä‘Æ°á»£c gá»i lÃ  context words hay tá»« ngá»¯ cáº£nh. Vá»›i má»—i tá»« Ä‘Ã­ch trong má»™t cÃ¢u cá»§a cÆ¡ sá»Ÿ dá»¯ liá»‡u, cÃ¡c tá»« ngá»¯ cáº£nh Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  cÃ¡c tá»« trong cÃ¹ng cÃ¢u cÃ³ vá»‹ trÃ­ cÃ¡ch tá»« Ä‘Ã­ch má»™t khoáº£ng khÃ´ng quÃ¡ C/2 vá»›i C lÃ  má»™t sá»‘ tá»± nhiÃªn dÆ°Æ¡ng. NhÆ° váº­y, vá»›i má»—i tá»« Ä‘Ã­ch, ta sáº½ cÃ³ má»™t bá»™ khÃ´ng quÃ¡ C tá»« ngá»¯ cáº£nh.XÃ©t vÃ­ dá»¥ sau Ä‘Ã¢y vá»›i cÃ¢u tiáº¿ng Anh: â€œThe quick brown fox jump over the lazy dogâ€ vá»›i C=4.Khi â€œtheâ€ lÃ  tá»« Ä‘Ã­ch, ta cÃ³ cáº·p dá»¯ liá»‡u huáº¥n luyá»‡n lÃ  (the, quick) vÃ  (the, brown). Khi â€œbrownâ€ lÃ  tá»« Ä‘Ã­ch, ta cÃ³ cáº·p dá»¯ liá»‡u huáº¥n luyá»‡n lÃ  (brown, the), (brown, quick), (brown, fox) vÃ  (brown, jumps).Word2vec Ä‘á»‹nh nghÄ©a hai embedding vector cÃ¹ng chiá»u cho má»—i tá»« w trong tá»« Ä‘iá»ƒn. Khi nÃ³ lÃ  má»™t tá»« Ä‘Ã­ch, embedding vector cá»§a nÃ³ lÃ  u; khi nÃ³ lÃ  má»™t tá»« ngá»¯ cáº£nh, embedding cá»§a nÃ³ lÃ  v. Sá»Ÿ dÄ© ta cáº§n hai embedding khÃ¡c nhau vÃ¬ Ã½ nghÄ©a cá»§a tá»« Ä‘Ã³ khi nÃ³ lÃ  tá»« Ä‘Ã­ch vÃ  tá»« ngá»¯ cáº£nh lÃ  khÃ¡c nhau. TÆ°Æ¡ng á»©ng vá»›i Ä‘Ã³, ta cÃ³ hai ma tráº­n embedding U vÃ  V cho cÃ¡c tá»« Ä‘Ã­ch vÃ  cÃ¡c tá»« ngá»¯ cáº£nh.CÃ³ hai cÃ¡ch khÃ¡c nhau xÃ¢y dá»±ng mÃ´ hÃ¬nh word2vec: Skip-gram: Dá»± Ä‘oÃ¡n nhá»¯ng tá»« ngá»¯ cáº£nh náº¿u biáº¿t trÆ°á»›c tá»« Ä‘Ã­ch. CBOW (Continuous Bag of Words): Dá»±a vÃ o nhá»¯ng tá»« ngá»¯ cáº£nh Ä‘á»ƒ dá»± Ä‘oÃ¡n tá»« Ä‘Ã­ch. Má»—i cÃ¡ch cÃ³ nhá»¯ng Æ°u nhÆ°á»£c Ä‘iá»ƒm khÃ¡c nhau vÃ  Ã¡p dá»¥ng vá»›i nhá»¯ng loáº¡i dá»¯ liá»‡u khÃ¡c nhau. 3.Skip-gramMÃ´ hÃ¬nh skip-gram liÃªn tá»¥c há»c báº±ng cÃ¡ch dá»± Ä‘oÃ¡n cÃ¡c tá»« xung quanh Ä‘Æ°á»£c Ä‘Æ°a ra má»™t tá»« hiá»‡n táº¡i. NÃ³i cÃ¡ch khÃ¡c, MÃ´ hÃ¬nh Skip-Gram liÃªn tá»¥c dá»± Ä‘oÃ¡n cÃ¡c tá»« trong má»™t pháº¡m vi nháº¥t Ä‘á»‹nh trÆ°á»›c vÃ  sau tá»« hiá»‡n táº¡i trong cÃ¹ng má»™t cÃ¢u.skip-gram dá»± Ä‘oÃ¡n ngá»¯ cáº£nh hoáº·c cÃ¡c tá»« lÃ¢n cáº­n cho má»™t tá»« nháº¥t Ä‘á»‹nh. MÃ´ hÃ¬nh Skip-Gram Ä‘Æ°á»£c Ä‘Ã o táº¡o trÃªn cÃ¡c cáº·p n-gram (target_word, context_word) vá»›i mÃ£ thÃ´ng bÃ¡o lÃ  1 vÃ  0. MÃ£ thÃ´ng bÃ¡o chá»‰ Ä‘á»‹nh xem context_words Ä‘áº¿n tá»« cÃ¹ng má»™t cá»­a sá»• hay Ä‘Æ°á»£c táº¡o ngáº«u nhiÃªn. Cáº·p cÃ³ mÃ£ thÃ´ng bÃ¡o 0 bá»‹ bá» qua. MÃ£ triá»ƒn khai mÃ´ hÃ¬nh Skip-GramCÃ¡c bÆ°á»›c cáº§n tuÃ¢n theo: XÃ¢y dá»±ng vá»‘n tá»« vá»±ng corpus XÃ¢y dá»±ng trÃ¬nh táº¡o skip-gram [(má»¥c tiÃªu, ngá»¯ cáº£nh), má»©c Ä‘á»™ liÃªn quan] XÃ¢y dá»±ng kiáº¿n trÃºc mÃ´ hÃ¬nh skip-gram ÄÃ o táº¡o mÃ´ hÃ¬nh Nháº­n nhÃºng Word 1. XÃ¢y dá»±ng vá»‘n tá»« vá»±ng corpus:BÆ°á»›c thiáº¿t yáº¿u trong khi xÃ¢y dá»±ng báº¥t ká»³ mÃ´ hÃ¬nh dá»±a trÃªn NLP nÃ o lÃ  táº¡o ra má»™t kho tÃ i liá»‡u trong Ä‘Ã³ chÃºng tÃ´i trÃ­ch xuáº¥t tá»«ng tá»« duy nháº¥t tá»« vá»±ng vÃ  gÃ¡n má»™t sá»‘ nháº­n dáº¡ng duy nháº¥t cho nÃ³.Kho tÆ° liá»‡u chÃºng ta Ä‘ang sá»­ dá»¥ng lÃ  â€˜The King James Version of the Bibleâ€™, tá»« Dá»± Ã¡n Gutenberg, cÃ³ sáºµn miá»…n phÃ­ thÃ´ng qua mÃ´ hÃ¬nh corpus trong nltk.from nltk.corpus import gutenberg # to get bible corpusfrom string import punctuation # to remove punctuation from corpusimport nltk import numpy as npfrom keras.preprocessing import textfrom keras.preprocessing.sequence import skipgrams from keras.layers import *from keras.layers.core import Dense, Reshapefrom keras.layers.embeddings import Embeddingfrom keras.models import Model,Sequential nltk.download('gutenberg')nltk.download('punkt')nltk.download('stopwords')# english lÃ  ngÃ´n ngá»¯ báº¡n chá»nstop_words = nltk.corpus.stopwords.words('english')QuÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u sang má»™t thá»© mÃ  mÃ¡y tÃ­nh cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c gá»i lÃ  tiá»n xá»­ lÃ½. Má»™t trong nhá»¯ng hÃ¬nh thá»©c xá»­ lÃ½ trÆ°á»›c chÃ­nh lÃ  lá»c ra nhá»¯ng dá»¯ liá»‡u vÃ´ dá»¥ng. Trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, nhá»¯ng tá»« vÃ´ Ã­ch (dá»¯ liá»‡u), Ä‘Æ°á»£c gá»i lÃ  nhá»¯ng tá»« dá»«ng(stop words). Tá»« dá»«ng lÃ  má»™t tá»« thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng (cháº³ng háº¡n nhÆ° â€œtheâ€, â€œaâ€, â€œanâ€, â€œinâ€) mÃ  cÃ´ng cá»¥ tÃ¬m kiáº¿m Ä‘Ã£ Ä‘Æ°á»£c láº­p trÃ¬nh Ä‘á»ƒ bá» qua.ChÃºng ta sá»­ dá»¥ng chá»©c nÄƒng do ngÆ°á»i dÃ¹ng xÃ¡c Ä‘á»‹nh Ä‘á»ƒ xá»­ lÃ½ sÆ¡ bá»™ vÄƒn báº£n giÃºp loáº¡i bá» cÃ¡c khoáº£ng tráº¯ng, chá»¯ sá»‘, tá»« dá»«ng vÃ  viáº¿t táº¯t thÃ¢n vÄƒn báº£nimport rebible = gutenberg.sents(\"bible-kjv.txt\")remove_terms = punctuation + '0123456789'wpt = nltk.WordPunctTokenizer()def normalize_document(doc): # lower case and remove special characters\\whitespaces doc = re.sub(r'[^a-zA-Z\\s]', '', doc,re.I|re.A) doc = doc.lower() doc = doc.strip() # tokenize document tokens = wpt.tokenize(doc) # filter stopwords out of document filtered_tokens = [token for token in tokens if token not in stop_words] # re-create document from filtered tokens doc = ' '.join(filtered_tokens) return docnormalize_corpus = np.vectorize(normalize_document)" }, { "title": "Biáº¿n tool cá»§a báº¡n thÃ nh package cÃ³ thá»ƒ cÃ i Ä‘áº·t qua pip", "url": "/posts/Bi%E1%BA%BFn-tool-c%E1%BB%A7a-b%E1%BA%A1n-th%C3%A0nh-package-c%C3%B3-th%E1%BB%83-c%C3%A0i-%C4%91%E1%BA%B7t-qua-pip/", "categories": "Python, Pypi", "tags": "pypi, package, github", "date": "2022-09-23 00:00:00 +0700", "snippet": "NhÆ° tiÃªu Ä‘á» bÃ i viáº¿t, bÃ i post nÃ y ghi láº¡i quÃ¡ trÃ¬nh tÃ´i xuáº¥t báº£n má»™t cÃ´ng cá»¥ cÃ¡ nhÃ¢n báº±ng python code Ä‘áº¿n cá»™ng Ä‘á»“ng, má»i ngÆ°á»i cÃ³ thá»ƒ sá»­ dá»¥ng nÃ³ vá»›i viá»‡c â€œpip install packageâ€ .Vui lÃ²ng Ä‘á»£i, tÃ´i sáº½ hoÃ n thiá»‡n nÃ³ ngay khi cÃ³ Ä‘á»§ thá»i gian.Báº¡n cÃ³ thá»ƒ tÃ¬m tháº¥y nÃ³ á»Ÿ Ä‘Ã¢y https://pypi.org/project/test-package-tlqb/" }, { "title": "PhÃ¢n loáº¡i Ã¢m thanh (P2)", "url": "/posts/Ph%C3%A2n-lo%E1%BA%A1i-%C3%A2m-thanh-(P2)/", "categories": "Python, Machine-learning", "tags": "ML, AI", "date": "2022-09-22 00:00:00 +0700", "snippet": "KhÃ¡i niá»‡m cÆ¡ báº£n vá» phÃ¢n loáº¡i Ã¢m thanhDáº¡ng sÃ³ng (Waveform)Ã‚m thanh lÃ  nhá»¯ng dao Ä‘á»™ng do má»™t váº­t táº¡o ra khi cÃ¡c pháº§n tá»­ khÃ´ng khÃ­ xung quanh dao Ä‘á»™ng. Ã‚m thanh lÃ  má»™t sÃ³ng cÆ¡ há»c, nÆ¡i nÄƒng lÆ°á»£ng Ä‘Æ°á»£c truyá»n tá»« nguá»“n nÃ y sang nguá»“n khÃ¡c. Dáº¡ng sÃ³ng lÃ  má»™t biá»ƒu diá»…n giáº£n Ä‘á»“ giÃºp chÃºng ta phÃ¢n tÃ­ch sá»± dá»‹ch chuyá»ƒn cá»§a sÃ³ng Ã¢m thanh theo thá»i gian, cÃ¹ng vá»›i má»™t sá»‘ tham sá»‘ thiáº¿t yáº¿u khÃ¡c cáº§n thiáº¿t cho má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ.Máº·t khÃ¡c, táº§n sá»‘ á»Ÿ dáº¡ng sÃ³ng lÃ  Ä‘áº¡i diá»‡n cá»§a sá»‘ láº§n má»™t dáº¡ng sÃ³ng láº·p láº¡i chÃ­nh nÃ³ trong khoáº£ng thá»i gian má»™t giÃ¢y. Äá»‰nh cá»§a dáº¡ng sÃ³ng á»Ÿ trÃªn cÃ¹ng Ä‘Æ°á»£c gá»i lÃ  Ä‘á»‰nh, trong khi Ä‘iá»ƒm dÆ°á»›i cÃ¹ng Ä‘Æ°á»£c gá»i lÃ  Ä‘Ã¡y. BiÃªn Ä‘á»™ lÃ  khoáº£ng cÃ¡ch tá»« Ä‘Æ°á»ng tÃ¢m Ä‘áº¿n Ä‘á»‰nh cá»§a mÃ¡ng hoáº·c Ä‘Ã¡y cá»§a Ä‘á»‰nh.Quang phá»• (Spectrograms)Quang phá»• lÃ  má»™t biá»ƒu diá»…n trá»±c quan cá»§a phá»• táº§n sá»‘ cá»§a má»™t tÃ­n hiá»‡u khi nÃ³ thay Ä‘á»•i theo thá»i gian. Khi Ä‘Æ°á»£c Ã¡p dá»¥ng cho má»™t tÃ­n hiá»‡u Ã¢m thanh , cÃ¡c báº£n ghi quang phá»• Ä‘Ã´i khi Ä‘Æ°á»£c gá»i lÃ  báº£n ghi Ã¢mDá»± Ã¡n PhÃ¢n loáº¡i Ã‚m thanhBáº±ng cÃ¡ch chuyá»ƒn Ä‘á»•i dáº¡ng sÃ³ng thÃ´ cá»§a dá»¯ liá»‡u Ã¢m thanh thÃ nh dáº¡ng quang phá»•, chÃºng ta cÃ³ thá»ƒ chuyá»ƒn nÃ³ qua cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u Ä‘á»ƒ giáº£i thÃ­ch vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u.Trong dá»± Ã¡n nÃ y, má»¥c tiÃªu lÃ  thu láº¡i Ã¢m thanh phÃ¡t ra tá»« má»™t con chim. Khi Ä‘Ã£ thu Ä‘Æ°á»£c thÃ nh cÃ´ng dáº¡ng sÃ³ng, chÃºng ta cÃ³ thá»ƒ tiáº¿n hÃ nh chuyá»ƒn dáº¡ng sÃ³ng nÃ y thÃ nh má»™t biá»ƒu Ä‘á»“ quang phá»•, Ä‘Ã¢y lÃ  biá»ƒu diá»…n trá»±c quan cá»§a dáº¡ng sÃ³ng cÃ³ sáºµn. VÃ¬ nhá»¯ng hÃ¬nh áº£nh phá»• nÃ y lÃ  hÃ¬nh áº£nh trá»±c quan, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng máº¡ng nÆ¡-ron tÃ­ch tá»¥ Ä‘á»ƒ phÃ¢n tÃ­ch chÃºng cho phÃ¹ há»£p báº±ng cÃ¡ch táº¡o mÃ´ hÃ¬nh há»c sÃ¢u Ä‘á»ƒ tÃ­nh toÃ¡n káº¿t quáº£ phÃ¢n loáº¡i nhá»‹ phÃ¢nThá»±c hiá»‡n dá»± Ã¡n Nháº­n dáº¡ng vÃ  PhÃ¢n loáº¡i Ã‚m thanh vá»›i Há»c sÃ¢u:Má»¥c tiÃªu cá»§a dá»± Ã¡n lÃ  Ä‘á»c Ã¢m thanh Ä‘áº¿n tá»« má»™t khu rá»«ng vÃ  giáº£i thÃ­ch xem dá»¯ liá»‡u nháº­n Ä‘Æ°á»£c thuá»™c vá» má»™t loÃ i chim cá»¥ thá»ƒ (chim mÅ© lÆ°á»¡i trai) hay lÃ  má»™t sá»‘ tiáº¿ng á»“n khÃ¡c mÃ  ta khÃ´ng thá»±c sá»± quan tÃ¢m Ä‘áº¿n viá»‡c ghi nháº­n.ThÆ° viá»‡n TensorFlow-io, sáº½ cáº¥p cho ta quyá»n truy cáº­p vÃ o cÃ¡c há»‡ thá»‘ng tá»‡p vÃ  Ä‘á»‹nh dáº¡ng tá»‡p khÃ´ng cÃ³ sáºµn trong há»— trá»£ tÃ­ch há»£p cá»§a TensorFlow!pip install tensorflow-io[tensorflow]Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿timport tensorflow as tf from tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2D, Dense, Flattenimport tensorflow_io as tfiofrom matplotlib import pyplot as pltimport osTáº£i dataset: https://www.kaggle.com/datasets/kenjee/z-by-hp-unlocked-challenge-3-signal-processingCÃ³ ba thÆ° má»¥c trong thÆ° má»¥c data. Ba thÆ° má»¥c cá»¥ thá»ƒ lÃ  cÃ¡c báº£n ghi Ã¢m trong rá»«ng chá»©a má»™t Ä‘oáº¡n clip dÃ i ba phÃºt vá» Ã¢m thanh Ä‘Æ°á»£c táº¡o ra trong rá»«ng, Ä‘oáº¡n clip dÃ i ba giÃ¢y vá» cÃ¡c báº£n ghi Ã¢m cá»§a chim Capuchin vÃ  Ä‘oáº¡n ghi Ã¢m dÃ i ba giÃ¢y vá» Ã¢m thanh khÃ´ng do chim Capuchin táº¡o raCAPUCHIN_FILE = os.path.join('data', 'Parsed_Capuchinbird_Clips', 'XC3776-3.wav')NOT_CAPUCHIN_FILE = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips', 'afternoon-birds-song-in-forest-0.wav')HÃ m Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong Ä‘oáº¡n mÃ£ dÆ°á»›i Ä‘Ã¢y sáº½ cho phÃ©p ta Ä‘á»c dá»¯ liá»‡u vÃ  chuyá»ƒn Ä‘á»•i nÃ³ thÃ nh má»™t kÃªnh Ä‘Æ¡n (hoáº·c Ä‘Æ¡n) Ä‘á»ƒ phÃ¢n tÃ­ch dá»… dÃ ng hÆ¡nHÃ m tf.squeeze() tráº£ vá» má»™t tensor cÃ³ cÃ¹ng giÃ¡ trá»‹ vá»›i Ä‘á»‘i sá»‘ Ä‘áº§u tiÃªn cá»§a nÃ³, nhÆ°ng cÃ³ hÃ¬nh dáº¡ng khÃ¡c. NÃ³ loáº¡i bá» cÃ¡c thá»© nguyÃªn cÃ³ kÃ­ch thÆ°á»›c lÃ  má»™tdef load_wav_16k_mono(filename): # Load encoded wav file file_contents = tf.io.read_file(filename) # Decode wav (tensors by channels) wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1) # Removes trailing axis wav = tf.squeeze(wav, axis=-1) sample_rate = tf.cast(sample_rate, dtype=tf.int64) # Goes from 44100Hz to 16000hz - amplitude of the audio signal wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000) return wavChuáº©n bá»‹ táº­p dá»¯ liá»‡uNhÃ£n 1: tiáº¿ng chim CapuchinNhÃ£n 0: tÃ­n hiá»‡u Ã¢m thanh nhiá»…utf.data.Dataset.list_file: Ä‘á»ƒ quÃ©t táº¥t cáº£ cÃ¡c pháº§n tá»­ thÆ° má»¥c data# Defining the positive and negative pathsPOS = os.path.join('data', 'Parsed_Capuchinbird_Clips/*.wav')NEG = os.path.join('data', 'Parsed_Not_Capuchinbird_Clips/*.wav')# Creating the Datasetspos = tf.data.Dataset.list_files(POS)neg = tf.data.Dataset.list_files(NEG)# Adding labelspositives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))data = positives.concatenate(negatives)PhÃ¢n tÃ­ch bÆ°á»›c sÃ³ng trung bÃ¬nh cá»§a chim Capuchin# Analyzing the average wavelength of a Capuchin birdlengths = []for file in os.listdir(os.path.join('data', 'Parsed_Capuchinbird_Clips')): tensor_wave = load_wav_16k_mono(os.path.join('data', 'Parsed_Capuchinbird_Clips', file)) lengths.append(len(tensor_wave))from statistics import meanmean(lengths)wav = load_wav_16k_mono('data/Parsed_Capuchinbird_Clips/XC22397-2.wav')wav = wav[:48000]zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)wav = tf.concat([zero_padding, wav],0)spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)spectrogram = tf.abs(spectrogram)spectrogram = tf.expand_dims(spectrogram, axis=2)Thu tháº­p táº¥t cáº£ cÃ¡c dáº¡ng sÃ³ng vÃ  tÃ­nh toÃ¡n TÃ­n hiá»‡u Biáº¿n Ä‘á»•i Fourier trong thá»i gian ngáº¯n vá»›i thÆ° viá»‡n TensorFlow Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c má»™t biá»ƒu diá»…n trá»±c quandef preprocess(file_path, label): wav = load_wav_16k_mono(file_path) wav = wav[:48000] zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32) wav = tf.concat([zero_padding, wav],0) spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32) spectrogram = tf.abs(spectrogram) spectrogram = tf.expand_dims(spectrogram, axis=2) return spectrogram, label filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()spectrogram, label = preprocess(filepath, label)XÃ¢y dá»±ng mÃ´ hÃ¬nh há»c sÃ¢uTáº£i cÃ¡c pháº§n tá»­ dá»¯ liá»‡u chÆ°Æ¡ng trÃ¬nh quang phá»• thu Ä‘Æ°á»£c tá»« chá»©c nÄƒng bÆ°á»›c tiá»n xá»­ lÃ½ vÃ  lÆ°u vÃ o bá»™ nhá»› cache vÃ  xÃ¡o trá»™n dá»¯ liá»‡u nÃ y báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c chá»©c nÄƒng cÃ³ sáºµn cá»§a TensorFlow, cÅ©ng nhÆ° táº¡o kÃ­ch thÆ°á»›c lÃ´ gá»“m mÆ°á»i sÃ¡u Ä‘á»ƒ táº£i cÃ¡c pháº§n tá»­ dá»¯ liá»‡u cho phÃ¹ há»£p.tf.data.Dataset.map(): Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chuyá»ƒn Ä‘á»•i cÃ¡c má»¥c trong táº­p dá»¯ liá»‡uSá»­ dá»¥ng tf.data.Dataset.cache()thá»±c sá»± khÃ´ng pháº£i lÃ  má»™t lá»±a chá»n tá»‘t vÃ¬ nÃ³ sáº½ lÆ°u toÃ n bá»™ táº­p dá»¯ liá»‡u vÃ o bá»™ nhá»›, Ä‘iá»u nÃ y gÃ¢y máº¥t thá»i gian vÃ  cÃ³ thá»ƒ lÃ m trÃ n bá»™ nhá»› cá»§a báº¡nshuffle( buffer_size, seed=None, reshuffle_each_iteration=None) PhÆ°Æ¡ng phÃ¡p xÃ¡o trá»™n cÃ¡c máº«u trong táº­p dá»¯ liá»‡u. Buffer_size lÃ  sá»‘ lÆ°á»£ng máº«u Ä‘Æ°á»£c láº¥y ngáº«u nhiÃªn vÃ  tráº£ vá» dÆ°á»›i dáº¡ng tf.Dataset.batch(batch_size,drop_remainder=False)Táº¡o cÃ¡c lÃ´ cá»§a táº­p dá»¯ liá»‡u vá»›i kÃ­ch thÆ°á»›c lÃ´ Ä‘Æ°á»£c cung cáº¥p vÃ¬ batch_size cÅ©ng lÃ  Ä‘á»™ dÃ i cá»§a cÃ¡c lÃ´.Ngay sau khi táº¥t cáº£ cÃ¡c má»¥c Ä‘Æ°á»£c Ä‘á»c tá»« táº­p dá»¯ liá»‡u vÃ  báº¡n cá»‘ Ä‘á»c pháº§n tá»­ tiáº¿p theo, táº­p dá»¯ liá»‡u sáº½ gáº·p lá»—i. ÄÃ³ lÃ  nÆ¡i ds.repeat() phÃ¡t huy tÃ¡c dá»¥ng. NÃ³ sáº½ khá»Ÿi táº¡o láº¡i táº­p dá»¯ liá»‡uHáº§u háº¿t cÃ¡c Ä‘Æ°á»ng á»‘ng Ä‘áº§u vÃ o cá»§a táº­p dá»¯ liá»‡u pháº£i káº¿t thÃºc báº±ng má»™t lá»‡nh gá»i Ä‘áº¿n prefetch. Äiá»u nÃ y cho phÃ©p cÃ¡c pháº§n tá»­ sau nÃ y Ä‘Æ°á»£c chuáº©n bá»‹ trong khi pháº§n tá»­ hiá»‡n táº¡i Ä‘ang Ä‘Æ°á»£c xá»­ lÃ½. Äiá»u nÃ y thÆ°á»ng cáº£i thiá»‡n Ä‘á»™ trá»… vÃ  thÃ´ng lÆ°á»£ng, vá»›i chi phÃ­ sá»­ dá»¥ng bá»™ nhá»› bá»• sung Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c pháº§n tá»­ tÃ¬m náº¡p trÆ°á»›c.# Creating a Tensorflow Data Pipelinedata = data.map(preprocess)data = data.cache()data = data.shuffle(buffer_size=1000)data = data.batch(16)data = data.prefetch(8)TrÆ°á»›c khi tiáº¿n hÃ nh xÃ¢y dá»±ng mÃ´ hÃ¬nh há»c sÃ¢u, ta cÃ³ thá»ƒ táº¡o phÃ¢n vÃ¹ng cho cÃ¡c máº«u thá»­ nghiá»‡m vÃ  Ä‘Ã o táº¡o, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong Ä‘oáº¡n mÃ£ bÃªn dÆ°á»›i.# Split into Training and Testing Partitionstrain = data.take(36)test = data.skip(36).take(15)# Ä‘á»™ dÃ i cá»§a táº­p dá»¯ liá»‡utf.data.experimental.cardinality(train)# hiá»ƒn thá»‹ shape cá»§a tf.Tensorfor i in train: print(i)XÃ¢y dá»±ng mÃ´ hÃ¬nh kiá»ƒu tuáº§n tá»±XÃ¢y dá»±ng hai khá»‘i lá»›p cháº­p vá»›i mÆ°á»i sÃ¡u bá»™ lá»c vÃ  kÃ­ch thÆ°á»›c háº¡t nhÃ¢n lÃ  (3, 3)Chá»©c nÄƒng kÃ­ch hoáº¡t ReLU Ä‘Æ°á»£c sá»­ dá»¥ng trong viá»‡c xÃ¢y dá»±ng cÃ¡c lá»›p tÃ­ch tá»¥.Sau Ä‘Ã³, chÃºng ta cÃ³ thá»ƒ tiáº¿n hÃ nh lÃ m pháº³ng Ä‘áº§u ra thu Ä‘Æ°á»£c tá»« cÃ¡c lá»›p tÃ­ch tá»¥ Ä‘á»ƒ lÃ m cho nÃ³ phÃ¹ há»£p cho quÃ¡ trÃ¬nh xá»­ lÃ½ tiáº¿p theo.Cuá»‘i cÃ¹ng, chÃºng ta cÃ³ thá»ƒ thÃªm cÃ¡c lá»›p Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§ vá»›i chá»©c nÄƒng kÃ­ch hoáº¡t Sigmoid vá»›i má»™t nÃºt Ä‘áº§u ra Ä‘á»ƒ nháº­n Ä‘áº§u ra phÃ¢n loáº¡i nhá»‹ phÃ¢n.model = Sequential()model.add(Conv2D(16, (3,3), activation='relu', input_shape=(1491, 257,1)))model.add(Conv2D(16, (3,3), activation='relu'))model.add(Flatten())# model.add(Dense(128, activation='relu'))model.add(Dense(1, activation='sigmoid'))model.summary()Äá»ƒ biÃªn dá»‹ch mÃ´ hÃ¬nh, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng trÃ¬nh tá»‘i Æ°u hÃ³a Adam, hÃ m máº¥t mÃ¡t entropy chÃ©o nhá»‹ phÃ¢n Ä‘á»ƒ phÃ¢n loáº¡i nhá»‹ phÃ¢n vÃ  xÃ¡c Ä‘á»‹nh má»™t sá»‘ sá»‘ liá»‡u thu há»“i vÃ  Ä‘á»™ chÃ­nh xÃ¡c bá»• sung cho phÃ¢n tÃ­ch mÃ´ hÃ¬nh.# Compiling and fitting the modelmodel.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])model.fit(train, epochs=4, validation_data=test)model.save('mymodel.h5')from keras.models import load_modelmodel = load_model('mymodel.h5')ÄÆ°a ra cÃ¡c Dá»± Ä‘oÃ¡n# Prediction for a single batchX_test, y_test = test.as_numpy_iterator().next()yhat = model.predict(X_test)# converting logits to classesyhat = [1 if prediction &gt; 0.5 else 0 for prediction in yhat]HÃ m bÃªn dÆ°á»›i nháº­n Ä‘áº§u vÃ o Ä‘á»‹nh dáº¡ng mp3 vÃ  chuyá»ƒn Ä‘á»•i chÃºng thÃ nh tensor. Sau Ä‘Ã³, ta tÃ­nh giÃ¡ trá»‹ trung bÃ¬nh cá»§a Ä‘áº§u vÃ o Ä‘a kÃªnh Ä‘á»ƒ chuyá»ƒn nÃ³ thÃ nh kÃªnh Ä‘Æ¡n vÃ  thu Ä‘Æ°á»£c tÃ­n hiá»‡u táº§n sá»‘ mong muá»‘n.def load_mp3_16k_mono(filename): \"\"\" Load an audio file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\" res = tfio.audio.AudioIOTensor(filename) # Convert to tensor and combine channels tensor = res.to_tensor() tensor = tf.math.reduce_sum(tensor, axis=1) / 2 # Extract sample rate and cast sample_rate = res.rate sample_rate = tf.cast(sample_rate, dtype=tf.int64) # Resample to 16 kHz wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000) return wav mp3 = os.path.join('data', 'Forest Recordings', 'recording_00.mp3')wav = load_mp3_16k_mono(mp3)audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)samples, index = audio_slices.as_numpy_iterator().next()Ta sáº½ xÃ¢y dá»±ng má»™t hÃ m giÃºp tÃ¡ch cÃ¡c phÃ¢n Ä‘oáº¡n riÃªng láº» thÃ nh cÃ¡c báº£n Ä‘á»“ quang phá»• cÃ³ cá»­a sá»• Ä‘á»ƒ tÃ­nh toÃ¡n thÃªm. Ta sáº½ Ã¡nh xáº¡ dá»¯ liá»‡u phÃ¹ há»£p vÃ  táº¡o cÃ¡c lÃ¡t cáº¯t thÃ­ch há»£p Ä‘á»ƒ Ä‘Æ°a ra cÃ¡c dá»± Ä‘oÃ¡n cáº§n thiáº¿t# Build Function to Convert Clips into Windowed Spectrogramsdef preprocess_mp3(sample, index): sample = sample[0] zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32) wav = tf.concat([zero_padding, sample],0) spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32) spectrogram = tf.abs(spectrogram) spectrogram = tf.expand_dims(spectrogram, axis=2) return spectrogramaudio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=16000, sequence_stride=16000, batch_size=1)audio_slices = audio_slices.map(preprocess_mp3)#audio_slices = audio_slices.batch(64)audio_slices = audio_slices.batch(32)yhat = model.predict(audio_slices)yhat = [1 if prediction &gt; 0.5 else 0 for prediction in yhat]Ta sáº½ cháº¡y quy trÃ¬nh sau cho táº¥t cáº£ cÃ¡c tá»‡p trong báº£n ghi rá»«ng vÃ  thu Ä‘Æ°á»£c tá»•ng káº¿t quáº£ Ä‘Æ°á»£c tÃ­nh toÃ¡n. Káº¿t quáº£ sáº½ chá»©a cÃ¡c Ä‘oáº¡n sá»‘ khÃ´ng vÃ  cÃ¡c Ä‘oáº¡n trong Ä‘Ã³ tá»•ng sá»‘ cÃ¡c sá»‘ Ä‘Ã³ Ä‘Æ°á»£c xuáº¥t ra Ä‘á»ƒ tÃ­nh Ä‘iá»ƒm tá»•ng thá»ƒ cá»§a cÃ¡c Ä‘oáº¡n clip. ChÃºng ta cÃ³ thá»ƒ tÃ¬m ra tá»•ng sá»‘ tiáº¿ng kÃªu cá»§a chim Capuchin trong báº£n ghi Ã¢m theo yÃªu cáº§u cá»§a dá»± Ã¡nresults = {}class_preds = {}for file in os.listdir(os.path.join('data', 'Forest Recordings')): FILEPATH = os.path.join('data','Forest Recordings', file) wav = load_mp3_16k_mono(FILEPATH) audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1) audio_slices = audio_slices.map(preprocess_mp3) audio_slices = audio_slices.batch(64) yhat = model.predict(audio_slices) results[file] = yhat for file, logits in results.items(): class_preds[file] = [1 if prediction &gt; 0.99 else 0 for prediction in logits]class_preds" }, { "title": "TÃ´i Ä‘Ã£ táº¡o ra má»™t blog nhÆ° tháº¿ nÃ o vá»›i github page", "url": "/posts/T%C3%B4i-%C4%91%C3%A3-t%E1%BA%A1o-ra-m%E1%BB%99t-blog-nh%C6%B0-th%E1%BA%BF-n%C3%A0o-v%E1%BB%9Bi-github-page/", "categories": "web, blog", "tags": "github page, web, blog", "date": "2022-09-21 00:00:00 +0700", "snippet": "NhÆ° tiÃªu Ä‘á» bÃ i viáº¿t, bÃ i post ghi láº¡i quÃ¡ trÃ¬nh tÃ´i táº¡o ra má»™t blog cÃ¡ nhÃ¢n vá»›i github page vÃ  jekyll.SÆ¡ lÆ°á»£cGiá»›i thiá»‡uNhÆ° cÃ¡c báº¡n Ä‘Ã£ biáº¿t website cÃ²n gá»i lÃ  trang web lÃ  táº­p há»£p cÃ¡c trang chá»©a thÃ´ng tin bao gá»“m vÄƒn báº£n, hÃ¬nh áº£nh, video,â€¦ náº±m trÃªn má»™t domain, Ä‘Æ°á»£c lÆ°u trá»¯ trÃªn mÃ¡y chá»§ web, vÃ­ dá»¥ vá» website nhÆ° (vietnix.vn, google.com, facebook.com).Website Ä‘Æ°á»£c xem lÃ  cÃ´ng cá»¥ há»— trá»£ Ä‘áº¯c lá»±c cho hoáº¡t Ä‘á»™ng Marketing online, gÃ³p pháº§n quáº£ng bÃ¡ rá»™ng rÃ£i hÃ¬nh áº£nh doanh nghiá»‡p, quáº£ng cÃ¡o sáº£n pháº©m, dá»‹ch vá»¥ Ä‘áº¿n khÃ¡ch hÃ ng nhanh chÃ³ng giÃºp xÃ¢y dá»±ng thÆ°Æ¡ng hiá»‡u, táº¡o dá»±ng sá»± uy tÃ­n, Ä‘á»“ng thá»i nÃ¢ng cao sá»©c máº¡nh cáº¡nh tranh cho cÃ¡c Ä‘Æ¡n vá»‹ kinh doanh trÃªn thá»‹ trÆ°á»ng.Hiá»‡n táº¡i cÃ³ ráº¥t nhiá»u cÃ¡ch Ä‘á»ƒ táº¡o 1 trang web (cho ngÆ°á»i khÃ´ng biáº¿t láº­p trÃ¬nh cho Ä‘áº¿n cÃ¡c ;láº­p trÃ¬nh viÃªn chuyÃªn nghiá»‡p) nhÆ° Wordpress,Wix,Python django, Ruby on rails â€¦ Trong bÃ i viáº¿t nÃ y, tÃ´i muá»‘n giá»›i thiá»‡u Ä‘áº¿n cÃ¡c báº¡n má»™t cÃ¡ch Ä‘Æ¡n giáº£n hÆ¡n (cho cÃ¡c báº¡n biáº¿t má»™t tÃ½ vá» láº­p trÃ¬nh) Ä‘Ã³ lÃ  blog vá»›i github page vÃ  jekyll.Má»¥c tiÃªu bÃ i viáº¿t Cung cáº¥p kiáº¿n thá»©c Ä‘áº§y Ä‘á»§ vá» viá»‡c thiáº¿t láº­p cÆ¡ báº£n cho Ä‘áº¿n táº¡o ra má»™t web vá»›i Ä‘áº§y Ä‘á»§ chá»©c nÄƒng. Ghi láº¡i quÃ¡ trÃ¬nh lÃ m viá»‡c vÃ  há»c táº­p trÃªn ná»n táº£ng nÃ y. CÃ¡c liÃªn káº¿t tham kháº£o https://pages.github.com/ https://viblo.asia/p/dung-jekyll-travis-va-github-pages-de-tao-ra-muon-van-trang-web-de-dang-Qbq5QWp3ZD8 https://github.com/cotes2020/chirpy-starter Táº¡o blog Vá»›i cÃ¡c trang GitHub, GitHub cho phÃ©p báº¡n lÆ°u trá»¯ má»™t trang web tá»« kho lÆ°u trá»¯ cá»§a mÃ¬nh. Khá»Ÿi táº¡o repositories Truy cáº­p vÃ o https://github.com/topics/jekyll-plugin vÃ  chá»n má»™t template báº¡n yÃªu thÃ­ch tá»« jekelyy. Trong bÃ i nÃ y tÃ´i chá»n template https://github.com/cotes2020/chirpy-starter. Fork repositories vÃ  Ä‘áº·t tÃªn láº¡i .github.io *Fork repositories tá»« chirpy-starter. *Äáº·t tÃªn láº¡i repositpries. *Káº¿t quáº£. CÃ i Ä‘áº·tUbuntu CÃ i Ä‘áº·t Ruby vÃ  cÃ¡c Ä‘iá»u kiá»‡n tiÃªn quyáº¿t khÃ¡c : sudo apt-get install ruby-full build-essential zlib1g-dev echo '# Install Ruby Gems to ~/gems' &gt;&gt; ~/.bashrcecho 'export GEM_HOME=\"$HOME/gems\"' &gt;&gt; ~/.bashrcecho 'export PATH=\"$HOME/gems/bin:$PATH\"' &gt;&gt; ~/.bashrcsource ~/.bashrc gem install jekyll bundler Config code Clone source code vá» mÃ¡y Ä‘á»ƒ config git clone https://github.com/tlqbao/tlqbao.github.io.git cd tlqbao.github.io.git CÃ i Ä‘áº·t cÃ¡c gÃ³i phá»¥ thuá»™c bundler Run local host bundle exec jekyll s Báº¡n sáº½ tÃ¬m tháº¥y hÆ°á»›ng dáº«n cá»¥ thá»ƒ cho viá»‡c config template nÃ y á»Ÿ https://github.com/cotes2020/jekyll-theme-chirpy#documentation Trong bÃ i viáº¿t nÃ y sáº½ chá»‰ Ä‘á» cáº­p Ä‘áº¿n viá»‡c config nhá»¯ng pháº§n cÆ¡ báº£n, báº¡n cÃ³ thá»ƒ xem vÃ  config sÃ¢u hÆ¡n tÃ¹y Ã½ theo tÃ i liá»‡u.Táº¥t cáº£ cÃ¡c pháº§n tÃ¹y chá»‰nh Ä‘á»u náº±m á»Ÿ file _config.yml Title (line 20). title: vÃ­ dá»¥: title: tlqbao url (line 32) url: â€˜' vÃ­ dá»¥: url: 'https://tlqbao.github.io' timezone (line 19) timezone: Asia/Ho_Chi_Minh tagline (line 26) tagline : &lt;cÃ¢u nÃ³i yÃªu thÃ­ch cá»§a báº¡n hÃ¢y báº¥t cá»© thá»© gÃ¬ Ä‘Ã³ â€¦&gt; Deploy blog Táº¡o commit vÃ  push code git add .git statusgit commit -m \"first config\"git push origin main Config git. Chá»n Settings â€”&gt; Pages. á» Deploy from branch chá»n Github Action. á» Deploy from branch chá»n gh-pages. Káº¿t quáº£: ThÃªm miá»n tÃ¹y chá»‰nhCÃ³ SSL Domain porkbunKhÃ´ng SSL Domain venomTáº¡o bÃ i viáº¿t Ä‘áº§u tiÃªnGiá»›i thiá»‡u ngÃ´n ngá»¯ MaskdownMá»™t sá»‘ syntax cÆ¡ báº£n trong Markdown.Markdown\tHTML\tKáº¿t quáº£| Markdown | HTML | Káº¿t quáº£ ||:â€”â€”-|:â€”â€”:|â€”â€”-:|| # Header 1 | &lt;h1&gt;Header 1&lt;/h1&gt; | Header 1 || ## Header 2 | &lt;h2&gt;Header 2&lt;/h2&gt; | Header 2 || ### Header 3 | &lt;h3&gt;Header 3&lt;/h3&gt; | Header 3 || #### Header 4 | &lt;h4&gt;Header 4&lt;/h4&gt; | Header 4 || ====== | ====== | =====: || Footer | Footer | Footer |CÃ¡c bÆ°á»›c táº¡o bÃ i viáº¿tCÃ¡c lá»—i thÆ°á»ng gáº·p vÃ  cÃ¡ch fix Lá»—i abc Lá»—i xyzTÆ°Æ¡ng lai BÃ i viáº¿t sáº½ liÃªn Ä‘Æ°á»£c cáº­p nháº­t thÆ°á»ng xuyÃªn." }, { "title": "PhÃ¢n loáº¡i Ã¢m thanh (P1)", "url": "/posts/Ph%C3%A2n-lo%E1%BA%A1i-%C3%A2m-thanh-(P1)/", "categories": "Python, Machine-learning", "tags": "ML, AI", "date": "2022-09-20 00:00:00 +0700", "snippet": "CÃ i Ä‘áº·t thÆ° viá»‡nThÆ° viá»‡n há»— trá»£ phÃ¢n tÃ­ch Ã¢m thanh vÃ  Ã¢m nháº¡c lÃ  Librosa!pip install librosa!pip install tensorflowPhÃ¢n tÃ­ch dá»¯ liá»‡uimport IPython.display as ipdfilepath = \"archive/fold1/101415-3-0-2.wav\"ipd.Audio(filepath)VÃ¬ váº­y, khi táº£i báº¥t ká»³ tá»‡p Ã¢m thanh nÃ o báº±ng Librosa, nÃ³ mang láº¡i 2 Ä‘iá»u. Má»™t lÃ  tá»‘c Ä‘á»™ láº¥y máº«u vÃ  má»™t lÃ  máº£ng hai chiá»u Tá»‘c Ä‘á»™ láº¥y máº«u - NÃ³ thá»ƒ hiá»‡n sá»‘ lÆ°á»£ng máº«u Ä‘Æ°á»£c ghi láº¡i má»—i giÃ¢y. Tá»‘c Ä‘á»™ láº¥y máº«u máº·c Ä‘á»‹nh mÃ  librosa Ä‘á»c tá»‡p lÃ  22050 Máº£ng 2-D - Trá»¥c Ä‘áº§u tiÃªn Ä‘áº¡i diá»‡n cho cÃ¡c biÃªn Ä‘á»™ máº«u Ä‘Ã£ ghi. VÃ  trá»¥c thá»© hai Ä‘áº¡i diá»‡n cho sá»‘ lÆ°á»£ng kÃªnh. CÃ³ nhiá»u loáº¡i kÃªnh khÃ¡c nhau - ÄÆ¡n Ã¢m (Ã¢m thanh cÃ³ má»™t kÃªnh) vÃ  Ã¢m thanh ná»•i (Ã¢m thanh cÃ³ hai kÃªnh). !pip install matplotlibimport librosaimport librosa.displayimport matplotlib.pyplot as pltdata, sample_rate = librosa.load(filepath)plt.figure(figsize=(12, 5))librosa.display.waveshow(data, sr=sample_rate)Librosa hiá»‡n Ä‘ang trá»Ÿ nÃªn phá»• biáº¿n Ä‘á»ƒ xá»­ lÃ½ tÃ­n hiá»‡u Ã¢m thanh vÃ¬ ba lÃ½ do sau. NÃ³ cá»‘ gáº¯ng há»™i tá»¥ tÃ­n hiá»‡u thÃ nh mono (má»™t kÃªnh). NÃ³ cÃ³ thá»ƒ Ä‘áº¡i diá»‡n cho tÃ­n hiá»‡u Ã¢m thanh tá»« -1 Ä‘áº¿n +1 (á»Ÿ dáº¡ng chuáº©n hÃ³a), do Ä‘Ã³, má»™t máº«u thÃ´ng thÆ°á»ng Ä‘Æ°á»£c quan sÃ¡t. NÃ³ cÅ©ng cÃ³ thá»ƒ xem tá»‘c Ä‘á»™ máº«u vÃ  theo máº·c Ä‘á»‹nh, nÃ³ chuyá»ƒn Ä‘á»•i nÃ³ thÃ nh 22 kHz. Kiá»ƒm tra táº­p dá»¯ liá»‡u máº¥t cÃ¢n báº±ng!pip install pandasimport pandas as pdmetadata = pd.read_csv('csv/UrbanSound8K.csv')metadata.head(10)sá»­ dá»¥ng hÃ m Ä‘áº¿m giÃ¡ trá»‹ Ä‘á»ƒ kiá»ƒm tra báº£n ghi cá»§a má»—i lá»›p.metadata['class'].value_counts()!pip install seabornimport seaborn as snsplt.figure(figsize=(10, 6))sns.countplot(metadata['class'])plt.title(\"Count of records in each class\")plt.xticks(rotation=\"vertical\")plt.show()Xá»­ lÃ½ trÆ°á»›c dá»¯ liá»‡uNhiá»‡m vá»¥ lÃ  trÃ­ch xuáº¥t má»™t sá»‘ thÃ´ng tin quan trá»ng vÃ  giá»¯ dá»¯ liá»‡u á»Ÿ dáº¡ng Ä‘á»™c láº­p (CÃ¡c tÃ­nh nÄƒng Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« â€‹â€‹tÃ­n hiá»‡u Ã¢m thanh) vÃ  cÃ¡c tÃ­nh nÄƒng phá»¥ thuá»™c (nhÃ£n lá»›p).Sá»­ dá»¥ng Mel Frequency Cepstral coefficients Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c tÃ­nh nÄƒng Ä‘á»™c láº­p tá»« tÃ­n hiá»‡u Ã¢m thanhMFCC tÃ³m táº¯t sá»± phÃ¢n bá»‘ táº§n sá»‘ trÃªn kÃ­ch thÆ°á»›c cá»­a sá»•. VÃ¬ váº­y, cÃ³ thá»ƒ phÃ¢n tÃ­ch cáº£ Ä‘áº·c tÃ­nh táº§n sá»‘ vÃ  thá»i gian cá»§a Ã¢m thanh. Biá»ƒu diá»…n Ã¢m thanh nÃ y sáº½ cho phÃ©p xÃ¡c Ä‘á»‹nh cÃ¡c Ä‘áº·c Ä‘iá»ƒm Ä‘á»ƒ phÃ¢n loáº¡i.mfccs = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40)print(mfccs.shape)print(mfccs)mfccs.shape: https://stackoverflow.com/questions/65206575/what-are-the-components-of-the-mel-mfcc### TrÃ­ch xuáº¥t cÃ¡c tÃ­nh nÄƒng tá»« táº¥t cáº£ cÃ¡c tá»‡p Ã¢m thanh vÃ  chuáº©n bá»‹ khung dá»¯ liá»‡u!pip install numpyres_type: strTheo máº·c Ä‘á»‹nh, Ä‘iá»u nÃ y sá»­ dá»¥ng cháº¿ Ä‘á»™ cháº¥t lÆ°á»£ng cao cá»§a resampy (â€˜kaiser_bestâ€™).Äá»ƒ sá»­ dá»¥ng má»™t phÆ°Æ¡ng phÃ¡p nhanh hÆ¡n, hÃ£y Ä‘áº·t res_type = â€˜kaiser_fastâ€™.Äá»ƒ sá»­ dá»¥ng scipy.signal.resample, hÃ£y Ä‘áº·t res_type = â€˜scipyâ€™.import numpy as npdef features_extractor(file_name): audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40) # Ä‘á»ƒ tÃ¬m hiá»ƒu cÃ¡c tÃ­nh nÄƒng Ä‘Æ°á»£c chia tá»· lá»‡, chÃºng ta sáº½ tÃ¬m giÃ¡ trá»‹ trung bÃ¬nh cá»§a sá»± chuyá»ƒn vá»‹ cá»§a má»™t máº£ng mfccs_scaled_features = np.mean(mfccs_features.T,axis=0) return mfccs_scaled_featuresthÆ° viá»‡n python TQDM Ä‘á»ƒ theo dÃµi tiáº¿n trÃ¬nh!pip install tqdmimport numpy as npfrom tqdm import tqdmimport osextracted_features=[]for index_num,row in tqdm(metadata.iterrows()): file_name = os.path.join('archive/fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"])) final_class_labels=row[\"class\"] data=features_extractor(file_name) extracted_features.append([data,final_class_labels])extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])extracted_features_df.head()Train Test splitTÃ¡ch táº­p dá»¯ liá»‡u thÃ nh táº­p dá»¯ liá»‡u Ä‘á»™c láº­p vÃ  phá»¥ thuá»™cX=np.array(extracted_features_df['feature'].tolist())y=np.array(extracted_features_df['class'].tolist())MÃ£ hÃ³a nhÃ£n thÃ nh sá»‘ nguyÃªnfrom tensorflow.keras.utils import to_categoricalfrom sklearn.preprocessing import LabelEncoderlabelencoder=LabelEncoder()y=to_categorical(labelencoder.fit_transform(y))chia dá»¯ liá»‡u thÃ nh cÃ¡c táº­p huáº¥n luyá»‡n vÃ  thá»­ nghiá»‡m theo tá»· lá»‡ 80-20from sklearn.model_selection import train_test_splitX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)Táº¡o mÃ´ hÃ¬nh phÃ¢n loáº¡i Ã¢m thanhANN vá»›i 3 lá»›p dÃ y Ä‘áº·c vÃ  kiáº¿n â€‹â€‹trÃºc: Lá»›p Ä‘áº§u tiÃªn cÃ³ 100 táº¿ bÃ o tháº§n kinh. HÃ¬nh dáº¡ng Ä‘áº§u vÃ o lÃ  40 theo sá»‘ lÆ°á»£ng tÃ­nh nÄƒng cÃ³ chá»©c nÄƒng kÃ­ch hoáº¡t lÃ  Relu vÃ  Ä‘á»ƒ trÃ¡nh báº¥t ká»³ trang bá»‹ quÃ¡ má»©c nÃ o, chÃºng tÃ´i sáº½ sá»­ dá»¥ng lá»›p Dropout vá»›i tá»· lá»‡ 0,5. Lá»›p thá»© hai cÃ³ 200 táº¿ bÃ o tháº§n kinh cÃ³ chá»©c nÄƒng kÃ­ch hoáº¡t lÃ  Relu vÃ  lá»›p Dropout cÃ³ tá»‰ lá»‡ lÃ  0,5. Lá»›p thá»© ba láº¡i cÃ³ 100 táº¿ bÃ o tháº§n kinh vá»›i kÃ­ch hoáº¡t lÃ  Relu vÃ  lá»›p Dropout cÃ³ tá»· lá»‡ lÃ  0,5. from tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Dense,Dropout,Activation,Flattenfrom tensorflow.keras.optimizers import Adamfrom sklearn import metricsnum_labels=y.shape[1]model=Sequential()###first layermodel.add(Dense(100,input_shape=(40,)))model.add(Activation('relu'))model.add(Dropout(0.5))###second layermodel.add(Dense(200))model.add(Activation('relu'))model.add(Dropout(0.5))###third layermodel.add(Dense(100))model.add(Activation('relu'))model.add(Dropout(0.5))###final layermodel.add(Dense(num_labels))model.add(Activation('softmax'))model.summary()BiÃªn dá»‹ch mÃ´ hÃ¬nhÄá»ƒ biÃªn dá»‹ch mÃ´ hÃ¬nh, chÃºng ta cáº§n xÃ¡c Ä‘á»‹nh loss function lÃ  cross-entropy, accuracy metrics lÃ  accuracy score vÃ  optimizer lÃ  Adam.model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')Train modelÄÃ o táº¡o mÃ´ hÃ¬nh vÃ  lÆ°u mÃ´ hÃ¬nh á»Ÿ Ä‘á»‹nh dáº¡ng HDF5.Sá»­ dá»¥ng callback, Ä‘Ã¢y lÃ  má»™t Ä‘iá»ƒm kiá»ƒm tra Ä‘á»ƒ biáº¿t cáº§n bao nhiÃªu thá»i gian Ä‘á»ƒ Ä‘Ã o táº¡o qua dá»¯ liá»‡u.Báº±ng cÃ¡ch Ä‘áº·t verbose = 0, 1 hoáº·c 2, Ä‘á»ƒ â€˜xemâ€™ tiáº¿n trÃ¬nh Ä‘Ã o táº¡o cho má»—i ká»· nguyÃªn nhÆ° tháº¿ nÃ o.verbose=0 sáº½ khÃ´ng cho báº¡n tháº¥y gÃ¬ (im láº·ng)verbose=1 sáº½ hiá»ƒn thá»‹ cho báº¡n má»™t thanh tiáº¿n trÃ¬nh progres_barverbose=2 sáº½ chá»‰ Ä‘á» cáº­p Ä‘áº¿n sá»‘ ká»· nguyÃªn: Epoch 1/10 â€¦from tensorflow.keras.callbacks import ModelCheckpointfrom datetime import datetime num_epochs = 100num_batch_size = 32checkpointer = ModelCheckpoint(filepath='./audio_classification.hdf5', verbose=1, save_best_only=True)(xuáº¥t ra cÃ¡c trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh má»—i khi quan sÃ¡t tháº¥y sá»± cáº£i thiá»‡n trong quÃ¡ trÃ¬nh Ä‘Ã o táº¡o.)# checkpoint# filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')# callbacks_list = [checkpoint] (Sá»­ dá»¥ng EarlyStopping cÃ¹ng vá»›i Checkpoint)# checkpoint# from tensorflow.keras.callbacks import EarlyStopping# filepath=\"weights.best.hdf5\"# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')# es = EarlyStopping(monitor='val_accuracy', patience=5)# -&gt;QuÃ¡ trÃ¬nh huáº¥n luyá»‡n nÃ y Ä‘Ã£ dá»«ng láº¡i náº¿u khÃ´ng cÃ³ Ä‘á»™ chÃ­nh xÃ¡c nÃ o Ä‘áº¡t Ä‘Æ°á»£c tá»‘t hÆ¡n trong nÄƒm ká»· nguyÃªn vá»«a qua# callbacks_list = [checkpoint, es]start = datetime.now()model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)duration = datetime.now() - startprint(\"Training completed in time: \", duration)Kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c cá»§a Testtest_accuracy=model.evaluate(X_test,y_test,verbose=0)print(test_accuracy[1])sá»­ dá»¥ng thuá»™c tÃ­nh metrics_names cá»§a mÃ´ hÃ¬nh Ä‘á»ƒ tÃ¬m hiá»ƒu xem má»—i giÃ¡ trá»‹ tráº£ vá» cá»§a model.evaluate tÆ°Æ¡ng á»©ng vá»›i cÃ¡i gÃ¬model.metrics_namesDá»± Ä‘oÃ¡n lá»›p tÆ°Æ¡ng á»©ng cho má»—i tá»‡p Ã¢m thanhpredict_x=model.predict(X_test) classes_x=np.argmax(predict_x,axis=1)print(classes_x)Kiá»ƒm tra má»™t sá»‘ máº«u Ã¢m thanh thá»­ nghiá»‡mfilename=\"archive/fold7/101848-9-0-0.wav\"#preprocess the audio fileaudio, sample_rate = librosa.load(filename, res_type='kaiser_fast') mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)#Reshape MFCC feature to 2-D arraymfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)#predicted_label=model.predict_classes(mfccs_scaled_features)x_predict=model.predict(mfccs_scaled_features) predicted_label=np.argmax(x_predict,axis=1)print(predicted_label)prediction_class = labelencoder.inverse_transform(predicted_label) print(prediction_class)" }, { "title": "Python Kivy | Táº¡o á»©ng dá»¥ng Ä‘iá»‡n thoáº¡i thÃ´ng minh vá»›i Kivy vÃ  Buildozer", "url": "/posts/Python-Kivy-T%E1%BA%A1o-%E1%BB%A9ng-d%E1%BB%A5ng-%C4%91i%E1%BB%87n-tho%E1%BA%A1i-th%C3%B4ng-minh-v%E1%BB%9Bi-Kivy-v%C3%A0-Buildozer/", "categories": "Python, Kivy", "tags": "kivy, mobile app, buildozer", "date": "2022-09-18 00:00:00 +0700", "snippet": "Trong bÃ i viáº¿t nÃ y, chÃºng ta cÃ¹ng tÃ¬m hiá»ƒu vá» framework Kivy, cÃ¡ch xÃ¢y dá»±ng má»™t á»©ng dá»¥ng Ä‘iá»‡n thoáº¡i vá»›i Kivy vÃ  build thÃ nh app android vá»›i buildozer.SÆ¡ lÆ°á»£cGiá»›i thiá»‡u framework djangoMá»¥c tiÃªu bÃ i viáº¿tCÃ¡c liÃªn káº¿t vÃ  nguá»“n tÃ i liá»‡u tham kháº£oCÃ i Ä‘áº·tKhá»Ÿi táº¡o mÃ´i trÆ°á»ngCÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n yÃªu cáº§uá»¨ng dá»¥ng Ä‘áº§u tiÃªná»¨ng dá»¥ng nÃ¢ng caoKhá»Ÿi táº¡o mÃ´i trÆ°á»ng build trÃªn Ubuntu 20.04CÃ¡c thÆ° viá»‡n yÃªu cáº§uThÆ° viá»‡n cáº§n thiáº¿t sudo apt-get install python3-distutils sudo python3 get-pip.py sudo apt-get install -y python3-pip build-essential git python3 python3-dev sudo apt-get install -y libsdl2-dev libsdl2-image-dev libsdl2-mixer-dev libsdl2-ttf-dev libportmidi-dev libswscale-dev libavformat-dev libavcodec-dev zlib1g-dev sudo apt-get install cython sudo pip3 install kivy python3 main.py - code is available sudo apt-get install libltdl-dev libffi-dev libssl-dev autoconf autotools-dev sudo apt install -y git zip unzip openjdk-8-jdk python3-pip autoconf libtool pkg-config zlib1g-dev libncurses5-dev libncursesw5-dev libtinfo5 cmake libffi-dev libssl-dev pip3 install --user --upgrade Cython==0.29.19 virtualenv # the --user should be removed if you do this in a venv ThÃªm dÃ²ng sau vÃ o cuá»‘i tá»‡p ~ / .bashrc cá»§a báº¡n export PATH=$PATH:~/.local/bin/Clone source code buildozer git clone https://github.com/kivy/buildozer.git cd buildozer sudo python3 setup.py install buildozer init buildozer android debugBuild app adroidCÃ¡c lá»—i thÆ°á»ng gáº·p vÃ  cÃ¡ch sá»­aTÆ°Æ¡ng lai*BÃ i viáº¿t sáº½ Ä‘Æ°á»£c cáº­p nháº­t thÆ°á»ng xuyÃªn." }, { "title": "Test post number 2", "url": "/posts/Test-post-number-2/", "categories": "Python, Machine-learning", "tags": "AI, ML", "date": "2022-09-17 00:00:00 +0700", "snippet": "Test thá»­ bÃ i viáº¿t sá»‘ 2" }, { "title": "Python hat - Evil Twin Attack (P.2)", "url": "/posts/Python-hat-Evil-Twin-Attack-(P.2)/", "categories": "Python, Hat", "tags": "hat, wifi", "date": "2022-09-17 00:00:00 +0700", "snippet": "Tiáº¿p ná»‘i bÃ i viáº¿t Táº¥n cÃ´ng máº¡ng vá»›i ngÃ´n ngá»¯ Python pháº§n 1 (DDoS-wifi) ,hÃ´m nay mÃ¬nh chia sáº» pháº§n 2 vá» ká»¹ thuáº­t táº¥n cÃ´ng Wifi báº±ng Ä‘iá»ƒm truy cáº­p giáº£ máº¡o. Äá»ƒ tiá»‡n trong viá»‡c quan sÃ¡t vÃ  thá»±c hÃ nh,cÃ¡c báº¡n cÃ³ thá»ƒ xem video theo link bÃªn dÆ°á»›i.Evil Twin Attack (P.2) - Video." }, { "title": "Python Django | Táº¡o webapp vá»›i framework Django", "url": "/posts/Python-Django-T%E1%BA%A1o-webapp-v%E1%BB%9Bi-framework-Django/", "categories": "Python, Django", "tags": "django, web", "date": "2022-09-17 00:00:00 +0700", "snippet": "Má»™t bÃ i viáº¿t Ä‘áº§y Ä‘á»§ tá»« táº¡o, config, nÃ¢ng cáº¥p vÃ  deploy web lÃªn server trÃªn cÃ¡c ná»n táº£ng khÃ¡c nhau.SÆ¡ lÆ°á»£cGiá»›i thiá»‡u framework django Django lÃ  khung á»©ng dá»¥ng web cho Python Django má»›i nháº¥t há»— trá»£ dÃ²ng python 3Má»¥c tiÃªu bÃ i viáº¿t Cung cáº¥p kiáº¿n thá»©c Ä‘áº§y Ä‘á»§ vá» viá»‡c thiáº¿t láº­p cÆ¡ báº£n cho Ä‘áº¿n táº¡o ra má»™t web cÆ¡ báº£n vá»›i Ä‘áº§y Ä‘á»§ chá»©c nÄƒng. Ghi láº¡i kinh nghiá»‡m hÆ¡n 1 nÄƒm lÃ m viá»‡c vÃ  há»c táº­p trÃªn ná»n táº£ng nÃ y.CÃ¡c liÃªn káº¿t vÃ  nguá»“n tÃ i liá»‡u tham kháº£oTÃ i liá»‡u tá»« Django https://docs.djangoproject.com/en/4.0/TÃ i liá»‡u tá»« geeksforgeeks https://www.geeksforgeeks.org/django-tutorial/TÃ i liá»‡u tá»« tomomano.gitlab.io https://tomomano.gitlab.io/intro-aws/#aws_accountCÃ i Ä‘áº·tKhá»Ÿi táº¡o mÃ´i trÆ°á»ng áº£oViá»‡c khá»Ÿi táº¡o mÃ´i trÆ°á»ng áº£o Ä‘á»ƒ phá»¥c vá»¥ cho project lÃ  cáº§n thiáº¿t, trÃ¡nh sá»± áº£nh hÆ°á»Ÿng tá»« mÃ´i trÆ°á»ng mÃ¡y Ä‘áº¿n project vÃ  ngÆ°á»£c láº¡i. Trong bÃ i viáº¿t nÃ y chá»‰ Ä‘á» cáº­p Ä‘áº¿n mÃ´i trÆ°á»ng áº£o trÃªn ubuntu (trÃªn cÃ¡c há»‡ Ä‘iá»u hÃ nh khÃ¡c sáº½ khÃ´ng Ä‘Æ°á»£c Ä‘á» cáº­p táº¡i Ä‘Ã¢y) CÃ i Ä‘áº·t thÆ° viá»‡n python3-venv sudo apt-get install -y python3-venv Táº¡o folder dá»± Ã¡n mkdir my_project Di chuyá»ƒn cÃ o folder dá»± Ã¡n cd my_project Táº¡o mÃ´i trÆ°á»ng áº£o python -m venv django-env KÃ­ch hoáº·t mÃ´i trÆ°á»ng áº£o source django-env/bin/activate Há»§y kÃ­ch hoáº¡t mÃ´i trÆ°á»ng deactivate CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n yÃªu cáº§uÄá»ƒ thuáº­n tiá»‡n cho quÃ¡ trÃ¬nh thÃªm vÃ  cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n yÃªu cáº§u cáº§n thiáº¿t trong dá»± trÃªn venv chÃºng ta nÃªn táº¡o file requirements.txt. á» Ä‘Ã¢y chÃºng ta khÃ´ng sá»­ dá»¥ng â€œpip freezeâ€ trÃ¡nh trÆ°á»ng há»£p cÃ i quÃ¡ nhiá»u thÆ° viá»‡n khÃ´ng cáº§n thiáº¿t. Táº¡o file requirements.txt touch requirements.txt CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n yÃªu cáº§u trong file requirements.txt pip install -r requirements.txt Táº¡o á»©ng dá»¥ng web django Ä‘áº§u tiÃªn Táº¡o project django-admin startproject web_project Táº¡o web app bÃªn trong project Di chuyá»ƒn vÃ o folder dá»± Ã¡n cd web_project Táº¡o web app python manage.py startapp my_web Cháº¡y thá»­ nghiá»‡m python manage.py runserver TÃ¬m hiá»ƒu vá» mÃ´ hÃ¬nh MVT (Models - View - Templates)TÃ¹y chá»‰nh cÆ¡ báº£nÃp dá»¥ngTáº¡o blog cÃ¡ nhÃ¢nTáº¡o webapp djangoThiáº¿t káº¿ Frontend vá»›i NicepageKáº¿t há»£p django vá»›i templates tá»« nicepageDeloyAWSHerokuNÃ¢ng cáº¥p blogThÃªm gÃ³i ckeditor vÃ o blogThÃªm slug vÃ  tagit vÃ o djangoThÃªm cloudinary lÆ°u trá»¯ bÃªn ngoÃ i herokuThÃªm miá»n tÃ¹y chá»‰nhTáº¡o tÃªn miá»n .tk miá»…n phÃ­Thiáº¿t láº­p tÃªn miá»n miá»…n phÃ­ vÃ  herokuNhá»¯ng lá»—i thÆ°á»ng gáº·p vÃ  cÃ¡ch sá»­aTÆ°Æ¡ng lai BÃ i viáº¿t sáº½ luÃ´n Ä‘Æ°á»£c cáº­p nháº­t thÆ°á»ng xuyÃªn." } ]
