---
title: Tá»•ng quan vá» xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn
author: huynhlevu
date: 2022-09-26
categories: [Python,Machine-learning]
tags: [ML, AI]
math: true
mermaid: true
image:
  path: /assets/img/NLP.jpeg
  width: 800
  height: 500
  alt: Tá»•ng quan vá» xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn
---

# <font color = 'red'> I. Giá»›i thiá»‡u vá» Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (Natural Language Proccessing)

Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cung cáº¥p má»™t bá»™ cÃ´ng cá»¥ vÃ  thuáº­t toÃ¡n ráº¥t cáº§n thiáº¿t Ä‘á»ƒ hiá»ƒu vÃ  xá»­ lÃ½ khá»‘i lÆ°á»£ng lá»›n dá»¯ liá»‡u phi cáº¥u trÃºc trong tháº¿ giá»›i hiá»‡n nay. Hiá»‡n nay Deep learning Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng rá»™ng rÃ£i cho nhiá»u nhiá»‡m vá»¥ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn vÃ¬ hiá»‡u suáº¥t deep learning hiá»‡u quáº£ Ä‘Ã¡ng ká»ƒ trong cÃ¡c nhiá»‡m vá»¥ nhÆ° phÃ¢n loáº¡i hÃ¬nh áº£nh, nháº­n dáº¡ng giá»ng nÃ³i vÃ  táº¡o vÄƒn báº£n thá»±c táº¿,... Tensorflow lÃ  má»™t deep learning framework trá»±c quan vÃ  hiá»‡u quáº£ nháº¥t cho cÃ¡c nhiá»‡m vá»¥ nÃ y.

## <font color = 'blue'> 1.Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn lÃ  gÃ¬

Má»¥c tiÃªu cá»§a xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn lÃ  lÃ m cho mÃ¡y mÃ³c hiá»ƒu cÃ¡c ngÃ´n ngá»¯ nÃ³i vÃ  viáº¿t cá»§a chÃºng ta. Xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cÃ³ máº·t á»Ÿ kháº¯p nÆ¡i vÃ  Ä‘Ã£ lÃ  má»™t pháº§n lá»›n trong cuá»™c sá»‘ng cá»§a con ngÆ°á»i. Trá»£ lÃ½ áº£o (Virtual Assistants) cháº³ng háº¡n nhÆ° Google Assistant, Cortana, Alexa vÃ  Apple Siri,.. pháº§n lá»›n lÃ  cÃ¡c há»‡ thá»‘ng NLP.

NLP lÃ  má»™t lÄ©nh vá»±c nghiÃªn cá»©u cá»±c ká»³ thÃ¡ch thá»©c vÃ¬ cÃ¡c tá»« vÃ  ngá»¯ nghÄ©a cÃ³ má»‘i quan há»‡ phi tuyáº¿n tÃ­nh ráº¥t phá»©c táº¡p. Váº¥n Ä‘á» cÃ²n khÃ³ khÄƒn hÆ¡n khi má»—i ngÃ´n ngá»¯ cÃ³ ngá»¯ phÃ¡p, cÃº phÃ¡p vÃ  tá»« vá»±ng riÃªng. Do Ä‘Ã³, xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n liÃªn quan Ä‘áº¿n cÃ¡c nhiá»‡m vá»¥ phá»©c táº¡o khÃ¡c nhau nhÆ° phÃ¢n tÃ­ch cÃº phÃ¡p vÄƒn báº£n, hiá»ƒu cáº¥u trÃºc ngá»¯ phÃ¡p cÆ¡ báº£n cá»§a ngÃ´n ngá»¯. VÃ­ dá»¥ trong hai cÃ¢u nÃ y,"tÃ´i Ä‘i trÃªn Ä‘Æ°á»ng" vÃ  "tÃ´i thÃªm Ä‘Æ°á»ng vÃ o nÆ°á»›c cam", tá»« "Ä‘Æ°á»ng" cÃ³ hai Ã½ nghÄ©a hoÃ n toÃ n khÃ¡c nhau, do bá»‘i cáº£nh mÃ  nÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng.Äá»ƒ hiá»ƒu bá»‘i cáº£nh mÃ  tá»« Ä‘ang Ä‘Æ°á»£c sá»­ dá»¥ng. Há»c mÃ¡y Ä‘Ã£ trá»Ÿ thÃ nh má»™t yáº¿u tá»‘ chÃ­nh cho NLP, giÃºp hoÃ n thÃ nh cÃ¡c nhiá»‡m vá»¥ Ä‘Ã£ nÃ³i á»Ÿ trÃªn thÃ´ng qua há»c mÃ¡y.

## <font color ='blue'> 2. Nhiá»‡m vá»¥ cá»§a xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn

- **Tokenization**: lÃ  nhiá»‡m vá»¥ tÃ¡ch má»™t kho vÄƒn báº£n thÃ nh cÃ¡c Ä‘Æ¡n vá»‹ nhá» hÆ¡n (vÃ­ dá»¥: tá»« hoáº·c kÃ½ tá»±). Máº·c dÃ¹ nÃ³ cÃ³ váº» bÃ¬nh thÆ°á»ng Ä‘á»‘i vá»›i má»™t sá»‘ ngÃ´n ngá»¯ nhÆ° tiáº¿ng Anh nhÆ°ng láº¡i khÃ³ khÄƒn Ä‘á»‘i vá»›i cÃ¡c ngÃ´n ngá»¯ nhÆ° tiáº¿ng Nháº­t vÃ¬ cÃ¡c tá»« khÃ´ng Ä‘Æ°á»£c phÃ¢n Ä‘á»‹nh bá»Ÿi khoáº£ng cÃ¡ch hay dáº¥u cháº¥m cÃ¢u
- **Word-Sense Disambiguation**: lÃ  nhiá»‡m vá»¥ xÃ¡c Ä‘á»‹nh Ä‘Ãºng Ã½ nghÄ©a cá»§a tá»«
- **Nháº­n dáº¡ng thá»±c thá»ƒ (Named Entity Recognition(NER))**: cá»‘ gáº¯ng trÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ (vÃ­ dá»¥: ngÆ°á»i, vá»‹ trÃ­, tá»• chá»©c) tá»« má»™t pháº§n nháº¥t Ä‘á»‹nh cá»§a vÄƒn báº£n. VÃ­ dá»¥, máº«u cÃ¢u , "John gave Mary two apples at school on Monday" sáº½ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh "[John]name gave [Mary]name [two]number apples at [school]organization on [Monday]time". NER lÃ  má»™t chá»§ Ä‘á» báº¯t buá»™c trong cÃ¡c lÄ©nh vá»±c nhÆ° truy xuáº¥t thÃ´ng tin.
- **GÃ¡n nhÃ£n tá»« loáº¡i (Part-of-Speech tagging POS)**: lÃ  nhiá»‡m vá»¥ gÃ¡n cÃ¡c tá»« loáº¡i cho cÃ¡c pháº§n cá»§a vÄƒn báº£n. NÃ³ cÃ³ thá»ƒ lÃ  cÃ¡c tháº» danh tá»«, Ä‘á»™ng tá»«, tÃ­nh tá»«, tráº¡ng tá»« vÃ  giá»›i tá»«,...
- **PhÃ¢n loáº¡i cÃ¢u/tÃ³m táº¯t vÄƒn báº£n**: PhÃ¢n loáº¡i cÃ¢u hoáº·c báº£n tÃ³m táº¯t (vÃ­ dá»¥, Ä‘Ã¡nh giÃ¡ phim) cÃ³ nhiá»u trÆ°á»ng há»£p sá»­ dá»¥ng nhÆ° phÃ¡t hiá»‡n thÆ° rÃ¡c, phÃ¢n loáº¡i bÃ i bÃ¡o (vÃ­ dá»¥: chÃ­nh trá»‹, cÃ´ng nghá»‡ vÃ  thá»ƒ thao) vÃ  xáº¿p háº¡ng Ä‘Ã¡nh giÃ¡ sáº£n pháº©m (nghÄ©a lÃ  tÃ­ch cá»±c hoáº·c tiÃªu cá»±c). Äiá»u nÃ y Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch Ä‘Ã o táº¡o má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i vá»›i dá»¯ liá»‡u Ä‘Æ°á»£c dÃ¡n nhÃ£n (nghÄ©a lÃ  Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c chÃº thÃ­ch bá»Ÿi con ngÆ°á»i, vá»›i nhÃ£n tÃ­ch cá»±c hoáº·c tiÃªu cá»±c).
- **Táº¡o vÄƒn báº£n**: Trong táº¡o vÄƒn báº£n, má»™t mÃ´ hÃ¬nh há»c táº­p (vÃ­ dá»¥: máº¡ng tháº§n kinh) Ä‘Æ°á»£c Ä‘Ã o táº¡o báº±ng vÄƒn báº£n (má»™t bá»™ sÆ°u táº­p lá»›n cÃ¡c tÃ i liá»‡u vÄƒn báº£n) vÃ  sau Ä‘Ã³ nÃ³ dá»± Ä‘oÃ¡n vÄƒn báº£n má»›i.VÃ­ dá»¥, mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ thá»ƒ xuáº¥t hiá»‡n má»™t cÃ¢u chuyá»‡n khoa há»c viá»…n tÆ°á»Ÿng hoÃ n toÃ n má»›i báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c cÃ¢u chuyá»‡n khoa há»c viá»…n tÆ°á»Ÿng hiá»‡n cÃ³ Ä‘á»ƒ Ä‘Ã o táº¡o. Gáº§n Ä‘Ã¢y, Openai Ä‘Ã£ phÃ¡t hÃ nh má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ Ä‘Æ°á»£c gá»i lÃ  Openai-GPT-2, cÃ³ thá»ƒ táº¡o ra vÄƒn báº£n cá»±c ká»³ thá»±c táº¿
- **Tráº£ lá»i cÃ¢u há»i (Question Answering)**: Ká»¹ thuáº­t QA cÃ³ giÃ¡ trá»‹ thÆ°Æ¡ng máº¡i cao vÃ  cÃ¡c ká»¹ thuáº­t nhÆ° váº­y Ä‘Æ°á»£c tÃ¬m tháº¥y táº¡i ná»n táº£ng cá»§a Chatbots vÃ  Virtual Assistant (vÃ­ dá»¥: Google Assistant vÃ  Apple Siri)
- **Dá»‹ch mÃ¡y (Machine Translation)**: MT lÃ  nhiá»‡m vá»¥ chuyá»ƒn Ä‘á»•i cÃ¢u/cá»¥m tá»« tá»« ngÃ´n ngá»¯ nguá»“n (vÃ­ dá»¥: tiáº¿ng Äá»©c) sang ngÃ´n ngá»¯ Ä‘Ã­ch (vÃ­ dá»¥: tiáº¿ng Anh). ÄÃ¢y lÃ  má»™t nhiá»‡m vá»¥ ráº¥t khÃ³ khÄƒn, vÃ¬ cÃ¡c ngÃ´n ngá»¯ khÃ¡c nhau cÃ³ cÃ¡c cáº¥u trÃºc cÃº phÃ¡p khÃ¡c nhau, Ä‘iá»u Ä‘Ã³ cÃ³ nghÄ©a lÃ  nÃ³ khÃ´ng pháº£i lÃ  má»™t chuyá»ƒn Ä‘á»•i má»™t-má»™t. HÆ¡n ná»¯a, cÃ¡c má»‘i quan há»‡ tá»« ngá»¯ giá»¯a cÃ¡c ngÃ´n ngá»¯ cÃ³ thá»ƒ lÃ  má»™t-nhiá»u, má»™t-má»™t, nhiá»u-má»™t hoáº·c nhiá»u-nhiá»u.

Trong hÃ¬nh dÆ°á»›i, ta cÃ³ thá»ƒ tháº¥y phÃ¢n loáº¡i phÃ¢n cáº¥p cá»§a cÃ¡c nhiá»‡m vá»¥ NLP khÃ¡c nhau Ä‘Æ°á»£c phÃ¢n loáº¡i thÃ nh nhiá»u loáº¡i khÃ¡c nhau. ÄÃ³ lÃ  má»™t nhiá»‡m vá»¥ khÃ³ khÄƒn Ä‘á»ƒ gÃ¡n má»™t nhiá»‡m vá»¥ NLP cho má»™t phÃ¢n loáº¡i duy nháº¥t. ChÃºng ta sáº½ chia cÃ¡c danh má»¥c thÃ nh hai loáº¡i chÃ­nh: dá»±a trÃªn ngÃ´n ngá»¯ (mÃ u sÃ¡ng vá»›i vÄƒn báº£n Ä‘en) vÃ  dá»±a trÃªn cÃ´ng thá»©c váº¥n Ä‘á» (mÃ u tá»‘i vá»›i vÄƒn báº£n tráº¯ng). Váº¥n Ä‘á» ngÃ´n ngá»¯ cÃ³ hai loáº¡i: cÃº phÃ¡p (dá»±a trÃªn cáº¥u trÃºc) vÃ  ngá»¯ nghÄ©a (dá»±a trÃªn Ã½ nghÄ©a). Váº¥n Ä‘á» dá»±a trÃªn cÃ´ng thá»©c cÃ³ váº¥n Ä‘á» cÃ³ ba loáº¡i: cÃ¡c nhiá»‡m vá»¥ tiá»n xá»­ lÃ½ (cÃ¡c tÃ¡c vá»¥ Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn dá»¯ liá»‡u vÄƒn báº£n trÆ°á»›c khi cung cáº¥p cho má»™t mÃ´ hÃ¬nh), nhiá»‡m vá»¥ phÃ¢n loáº¡i(nhiá»‡m vá»¥ mÃ  chÃºng ta cá»‘ gáº¯ng gÃ¡n vÄƒn báº£n Ä‘áº§u vÃ o cho má»™t hoáº·c nhiá»u danh má»¥c tá»« má»™t táº­p há»£p cÃ¡c danh má»¥c Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c) vÃ  cÃ¡c nhiá»‡m vá»¥ táº¡o ra (cÃ¡c nhiá»‡m vá»¥ mÃ  chÃºng tÃ´i cá»‘ gáº¯ng táº¡o ra má»™t Ä‘áº§u ra vÄƒn báº£n má»›i)

![](/assets/img/NLP1.png)

## <font color = 'blue'> 3. CÃ¡ch tiáº¿p cáº­n truyá»n thá»‘ng Ä‘á»ƒ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn

CÃ¡ch tiáº¿p cáº­n truyá»n thá»‘ng hoáº·c cá»• Ä‘iá»ƒn Ä‘á»ƒ giáº£i quyáº¿t NLP lÃ  má»™t luá»“ng tuáº§n tá»± cá»§a má»™t sá»‘ bÆ°á»›c chÃ­nh vÃ  Ä‘Ã³ lÃ  má»™t cÃ¡ch tiáº¿p cáº­n thá»‘ng kÃª. Khi chÃºng ta xem xÃ©t ká»¹ hÆ¡n vá» mÃ´ hÃ¬nh há»c táº­p NLP truyá»n thá»‘ng, chÃºng ta sáº½ cÃ³ thá»ƒ tháº¥y má»™t táº­p há»£p cÃ¡c tÃ¡c vá»¥ riÃªng biá»‡t Ä‘ang diá»…n ra, cháº³ng háº¡n nhÆ° tiá»n xá»­ lÃ½ dá»¯ liá»‡u báº±ng cÃ¡ch xÃ³a dá»¯ liá»‡u khÃ´ng mong muá»‘n,ká»¹ thuáº­t tÃ­nh nÄƒng (feature engineering) Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c cÃ¡c biá»ƒu diá»…n tá»‘t vá» dá»¯ liá»‡u vÄƒn báº£n, tÃ¬m hiá»ƒu Ä‘á»ƒ sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n há»c mÃ¡y vá»›i sá»± trá»£ giÃºp cá»§a dá»¯ liá»‡u Ä‘Ã o táº¡o vÃ  dá»± Ä‘oÃ¡n Ä‘áº§u ra cho dá»¯ liá»‡u. Trong Ä‘Ã³, ká»¹ thuáº­t tÃ­nh nÄƒng lÃ  bÆ°á»›c tá»‘n thá»i gian vÃ  quan trá»ng nháº¥t Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t trÃªn má»™t nhiá»‡m vá»¥ NLP nháº¥t Ä‘á»‹nh.

## <font color = 'blue'> 3.Hiá»ƒu cÃ¡ch tiáº¿p cáº­n truyá»n thá»‘ng

Äáº§u tiÃªn,vÄƒn báº£n cáº§n Ä‘Æ°á»£c xá»­ lÃ½ trÆ°á»›c, táº­p trung vÃ o viá»‡c giáº£m tá»« vá»±ng vÃ  phÃ¢n tÃ¢m.Tiáº¿p Ä‘áº¿n Ä‘áº¿n lÃ  má»™t sá»‘ bÆ°á»›c ká»¹ thuáº­t tÃ­nh nÄƒng (feature engineering). Má»¥c tiÃªu chÃ­nh cá»§a ká»¹ thuáº­t tÃ­nh nÄƒng lÃ  lÃ m cho viá»‡c há»c dá»… dÃ ng hÆ¡n cho cÃ¡c thuáº­t toÃ¡n. ThÃ´ng thÆ°á»ng cÃ¡c tÃ­nh nÄƒng Ä‘Æ°á»£c thiáº¿t káº¿ báº±ng tay vÃ  thiÃªn vá»‹ Ä‘á»‘i vá»›i sá»± hiá»ƒu biáº¿t cá»§a con ngÆ°á»i vá» má»™t ngÃ´n ngá»¯. Ká»¹ thuáº­t tÃ­nh nÄƒng lÃ  vÃ´ cÃ¹ng quan trá»ng Ä‘á»‘i vá»›i cÃ¡c thuáº­t toÃ¡n NLP cá»• Ä‘iá»ƒn, vÃ  do Ä‘Ã³, cÃ¡c há»‡ thá»‘ng hiá»‡u suáº¥t tá»‘t nháº¥t thÆ°á»ng cÃ³ cÃ¡c tÃ­nh nÄƒng tá»‘t nháº¥t. VÃ­ dá»¥: Ä‘á»‘i vá»›i má»™t nhiá»‡m vá»¥ phÃ¢n loáº¡i tÃ¬nh cáº£m, báº¡n cÃ³ thá»ƒ biá»ƒu thá»‹ má»™t cÃ¢u cÃ³ cÃ¢y phÃ¢n tÃ­ch vÃ  gÃ¡n cÃ¡c nhÃ£n dÆ°Æ¡ng, Ã¢m hoáº·c trung tÃ­nh cho má»—i nÃºt/cÃ¢y con trong cÃ¢y Ä‘á»ƒ phÃ¢n loáº¡i cÃ¢u Ä‘Ã³ lÃ  dÆ°Æ¡ng hoáº·c Ã¢m. NgoÃ i ra, giai Ä‘oáº¡n ká»¹ thuáº­t tÃ­nh nÄƒng cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c tÃ i nguyÃªn bÃªn ngoÃ i nhÆ° WordNet (cÆ¡ sá»Ÿ dá»¯ liá»‡u tá»« vá»±ng cÃ³ thá»ƒ cung cáº¥p hiá»ƒu biáº¿t vá» cÃ¡ch cÃ¡c tá»« khÃ¡c nhau cÃ³ liÃªn quan vá»›i nhau - vÃ­ dá»¥: tá»« Ä‘á»“ng nghÄ©a) Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c tÃ­nh nÄƒng tá»‘t hÆ¡n. ChÃºng ta sáº½ sá»›m xem xÃ©t má»™t ká»¹ thuáº­t ká»¹ thuáº­t tÃ­nh nÄƒng Ä‘Æ¡n giáº£n Ä‘Æ°á»£c gá»i lÃ  bag-of-words.

Tiáº¿p theo, thuáº­t toÃ¡n há»c táº­p há»c cÃ¡ch thá»±c hiá»‡n tá»‘t trong nhiá»‡m vá»¥ Ä‘Ã£ cho báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c tÃ­nh nÄƒng thu Ä‘Æ°á»£c vÃ  tÃ¹y chá»n cÃ¡c tÃ i nguyÃªn bÃªn ngoÃ i. VÃ­ dá»¥, Ä‘á»‘i vá»›i má»™t nhiá»‡m vá»¥ tÃ³m táº¯t vÄƒn báº£n, má»™t kho vÄƒn báº£n song song chá»©a cÃ¡c cá»¥m tá»« phá»• biáº¿n vÃ  cÃ¡c chÃº giáº£i cÃ´ Ä‘á»ng sáº½ lÃ  má»™t nguá»“n tÃ i nguyÃªn bÃªn ngoÃ i tá»‘t. Cuá»‘i cÃ¹ng, dá»± Ä‘oÃ¡n xáº£y ra. Dá»± Ä‘oÃ¡n ráº¥t Ä‘Æ¡n giáº£n, trong Ä‘Ã³ báº¡n sáº½ cung cáº¥p má»™t Ä‘áº§u vÃ o má»›i vÃ  chá»©a cÃ¡c dá»± Ä‘oÃ¡n báº±ng cÃ¡ch chuyá»ƒn tiáº¿p Ä‘áº§u vÃ o thÃ´ng qua mÃ´ hÃ¬nh há»c táº­p. ToÃ n bá»™ quÃ¡ trÃ¬nh cá»§a phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng Ä‘Æ°á»£c mÃ´ táº£ bÃªn dÆ°á»›i
![](/assets/img/NLP2.png)

## <font color='blue'> 4.Háº¡n cháº¿ cá»§a phÆ°Æ¡ng phÃ¡p truyá»n thá»‘ng
CÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ Ä‘Æ°á»£c sá»­ dá»¥ng trong NLP truyá»n thá»‘ng buá»™c Ä‘Ã¡nh Ä‘á»•i thÃ´ng tin cÃ³ kháº£ nÄƒng há»¯u Ã­ch Ä‘Æ°á»£c nhÃºng trong vÄƒn báº£n (vÃ­ dá»¥: dáº¥u cÃ¢u) Ä‘á»ƒ lÃ m cho viá»‡c há»c kháº£ thi báº±ng cÃ¡ch giáº£m tá»« vá»±ng.

Ká»¹ thuáº­t tÃ­nh nÄƒng máº¥t ráº¥t nhiá»u thá»i gian. Äá»ƒ thiáº¿t káº¿ má»™t há»‡ thá»‘ng Ä‘Ã¡ng tin cáº­y, cÃ¡c tÃ­nh nÄƒng tá»‘t cáº§n pháº£i Ä‘Æ°á»£c nghÄ© ra. QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ ráº¥t táº» nháº¡t vÃ¬ cÃ¡c khÃ´ng gian tÃ­nh nÄƒng khÃ¡c nhau cáº§n Ä‘Æ°á»£c khÃ¡m phÃ¡ vÃ  Ä‘Ã¡nh giÃ¡ rá»™ng rÃ£i. NgoÃ i ra, Ä‘á»ƒ cÃ³ hiá»‡u quáº£ cÃ¡c tÃ­nh nÄƒng máº¡nh máº½, cáº§n cÃ³ chuyÃªn mÃ´n vá» miá»n, cÃ³ thá»ƒ khan hiáº¿m vÃ  tá»‘n kÃ©m cho má»™t sá»‘ nhiá»‡m vá»¥ NLP nháº¥t Ä‘á»‹nh.

CÃ¡c tÃ i nguyÃªn bÃªn ngoÃ i khÃ¡c nhau lÃ  cáº§n thiáº¿t Ä‘á»ƒ nÃ³ hoáº¡t Ä‘á»™ng tá»‘t, vÃ  khÃ´ng cÃ³ nhiá»u tÃ i nguyÃªn miá»…n phÃ­. CÃ¡c tÃ i nguyÃªn bÃªn ngoÃ i nhÆ° váº­y thÆ°á»ng bao gá»“m thÃ´ng tin Ä‘Æ°á»£c táº¡o thá»§ cÃ´ng Ä‘Æ°á»£c lÆ°u trá»¯ trong cÆ¡ sá»Ÿ dá»¯ liá»‡u lá»›n. Táº¡o má»™t cho má»™t nhiá»‡m vá»¥ cá»¥ thá»ƒ cÃ³ thá»ƒ máº¥t vÃ i nÄƒm, phá»¥ thuá»™c vÃ o má»©c Ä‘á»™ nghiÃªm trá»ng cá»§a nhiá»‡m vá»¥.

## <font color = 'blue'> 5.PhÆ°Æ¡ng phÃ¡p há»c sÃ¢u Ä‘á»ƒ xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn

CÃ¡c mÃ´ hÃ¬nh sÃ¢u Ä‘Ã£ táº¡o ra má»™t lÃ n sÃ³ng thay Ä‘á»•i mÃ´ hÃ¬nh trong nhiá»u lÄ©nh vá»±c trong há»c mÃ¡y, vÃ¬ cÃ¡c mÃ´ hÃ¬nh sÃ¢u Ä‘Ã£ há»c Ä‘Æ°á»£c cÃ¡c tÃ­nh nÄƒng phong phÃº tá»« dá»¯ liá»‡u thÃ´ thay vÃ¬ sá»­ dá»¥ng cÃ¡c tÃ­nh nÄƒng bá»‹ háº¡n cháº¿ do con ngÆ°á»i thiáº¿t káº¿. Äiá»u nÃ y do Ä‘Ã³ khiáº¿n ká»¹ thuáº­t tÃ­nh nÄƒng gÃ¢y phiá»n nhiá»…u vÃ  Ä‘áº¯t tiá»n bá»‹ lá»—i thá»i. Vá»›i Ä‘iá»u nÃ y, cÃ¡c mÃ´ hÃ¬nh sÃ¢u Ä‘Ã£ lÃ m cho quy trÃ¬nh lÃ m viá»‡c truyá»n thá»‘ng hiá»‡u quáº£ hÆ¡n, vÃ¬ cÃ¡c mÃ´ hÃ¬nh sÃ¢u thá»±c hiá»‡n há»c táº­p tÃ­nh nÄƒng vÃ  há»c táº­p nhiá»‡m vá»¥ má»™t cÃ¡ch Ä‘á»“ng thá»i. HÆ¡n ná»¯a, do sá»‘ lÆ°á»£ng lá»›n cÃ¡c tham sá»‘ (nghÄ©a lÃ  trá»ng sá»‘) trong má»™t mÃ´ hÃ¬nh sÃ¢u, nÃ³ cÃ³ thá»ƒ bao gá»“m nhiá»u tÃ­nh nÄƒng hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i con ngÆ°á»i cÃ³ thá»ƒ thiáº¿t káº¿. Tuy nhiÃªn, cÃ¡c mÃ´ hÃ¬nh sÃ¢u Ä‘Æ°á»£c coi lÃ  má»™t há»™p Ä‘en do kháº£ nÄƒng diá»…n giáº£i kÃ©m cá»§a mÃ´ hÃ¬nh. 
Má»™t máº¡ng lÆ°á»›i tháº§n kinh sÃ¢u vá» cÆ¡ báº£n lÃ  má»™t máº¡ng lÆ°á»›i tháº§n kinh nhÃ¢n táº¡o cÃ³ lá»›p Ä‘áº§u vÃ o, nhiá»u lá»›p áº©n Ä‘Æ°á»£c káº¿t ná»‘i vá»›i nhau á»Ÿ giá»¯a, vÃ  cuá»‘i cÃ¹ng, má»™t lá»›p Ä‘áº§u ra (vÃ­ dá»¥: phÃ¢n loáº¡i hoáº·c há»“i quy). NhÆ° báº¡n cÃ³ thá»ƒ tháº¥y, Ä‘iá»u nÃ y táº¡o thÃ nh má»™t mÃ´ hÃ¬nh tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i tá»« dá»¯ liá»‡u thÃ´ Ä‘áº¿n dá»± Ä‘oÃ¡n. CÃ¡c lá»›p áº©n nÃ y á»Ÿ giá»¯a cung cáº¥p sá»©c máº¡nh cho cÃ¡c mÃ´ hÃ¬nh sÃ¢u vÃ¬ chÃºng chá»‹u trÃ¡ch nhiá»‡m há»c cÃ¡c tÃ­nh nÄƒng tá»‘t tá»« dá»¯ liá»‡u thÃ´.
## <font color = 'blue'> 6.Hiá»ƒu má»™t mÃ´ hÃ¬nh sÃ¢u Ä‘Æ¡n giáº£n - má»™t máº¡ng lÆ°á»›i tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§
BÃ¢y giá», hÃ£y Ä‘á»ƒ cÃ³ má»™t cÃ¡i nhÃ¬n ká»¹ hÆ¡n vá» má»™t máº¡ng lÆ°á»›i tháº§n kinh sÃ¢u Ä‘á»ƒ cÃ³ Ä‘Æ°á»£c sá»± hiá»ƒu biáº¿t tá»‘t hÆ¡n. Máº·c dÃ¹ cÃ³ ráº¥t nhiá»u biáº¿n thá»ƒ khÃ¡c nhau cá»§a cÃ¡c mÃ´ hÃ¬nh sÃ¢u, hÃ£y nhÃ¬n vÃ o má»™t trong nhá»¯ng mÃ´ hÃ¬nh sá»›m nháº¥t cÃ³ tá»« nÄƒm 1950 mÃ´ táº£ má»™t a fully connected neural network (FCNN) cÃ³ ba lá»›p tiÃªu chuáº©n

Má»¥c tiÃªu cá»§a FCNN lÃ  Ã¡nh xáº¡ Ä‘áº§u vÃ o (vÃ­ dá»¥: hÃ¬nh áº£nh hoáº·c cÃ¢u) Ä‘áº¿n má»™t nhÃ£n hoáº·c chÃº thÃ­ch nháº¥t Ä‘á»‹nh (vÃ­ dá»¥: danh má»¥c Ä‘á»‘i tÆ°á»£ng cho hÃ¬nh áº£nh). Äiá»u nÃ y Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch sá»­ dá»¥ng Ä‘áº§u vÃ o X Ä‘á»ƒ tÃ­nh toÃ¡n H - biá»ƒu diá»…n áº©n cá»§a X - sá»­ dá»¥ng má»™t phÃ©p biáº¿n Ä‘á»•i nhÆ° â„=ğœ(ğ‘Š * h + b); á» Ä‘Ã¢y, W lÃ  trá»ng sá»‘ vÃ  b lÃ  Ä‘á»™ lá»‡ch cá»§a FCNN, vÃ  ğœ lÃ  chá»©c nÄƒng kÃ­ch hoáº¡t sigmoid. Máº¡ng tháº§n kinh sá»­ dá»¥ng cÃ¡c chá»©c nÄƒng kÃ­ch hoáº¡t phi tuyáº¿n tÃ­nh á»Ÿ má»—i lá»›p. KÃ­ch hoáº¡t sigmoid lÃ  má»™t trong nhá»¯ng kÃ­ch hoáº¡t nhÆ° váº­y. NÃ³ lÃ  má»™t chuyá»ƒn Ä‘á»•i pháº§n tá»­ Ä‘Æ°á»£c Ã¡p dá»¥ng cho Ä‘áº§u ra cá»§a má»™t lá»›p, trong Ä‘Ã³ Ä‘áº§u ra sigmoidal cá»§a x Ä‘Æ°á»£c cho bá»Ÿi, ğœ(ğ‘¥) = 1/(1+ğ‘’-x). 

Tiáº¿p theo, má»™t trÃ¬nh phÃ¢n loáº¡i Ä‘Æ°á»£c Ä‘áº·t trÃªn Ä‘áº§u FCNN cung cáº¥p kháº£ nÄƒng táº­n dá»¥ng cÃ¡c tÃ­nh nÄƒng Ä‘Ã£ há»c trong cÃ¡c lá»›p áº©n Ä‘á»ƒ phÃ¢n loáº¡i Ä‘áº§u vÃ o. TrÃ¬nh phÃ¢n loáº¡i lÃ  má»™t pháº§n cá»§a FCNN vÃ  má»™t lá»›p áº©n khÃ¡c vá»›i má»™t sá»‘ trá»ng sá»‘ Ws vÃ  thiÃªn vá»‹ Bs. NgoÃ i ra, chÃºng ta cÃ³ thá»ƒ tÃ­nh toÃ¡n Ä‘áº§u ra cuá»‘i cÃ¹ng cá»§a FCNN lÃ  output =softmax(ğ‘Šğ‘  âˆ— â„+ Bğ‘ ).

VÃ­ dá»¥, má»™t phÃ¢n loáº¡i SoftMax cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c váº¥n Ä‘á» phÃ¢n loáº¡i Ä‘a nhÃ£n. NÃ³ cung cáº¥p má»™t biá»ƒu diá»…n chuáº©n hÃ³a cá»§a Ä‘áº§u ra Ä‘iá»ƒm sá»‘ cá»§a lá»›p phÃ¢n loáº¡i. ÄÃ³ lÃ , nÃ³ sáº½ táº¡o ra má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t há»£p lá»‡ trÃªn cÃ¡c lá»›p trong lá»›p phÃ¢n loáº¡i. NhÃ£n Ä‘Æ°á»£c coi lÃ  nÃºt Ä‘áº§u ra cÃ³ giÃ¡ trá»‹ softmax cao nháº¥t. Sau Ä‘Ã³, vá»›i Ä‘iá»u nÃ y, chÃºng ta cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh tá»•n tháº¥t phÃ¢n loáº¡i Ä‘Æ°á»£c tÃ­nh lÃ  sá»± khÃ¡c biá»‡t giá»¯a nhÃ£n Ä‘áº§u ra dá»± Ä‘oÃ¡n vÃ  nhÃ£n Ä‘áº§u ra thá»±c táº¿. Má»™t vÃ­ dá»¥ vá» chá»©c nÄƒng máº¥t mÃ¡t nhÆ° váº­y lÃ  máº¥t bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh (mean squared loss).

Tiáº¿p theo, cÃ¡c tham sá»‘ máº¡ng tháº§n kinh, W, B, WS vÃ  BS, Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a báº±ng trÃ¬nh tá»‘i Æ°u hÃ³a ngáº«u nhiÃªn tiÃªu chuáº©n (vÃ­ dá»¥: giáº£m Ä‘á»™ dá»‘c ngáº«u nhiÃªn) Ä‘á»ƒ giáº£m sá»± máº¥t phÃ¢n loáº¡i cá»§a táº¥t cáº£ cÃ¡c Ä‘áº§u vÃ o. HÃ¬nh dÆ°á»›i mÃ´ táº£ quÃ¡ trÃ¬nh Ä‘Æ°á»£c giáº£i thÃ­ch trong Ä‘oáº¡n nÃ y cho FCNN ba lá»›p.

![](/assets/img/NLP3.png)

CÃ³ thá»ƒ sá»­ dá»¥ng máº¡ng tháº§n kinh (cÃ³ thá»ƒ sÃ¢u hoáº·c nÃ´ng, tÃ¹y thuá»™c vÃ o Ä‘á»™ khÃ³ cá»§a nhiá»‡m vá»¥) cho nhiá»‡m vá»¥ nÃ y báº±ng cÃ¡ch tuÃ¢n thá»§ quy trÃ¬nh lÃ m viá»‡c sau:

1. MÃ£ thÃ´ng bÃ¡o (Tokenize) cÃ¢u thÃ nh cÃ¡c tá»«. 
2. Chuyá»ƒn Ä‘á»•i cÃ¡c cÃ¢u thÃ nh má»™t biá»ƒu diá»…n sá»‘ cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh (vÃ­ dá»¥: biá»ƒu diá»…n tÃºi cá»§a cÃ¡c tá»«). Má»™t biá»ƒu diá»…n cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh lÃ  cáº§n thiáº¿t vÃ¬ cÃ¡c máº¡ng tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§ Ä‘Ã²i há»i má»™t Ä‘áº§u vÃ o cÃ³ kÃ­ch thÆ°á»›c cá»‘ Ä‘á»‹nh. 
3. Cung cáº¥p cÃ¡c Ä‘áº§u vÃ o sá»‘ vÃ o máº¡ng tháº§n kinh, dá»± Ä‘oÃ¡n Ä‘áº§u ra (dÆ°Æ¡ng hoáº·c Ã¢m) vÃ  so sÃ¡nh vá»›i má»¥c tiÃªu thá»±c. 
4. Tá»‘i Æ°u hÃ³a máº¡ng lÆ°á»›i tháº§n kinh báº±ng cÃ¡ch sá»­ dá»¥ng chá»©c nÄƒng tá»•n tháº¥t mong muá»‘n.

## <font color = 'blue'> 7. Má»™t sá»‘ ná»n táº£ng tÃ­nh toÃ¡n dá»±a trÃªn Ä‘Ã¡m mÃ¢y phá»• biáº¿n

â€¢ Google Colab: https://colab.research.google.com/

â€¢ Google Cloud Platform (GCP): https://cloud.google.com/

â€¢ Amazon Web Services (AWS): https://aws.amazon.com/

# <font color ='red'> II.Hiá»ƒu vá» Tensorflow 2

## <font color = 'blue'> 1.Tensorflow lÃ  gÃ¬?

Tensorflow lÃ  má»™t nguá»“n má»Ÿ, Ä‘Æ°á»£c phÃ¡t hÃ nh bá»Ÿi Google, chá»§ yáº¿u nháº±m giáº£m bá»›t cÃ¡c chi tiáº¿t Ä‘au Ä‘á»›n khi thá»±c hiá»‡n máº¡ng lÆ°á»›i tháº§n kinh (vÃ­ dá»¥, tÃ­nh toÃ¡n cÃ¡c dáº«n xuáº¥t (derivatives) cá»§a trá»ng lÆ°á»£ng cá»§a máº¡ng lÆ°á»›i tháº§n kinh). TensorFlow tiáº¿n thÃªm má»™t bÆ°á»›c báº±ng cÃ¡ch cung cáº¥p cÃ¡c triá»ƒn khai hiá»‡u quáº£ cÃ¡c tÃ­nh toÃ¡n sá»‘ Ä‘Ã³ báº±ng cÃ¡ch sá»­ dá»¥ng kiáº¿n trÃºc thiáº¿t bá»‹ há»£p nháº¥t tÃ­nh toÃ¡n (CUDA), lÃ  má»™t ná»n táº£ng tÃ­nh toÃ¡n song song Ä‘Æ°á»£c NVIDIA giá»›i thiá»‡u. 

## <font color = 'blue'> 2.Báº¯t Ä‘áº§u vá»›i TensorFlow 2

BÃ¢y giá», hÃ£y Ä‘á»ƒ tÃ¬m hiá»ƒu vá» má»™t vÃ i thÃ nh pháº§n thiáº¿t yáº¿u trong khung TensorFlow báº±ng cÃ¡ch lÃ m viá»‡c thÃ´ng qua má»™t vÃ­ dá»¥ vá» mÃ£. HÃ£y Ä‘á»ƒ viáº¿t má»™t vÃ­ dá»¥ Ä‘á»ƒ thá»±c hiá»‡n tÃ­nh toÃ¡n sau, Ä‘iá»u nÃ y ráº¥t phá»• biáº¿n Ä‘á»‘i vá»›i cÃ¡c máº¡ng tháº§n kinh:

![](/assets/img/NLP4.png)

TÃ­nh toÃ¡n nÃ y bao gá»“m nhá»¯ng gÃ¬ xáº£y ra trong má»™t lá»›p duy nháº¥t cá»§a má»™t máº¡ng nÆ¡-ron Ä‘Æ°á»£c káº¿t ná»‘i hoÃ n toÃ n. á» Ä‘Ã¢y W vÃ  x lÃ  ma tráº­n vÃ  b lÃ  má»™t vectÆ¡. Sau Ä‘Ã³,".' biá»ƒu thá»‹ dot. sigmoid lÃ  má»™t phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n tÃ­nh Ä‘Æ°á»£c Ä‘Æ°a ra bá»Ÿi phÆ°Æ¡ng trÃ¬nh sau:

![](/assets/img/NLP5.png)

Äáº§u tiÃªn, chÃºng ta sáº½ cáº§n nháº­p TensorFlow vÃ  Numpy. Numpy lÃ  má»™t khung tÃ­nh toÃ¡n khoa há»c khÃ¡c cung cáº¥p cÃ¡c hoáº¡t Ä‘á»™ng toÃ¡n há»c vÃ  cÃ¡c hoáº¡t Ä‘á»™ng khÃ¡c Ä‘á»ƒ thao tÃ¡c dá»¯ liá»‡u. Nháº­p vÃ o chÃºng lÃ  Ä‘iá»u cáº§n thiáº¿t trÆ°á»›c khi báº¡n cháº¡y báº¥t ká»³ loáº¡i hoáº¡t Ä‘á»™ng liÃªn quan Ä‘áº¿n TensorFlow hoáº·c Numpy trong Python:

```python
import tensorflow as tf 
import numpy as np
```

Äáº§u tiÃªn, chÃºng tÃ´i sáº½ viáº¿t má»™t hÃ m cÃ³ thá»ƒ láº¥y cÃ¡c Ä‘áº§u vÃ o X, W vÃ  B vÃ  thá»±c hiá»‡n tÃ­nh toÃ¡n nÃ y cho chÃºng tÃ´i:

```python
def layer(x, W, b): 
    # Building the graph
    h = tf.nn.sigmoid(tf.matmul(x,W) + b) # Operation to perform
    return h
```

Tiáº¿p theo, chÃºng tÃ´i thÃªm má»™t cÃ´ng cá»¥ trang trÃ­ Python cÃ³ tÃªn TF.Function nhÆ° sau

```python
@tf.function
def layer(x, W, b): 
    # Building the graph
    h = tf.nn.sigmoid(tf.matmul(x,W) + b) # Operation to perform
    return h
```

NÃ³i má»™t cÃ¡ch Ä‘Æ¡n giáº£n, má»™t decorator Python chá»‰ lÃ  má»™t hÃ m khÃ¡c. Má»™t decorator Python cung cáº¥p má»™t cÃ¡ch sáº¡ch sáº½ Ä‘á»ƒ gá»i má»™t hÃ m khÃ¡c báº¥t cá»© khi nÃ o báº¡n gá»i hÃ m decorated. NÃ³i cÃ¡ch khÃ¡c, má»—i khi hÃ m layer() Ä‘Æ°á»£c gá»i, tf.function() Ä‘Æ°á»£c gá»i. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c má»¥c Ä‘Ã­ch khÃ¡c nhau, cháº³ng háº¡n nhÆ°:

â€¢ Ghi nháº­t kÃ½ ná»™i dung vÃ  hoáº¡t Ä‘á»™ng trong má»™t hÃ m 

â€¢ XÃ¡c thá»±c cÃ¡c Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra cá»§a hÃ m khÃ¡c

Khi hÃ m layer() Ä‘i qua tf.function (), TensorFlow sáº½ theo dÃµi ná»™i dung (nÃ³i cÃ¡ch khÃ¡c, cÃ¡c hoáº¡t Ä‘á»™ng vÃ  dá»¯ liá»‡u) trong hÃ m vÃ  tá»± Ä‘á»™ng xÃ¢y dá»±ng biá»ƒu Ä‘á»“ tÃ­nh toÃ¡n.

Biá»ƒu Ä‘á»“ tÃ­nh toÃ¡n (cÃ²n Ä‘Æ°á»£c gá»i lÃ  biá»ƒu Ä‘á»“ DataFlow) xÃ¢y dá»±ng DAG (biá»ƒu Ä‘á»“ acyclic cÃ³ hÆ°á»›ng) hiá»ƒn thá»‹ loáº¡i Ä‘áº§u vÃ o nÃ o Ä‘Æ°á»£c yÃªu cáº§u vÃ  loáº¡i tÃ­nh toÃ¡n cáº§n Ä‘Æ°á»£c thá»±c hiá»‡n trong chÆ°Æ¡ng trÃ¬nh

Trong vÃ­ dá»¥ nÃ y, hÃ m layer() táº¡o ra H báº±ng cÃ¡ch sá»­ dá»¥ng Ä‘áº§u vÃ o X, W vÃ  B vÃ  má»™t sá»‘ phÆ°Æ¡ng tiá»‡n chuyá»ƒn Ä‘á»•i hoáº·c cÃ¡c operations nhÆ° + vÃ  tf.matmul ():

![](/assets/img/NLP6.png)

Náº¿u chÃºng ta nhÃ¬n vÃ o má»™t sá»± tÆ°Æ¡ng tá»± cho má»™t DAG, náº¿u báº¡n nghÄ© vá» Ä‘áº§u ra nhÆ° 
má»™t chiáº¿c bÃ¡nh, thÃ¬ biá»ƒu Ä‘á»“ sáº½ lÃ  cÃ´ng thá»©c Ä‘á»ƒ lÃ m cho bÃ¡nh Ä‘Ã³ sá»­ dá»¥ng cÃ¡c thÃ nh pháº§n (nghÄ©a lÃ  Ä‘áº§u vÃ o).

TÃ­nh nÄƒng xÃ¢y dá»±ng biá»ƒu Ä‘á»“ tÃ­nh toÃ¡n nÃ y tá»± Ä‘á»™ng trong TensorFlow Ä‘Æ°á»£c gá»i lÃ  AutoGraph. AutoGraph khÃ´ng chá»‰ nhÃ¬n vÃ o cÃ¡c operations trong hÃ m Ä‘Æ°á»£c thÃ´ng qua; NÃ³ cÅ©ng xem xÃ©t ká»¹ lÆ°á»¡ng dÃ²ng cháº£y cá»§a cÃ¡c hoáº¡t Ä‘á»™ng. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  báº¡n cÃ³ thá»ƒ cÃ³ náº¿u cÃ¡c cÃ¢u lá»‡nh if, hoáº·c cÃ¡c vÃ²ng láº·p for/while trong hÃ m cá»§a báº¡n vÃ  AutoGraph sáº½ quan tÃ¢m chÃºng khi xÃ¢y dá»±ng biá»ƒu Ä‘á»“. 

Tiáº¿p theo, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng chá»©c nÄƒng nÃ y ngay láº­p tá»©c, nhÆ° sau

```python
x = np.array([[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]],dtype=np.float32)
```

á» Ä‘Ã¢y, x lÃ  má»™t máº£ng numpy Ä‘Æ¡n giáº£n

```python
init_w = tf.initializers.RandomUniform(minval=-0.1, maxval=0.1)(shape=[10,5])
W = tf.Variable(init_w, dtype=tf.float32, name='W') 
init_b = tf.initializers.RandomUniform()(shape=[5])
b = tf.Variable(init_b, dtype=tf.float32, name='b')
```

W vÃ  B lÃ  cÃ¡c biáº¿n TensorFlow Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh báº±ng Ä‘á»‘i tÆ°á»£ng TF.Varable. W vÃ  B lÃ  tensor. Má»™t tensor vá» cÆ¡ báº£n lÃ  má»™t máº£ng N chiá»u. VÃ­ dá»¥, má»™t vectÆ¡ má»™t chiá»u hoáº·c ma tráº­n hai chiá»u Ä‘Æ°á»£c gá»i lÃ  tensor. tf.variable lÃ  má»™t cáº¥u trÃºc cÃ³ thá»ƒ thay Ä‘á»•i, cÃ³ nghÄ©a lÃ  cÃ¡c giÃ¡ trá»‹ trong tensor Ä‘Æ°á»£c lÆ°u trá»¯ trong biáº¿n Ä‘Ã³ cÃ³ thá»ƒ thay Ä‘á»•i theo thá»i gian. VÃ­ dá»¥, cÃ¡c biáº¿n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ lÆ°u trá»¯ cÃ¡c trá»ng sá»‘ máº¡ng tháº§n kinh, thay Ä‘á»•i trong quÃ¡ trÃ¬nh tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh.

NgoÃ i ra, lÆ°u Ã½ ráº±ng vá»›i W vÃ  B, chÃºng tÃ´i cung cáº¥p má»™t sá»‘ Ä‘á»‘i sá»‘ quan trá»ng, cháº³ng háº¡n nhÆ° sau:

```python
init_w = tf.initializers.RandomUniform(minval=-0.1, maxval=0.1)(shape=[10,5])
init_b = tf.initializers.RandomUniform()(shape=[5])
```

ChÃºng Ä‘Æ°á»£c gá»i lÃ  cÃ¡c bá»™ khá»Ÿi táº¡o biáº¿n vÃ  lÃ  cÃ¡c tensor sáº½ Ä‘Æ°á»£c gÃ¡n cho cÃ¡c biáº¿n W vÃ  B ban Ä‘áº§u. Má»™t biáº¿n pháº£i cÃ³ má»™t giÃ¡ trá»‹ ban Ä‘áº§u Ä‘Æ°á»£c cung cáº¥p. á» Ä‘Ã¢y, tf.initializer.randomuniform cÃ³ nghÄ©a lÃ  chÃºng ta thá»‘ng nháº¥t cÃ¡c giÃ¡ trá»‹ máº«u giá»¯a minval (-0.1) vÃ  maxval (0,1) Ä‘á»ƒ gÃ¡n cÃ¡c giÃ¡ trá»‹ cho cÃ¡c tensor. CÃ³ nhiá»u bá»™ khá»Ÿi táº¡o khÃ¡c nhau Ä‘Æ°á»£c cung cáº¥p trong TensorFlow (https: // www.tensorflow.org/api_docs/python/tf/keras/initializer). NÃ³ cÅ©ng ráº¥t quan trá»ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh hÃ¬nh dáº¡ng cá»§a bá»™ khá»Ÿi táº¡o cá»§a báº¡n khi báº¡n Ä‘ang xÃ¡c Ä‘á»‹nh chÃ­nh bá»™ khá»Ÿi táº¡o. Thuá»™c tÃ­nh hÃ¬nh dáº¡ng xÃ¡c Ä‘á»‹nh kÃ­ch thÆ°á»›c cá»§a tá»«ng chiá»u cá»§a tenxÆ¡ Ä‘áº§u ra. VÃ­ dá»¥: náº¿u hÃ¬nh dáº¡ng lÃ  [10, 5], Ä‘iá»u nÃ y cÃ³ nghÄ©a lÃ  nÃ³ sáº½ lÃ  cáº¥u trÃºc hai chiá»u vÃ  sáº½ cÃ³ 10 pháº§n tá»­ trÃªn trá»¥c 0 (hÃ ng) vÃ  5 pháº§n tá»­ trÃªn trá»¥c 1 (cá»™t):

```python
h = layer(x,W,b)
```

Cuá»‘i cÃ¹ng, H Ä‘Æ°á»£c gá»i lÃ  tensorflow tensor nÃ³i chung. Má»™t tensorflow tensor lÃ  má»™t cáº¥u trÃºc báº¥t biáº¿n. Khi má»™t giÃ¡ trá»‹ Ä‘Æ°á»£c gÃ¡n cho tensorflow tensor, nÃ³ khÃ´ng thá»ƒ thay Ä‘á»•i.

NhÆ° báº¡n cÃ³ thá»ƒ tháº¥y, thuáº­t ngá»¯ tensor Ä‘Æ°á»£c sá»­ dá»¥ng theo hai cÃ¡ch:

 â€¢ Ä‘á»ƒ chá»‰ má»™t máº£ng n chiá»u 
 
 â€¢ Ä‘á»ƒ tham kháº£o cáº¥u trÃºc dá»¯ liá»‡u báº¥t biáº¿n trong tensorflow

Cuá»‘i cÃ¹ng, báº¡n cÃ³ thá»ƒ tháº¥y ngay giÃ¡ trá»‹ cá»§a H

```python
print(f"h = {h.numpy()}")
```

```python
@tf.function
def layer(x, W, b): 
    # Building the graph
    h = tf.nn.sigmoid(tf.matmul(x,W) + b) # Operation to be performed
    return h
x = np.array([[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]], 
dtype=np.float32) 
# Variable
init_w = tf.initializers.RandomUniform(minval=-0.1, maxval=0.1)(shape=[10,5])
W = tf.Variable(init_w, dtype=tf.float32, name='W') 
# Variable
init_b = tf.initializers.RandomUniform()(shape=[5])
b = tf.Variable(init_b, dtype=tf.float32, name='b') 
h = layer(x,W,b)
print(f"h = {h.numpy()}")
```
## <font color = 'blue'> 3.Äáº§u vÃ o, biáº¿n, Ä‘áº§u ra vÃ  operation

â€¢ Äáº§u vÃ o: Dá»¯ liá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã o táº¡o vÃ  kiá»ƒm tra cÃ¡c thuáº­t toÃ¡n cá»§a chÃºng tÃ´i 

â€¢ Biáº¿n: Tensor cÃ³ thá»ƒ thay Ä‘á»•i, chá»§ yáº¿u xÃ¡c Ä‘á»‹nh cÃ¡c tham sá»‘ cá»§a thuáº­t toÃ¡n cá»§a chÃºng tÃ´i

â€¢ Äáº§u ra: CÃ¡c tensor báº¥t biáº¿n lÆ°u trá»¯ cáº£ Ä‘áº§u ra Ä‘áº§u cuá»‘i vÃ  Ä‘áº§u ra trung gian 

â€¢ Operation: CÃ¡c phÃ©p biáº¿n Ä‘á»•i khÃ¡c nhau cho Ä‘áº§u vÃ o Ä‘á»ƒ táº¡o ra Ä‘áº§u ra mong muá»‘n

![](/assets/img/NLP7.png)

### <font color = 'green'> Äá»‹nh nghÄ©a Ä‘áº§u vÃ o trong Tensorflow
CÃ³ ba cÃ¡ch khÃ¡c nhau mÃ  báº¡n cÃ³ thá»ƒ cung cáº¥p dá»¯ liá»‡u cho chÆ°Æ¡ng trÃ¬nh TensorFlow: 

â€¢ Táº¡o dá»¯ liá»‡u dÆ°á»›i dáº¡ng máº£ng Numpy 

â€¢ Táº¡o dá»¯ liá»‡u dÆ°á»›i dáº¡ng tenorflow tensors 

â€¢ Sá»­ dá»¥ng API TF.DATA Ä‘á»ƒ táº¡o Ä‘Æ°á»ng á»‘ng Ä‘áº§u vÃ o 

### <font color = 'green'> Äá»‹nh nghÄ©a biáº¿n trong Tensorflow
CÃ¡c biáº¿n Ä‘Ã³ng má»™t vai trÃ² quan trá»ng trong tensorflow. Má»™t biáº¿n vá» cÆ¡ báº£n lÃ  má»™t tenxÆ¡ vá»›i hÃ¬nh dáº¡ng cá»¥ thá»ƒ xÃ¡c Ä‘á»‹nh cÃ³ bao nhiÃªu kÃ­ch thÆ°á»›c mÃ  biáº¿n sáº½ cÃ³ vÃ  kÃ­ch thÆ°á»›c cá»§a má»—i chiá»u. Tuy nhiÃªn, khÃ´ng giá»‘ng nhÆ° má»™t tenxÆ¡ tenorflow thÃ´ng thÆ°á»ng, cÃ¡c biáº¿n cÃ³ thá»ƒ thay Ä‘á»•i; nghÄ©a lÃ  giÃ¡ trá»‹ cá»§a cÃ¡c biáº¿n cÃ³ thá»ƒ thay Ä‘á»•i sau khi chÃºng Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh. ÄÃ¢y lÃ  má»™t thuá»™c tÃ­nh lÃ½ tÆ°á»Ÿng Ä‘á»ƒ pháº£i thá»±c hiá»‡n cÃ¡c tham sá»‘ cá»§a mÃ´ hÃ¬nh há»c táº­p (vÃ­ dá»¥: trá»ng lÆ°á»£ng máº¡ng tháº§n kinh), trong Ä‘Ã³ cÃ¡c trá»ng sá»‘ thay Ä‘á»•i má»™t chÃºt sau má»—i bÆ°á»›c há»c táº­p. VÃ­ dá»¥: náº¿u báº¡n xÃ¡c Ä‘á»‹nh má»™t biáº¿n cÃ³ x = tf.varable (0, dtype = tf.int32), báº¡n cÃ³ thá»ƒ thay Ä‘á»•i giÃ¡ trá»‹ cá»§a biáº¿n Ä‘Ã³ báº±ng cÃ¡ch sá»­ dá»¥ng hoáº¡t Ä‘á»™ng tenorflow nhÆ° tf.assign (x, x+1). Tuy nhiÃªn, náº¿u báº¡n xÃ¡c Ä‘á»‹nh má»™t tenxÆ¡ nhÆ° x = tf.constant (0, dtype = tf.int32), báº¡n khÃ´ng thá»ƒ thay Ä‘á»•i giÃ¡ trá»‹ cá»§a tenxÆ¡, nhÆ° báº¡n cÃ³ thá»ƒ cho má»™t biáº¿n. NÃ³ sáº½ á»Ÿ láº¡i 0 cho Ä‘áº¿n khi káº¿t thÃºc viá»‡c thá»±c hiá»‡n chÆ°Æ¡ng trÃ¬nh.

Táº¡o biáº¿n lÃ  khÃ¡ Ä‘Æ¡n giáº£n. Trong vÃ­ dá»¥ sigmoid cá»§a chÃºng ta, chÃºng ta Ä‘Ã£ táº¡o hai biáº¿n, W vÃ  b. Khi táº¡o ra má»™t biáº¿n, má»™t vÃ i Ä‘iá»u lÃ  vÃ´ cÃ¹ng quan trá»ng. ChÃºng ta sáº½ liá»‡t kÃª chÃºng á»Ÿ Ä‘Ã¢y vÃ  tháº£o luáº­n chi tiáº¿t trong cÃ¡c Ä‘oáº¡n sau:

- HÃ¬nh dáº¡ng biáº¿n 
- GiÃ¡ trá»‹ ban Ä‘áº§u 
- Kiá»ƒu dá»¯ liá»‡u 
- TÃªn (TÃ¹y chá»n)

HÃ¬nh dáº¡ng biáº¿n lÃ  má»™t danh sÃ¡ch cá»§a Ä‘á»‹nh dáº¡ng [x, y, z, ...]. Má»—i giÃ¡ trá»‹ trong danh sÃ¡ch cho biáº¿t kÃ­ch thÆ°á»›c hoáº·c trá»¥c tÆ°Æ¡ng á»©ng lá»›n nhÆ° tháº¿ nÃ o. Cháº³ng háº¡n, náº¿u báº¡n yÃªu cáº§u tenxÆ¡ 2D vá»›i 50 hÃ ng vÃ  10 cá»™t lÃ m biáº¿n, hÃ¬nh dáº¡ng sáº½ báº±ng [50,10].

KÃ­ch thÆ°á»›c cá»§a biáº¿n (nghÄ©a lÃ  Ä‘á»™ dÃ i cá»§a vectÆ¡ hÃ¬nh dáº¡ng) Ä‘Æ°á»£c cÃ´ng nháº­n lÃ  thá»© háº¡ng cá»§a tensor trong tenorflow.

Tiáº¿p theo, má»™t biáº¿n yÃªu cáº§u má»™t giÃ¡ trá»‹ ban Ä‘áº§u pháº£i Ä‘Æ°á»£c khá»Ÿi táº¡o. TensorFlow cung cáº¥p má»™t sá»‘ bá»™ khá»Ÿi táº¡o khÃ¡c nhau, bao gá»“m cÃ¡c bá»™ khá»Ÿi táº¡o khÃ´ng Ä‘á»•i vÃ  bá»™ khá»Ÿi táº¡o phÃ¢n phá»‘i bÃ¬nh thÆ°á»ng. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t vÃ i bá»™ khá»Ÿi táº¡o TensorFlow phá»• biáº¿n mÃ  báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ khá»Ÿi táº¡o cÃ¡c biáº¿n:

- tf.initializers.Zeros
- tf.initializers.Constant
- tf.initializers.RandomNormal
- tf.initializers.GlorotUniform

HÃ¬nh dáº¡ng cá»§a biáº¿n cÃ³ thá»ƒ Ä‘Æ°á»£c cung cáº¥p nhÆ° lÃ  má»™t pháº§n cá»§a trÃ¬nh khá»Ÿi táº¡o nhÆ° sau:

```python
tf.initializers.RandomUniform(minval=-0.1, maxval=0.1)(shape=[10,5])
```

Kiá»ƒu dá»¯ liá»‡u Ä‘Ã³ng má»™t vai trÃ² quan trá»ng trong viá»‡c xÃ¡c Ä‘á»‹nh kÃ­ch thÆ°á»›c cá»§a má»™t biáº¿n. CÃ³ nhiá»u loáº¡i dá»¯ liá»‡u khÃ¡c nhau, bao gá»“m TF.Bool, TF.Uint8, TF.Float32 vÃ  TF.INT32. Má»—i loáº¡i dá»¯ liá»‡u cÃ³ má»™t sá»‘ bit cáº§n thiáº¿t Ä‘á»ƒ biá»ƒu diá»…n má»™t giÃ¡ trá»‹ duy nháº¥t vá»›i loáº¡i Ä‘Ã³. VÃ­ dá»¥, tf.uint8 yÃªu cáº§u 8 bit, trong khi tf.float32 yÃªu cáº§u 32 bit. ÄÃ³ lÃ  thá»±c táº¿ phá»• biáº¿n Ä‘á»ƒ sá»­ dá»¥ng cÃ¡c loáº¡i dá»¯ liá»‡u tÆ°Æ¡ng tá»± cho cÃ¡c tÃ­nh toÃ¡n, vÃ¬ lÃ m cÃ¡ch khÃ¡c cÃ³ thá»ƒ dáº«n Ä‘áº¿n sá»± khÃ´ng phÃ¹ há»£p cá»§a kiá»ƒu dá»¯ liá»‡u. VÃ¬ váº­y, náº¿u báº¡n cÃ³ hai loáº¡i dá»¯ liá»‡u khÃ¡c nhau cho hai tenxor mÃ  báº¡n cáº§n chuyá»ƒn Ä‘á»•i, báº¡n pháº£i chuyá»ƒn Ä‘á»•i rÃµ rÃ ng má»™t tenxÆ¡ sang loáº¡i tenxÆ¡ khÃ¡c báº±ng cÃ¡ch sá»­ dá»¥ng thao tÃ¡c tf.cast (...).

Hoáº¡t Ä‘á»™ng tf.cast (...) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘á»‘i phÃ³ vá»›i cÃ¡c tÃ¬nh huá»‘ng nhÆ° váº­y. VÃ­ dá»¥: náº¿u báº¡n cÃ³ biáº¿n X vá»›i loáº¡i tf.int32, cáº§n Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh tf.float32, sá»­ dá»¥ng tf.cast(x, dtype = tf.float32) Ä‘á»ƒ chuyá»ƒn Ä‘á»•i x thÃ nh tf.float32.

Cuá»‘i cÃ¹ng, tÃªn cá»§a biáº¿n sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m ID Ä‘á»ƒ xÃ¡c Ä‘á»‹nh biáº¿n Ä‘Ã³ trong biá»ƒu Ä‘á»“. Náº¿u báº¡n Ä‘Ã£ tá»«ng trá»±c quan hÃ³a biá»ƒu Ä‘á»“ tÃ­nh toÃ¡n, biáº¿n sáº½ xuáº¥t hiá»‡n báº±ng Ä‘á»‘i sá»‘ Ä‘Æ°á»£c chuyá»ƒn Ä‘áº¿n tÃªn tá»« khÃ³a. Náº¿u báº¡n khÃ´ng chá»‰ Ä‘á»‹nh tÃªn, TensorFlow sáº½ sá»­ dá»¥ng sÆ¡ Ä‘á»“ Ä‘áº·t tÃªn máº·c Ä‘á»‹nh.

```python
a = tf.Variable(tf.zeros([5]),name='b')
```

á» Ä‘Ã¢y, biá»ƒu Ä‘á»“ tensorflow sáº½ biáº¿t biáº¿n nÃ y báº±ng tÃªn b chá»© khÃ´ng pháº£i a

### <font color = 'green'> Äá»‹nh nghÄ©a Ä‘áº§u ra trong Tensorflow

Äáº§u ra tenorflow thÆ°á»ng lÃ  tensor vÃ  káº¿t quáº£ cá»§a viá»‡c chuyá»ƒn Ä‘á»•i thÃ nh Ä‘áº§u vÃ o hoáº·c má»™t biáº¿n hoáº·c cáº£ hai. Trong vÃ­ dá»¥ cá»§a chÃºng ta, h lÃ  Ä‘áº§u ra, trong Ä‘Ã³ h = tf.nn.sigmoid (tf.matmul (x, w) + b). CÅ©ng cÃ³ thá»ƒ cung cáº¥p cÃ¡c Ä‘áº§u ra nhÆ° váº­y cho cÃ¡c hoáº¡t Ä‘á»™ng khÃ¡c, táº¡o thÃ nh má»™t táº­p há»£p cÃ¡c hoáº¡t Ä‘á»™ng chuá»—i. HÆ¡n ná»¯a, khÃ´ng nháº¥t thiáº¿t pháº£i lÃ  hoáº¡t Ä‘á»™ng tensorflow. Báº¡n cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng sá»‘ há»c python tiÃªu chuáº©n vá»›i tensorflow. ÄÃ¢y lÃ  má»™t vÃ­ dá»¥:

```python
x = tf.matmul(w,A)
y = x + B
```

### <font color = 'green'> Äá»‹nh nghÄ©a operations trong TensorFlow

Má»™t hoáº¡t Ä‘á»™ng trong TensorFlow cÃ³ má»™t hoáº·c nhiá»u Ä‘áº§u vÃ o vÃ  táº¡o ra má»™t hoáº·c nhiá»u Ä‘áº§u ra. Náº¿u báº¡n xem API TensorFlow táº¡i https://www.tensorflow.org/api_docs/python/tf, báº¡n sáº½ tháº¥y TensorFlow cÃ³ má»™t bá»™ sÆ°u táº­p hoáº¡t Ä‘á»™ng lá»›n. á» Ä‘Ã¢y, chÃºng tÃ´i sáº½ xem xÃ©t má»™t vÃ i trong sá»‘ cÃ¡c hoáº¡t Ä‘á»™ng vÃ´ sá»‘ tenorflow.

#### <font color = 'pink'> Hoáº¡t Ä‘á»™ng so sÃ¡nh

Hoáº¡t Ä‘á»™ng so sÃ¡nh ráº¥t há»¯u Ã­ch Ä‘á»ƒ so sÃ¡nh hai tensor. VÃ­ dá»¥ mÃ£ sau Ä‘Ã¢y bao gá»“m má»™t vÃ i hoáº¡t Ä‘á»™ng so sÃ¡nh há»¯u Ã­ch.

```python
import tensorflow as tf
x = tf.constant([[1,2],[3,4]], dtype=tf.int32)
y = tf.constant([[4,3],[3,2]], dtype=tf.int32)

x_equal_y = tf.equal(x, y, name=None)

x_less_y = tf.less(x, y, name=None)

x_great_equal_y = tf.greater_equal(x, y, name=None)

condition = tf.constant([[True,False],[True,False]],dtype=tf.bool)

x_cond_y = tf.where(condition, x, y, name=None)
```

#### <font color='pink'> Hoáº¡t Ä‘á»™ng toÃ¡n há»c

TensorFlow cho phÃ©p báº¡n thá»±c hiá»‡n cÃ¡c thao tÃ¡c toÃ¡n há»c trÃªn cÃ¡c tenxÆ¡ tá»« Ä‘Æ¡n giáº£n Ä‘áº¿n phá»©c táº¡p. Bá»™ hoáº¡t Ä‘á»™ng hoÃ n chá»‰nh cÃ³ sáºµn táº¡i https://www.tensorflow.org/versions/r2.0/ api_docs/python/tf/math:

```python
x = tf.constant([[1,2],[3,4]], dtype=tf.float32)
y = tf.constant([[4,3],[3,2]], dtype=tf.float32)

x_add_y = tf.add(x, y)

x_mul_y = tf.matmul(x, y)

log_x = tf.log(x)

x_sum_1 = tf.reduce_sum(x, axis=[1], keepdims=False)

x_sum_2 = tf.reduce_sum(x, axis=[0], keepdims=True)

data = tf.constant([1,2,3,4,5,6,7,8,9,10], dtype=tf.float32)
segment_ids = tf.constant([0,0,0,1,1,2,2,2,2,2 ], dtype=tf.int32)

x_seg_sum = tf.segment_sum(data, segment_ids)
```

#### <font color = 'pink'> Cáº­p nháº­t giÃ¡ trá»‹ trong cÃ¡c tensor

Má»™t hoáº¡t Ä‘á»™ng phÃ¢n tÃ¡n (scatter operation), Ä‘á» cáº­p Ä‘áº¿n viá»‡c thay Ä‘á»•i cÃ¡c giÃ¡ trá»‹ táº¡i má»™t sá»‘ chá»‰ sá»‘ nháº¥t Ä‘á»‹nh cá»§a má»™t tensor, lÃ  ráº¥t phá»• biáº¿n trong cÃ¡c váº¥n Ä‘á» Ä‘iá»‡n toÃ¡n khoa há»c. Chá»©c nÄƒng nÃ y ban Ä‘áº§u Ä‘Æ°á»£c cung cáº¥p thÃ´ng qua hÃ m tf.scatter_nd() 

Tuy nhiÃªn, trong cÃ¡c phiÃªn báº£n TensorFlow gáº§n Ä‘Ã¢y, báº¡n cÃ³ thá»ƒ thá»±c hiá»‡n cÃ¡c hoáº¡t Ä‘á»™ng phÃ¢n tÃ¡n thÃ´ng qua láº­p chá»‰ má»¥c máº£ng vÃ  cáº¯t báº±ng cÃº phÃ¡p giá»‘ng nhÆ° Numpy. HÃ£y cÃ¹ng xem má»™t vÃ i vÃ­ dá»¥. Giáº£ sá»­ báº¡n cÃ³ TensorFlow biáº¿n V, lÃ  ma tráº­n [3,2]:

```python
v = tf.Variable(tf.constant([[1,9],[3,10],[5,11]],
dtype=tf.float32),name='ref')   
```

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i hÃ ng thá»© 0 cá»§a tenxÆ¡ nÃ y báº±ng:

```python
v[0].assign([-1, -9])
```

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i giÃ¡ trá»‹ táº¡i Index [1,1] báº±ng:

```python
v[1,1].assign(-10)
```

Báº¡n cÃ³ thá»ƒ thá»±c hiá»‡n cáº¯t hÃ ng vá»›i:

```python
v[1:,0].assign([-3,-5])
```

#### <font color = 'pink'> Thu tháº­p cÃ¡c giÃ¡ trá»‹ tá»« má»™t tenor

Má»™t hoáº¡t Ä‘á»™ng táº­p há»£p (gather operation) ráº¥t giá»‘ng vá»›i má»™t hoáº¡t Ä‘á»™ng phÃ¢n tÃ¡n. HÃ£y nhá»› ráº±ng phÃ¢n tÃ¡n lÃ  vá» viá»‡c gÃ¡n cÃ¡c giÃ¡ trá»‹ cho cÃ¡c tensor, trong khi viá»‡c thu tháº­p láº¥y cÃ¡c giÃ¡ trá»‹ cá»§a má»™t tensor. HÃ£y Ä‘á»ƒ hiá»ƒu Ä‘iá»u nÃ y thÃ´ng qua má»™t vÃ­ dá»¥. Giáº£ sá»­ báº¡n cÃ³ tenorflow tenor, T:

```python
t = tf.constant([[1,9],[3,10],[5,11]],dtype=tf.float32)
```

Báº¡n cÃ³ thá»ƒ cÃ³ Ä‘Æ°á»£c hÃ ng thá»© 0 cá»§a T vá»›i:

```python
t[0].numpy()
```

Báº¡n cÅ©ng cÃ³ thá»ƒ thá»±c hiá»‡n trÆ°á»£t hÃ ng (row-slicing) vá»›i:

```python
t[1:,0].numpy()
```

KhÃ´ng giá»‘ng nhÆ° hoáº¡t Ä‘á»™ng phÃ¢n tÃ¡n, hoáº¡t Ä‘á»™ng táº­p há»£p hoáº¡t Ä‘á»™ng cáº£ trÃªn cÃ¡c cáº¥u trÃºc TF.Varable vÃ  TF.Tensor.

## <font color = 'blue'> 4.Operation liÃªn quan Ä‘áº¿n máº¡ng tháº§n kinh

BÃ¢y giá», hÃ£y xem xÃ©t má»™t sá»‘ hoáº¡t Ä‘á»™ng liÃªn quan Ä‘áº¿n máº¡ng tháº§n kinh há»¯u Ã­ch mÃ  chÃºng ta sáº½ sá»­ dá»¥ng ráº¥t nhiá»u trong cÃ¡c chÆ°Æ¡ng sau. CÃ¡c hoáº¡t Ä‘á»™ng mÃ  chÃºng tÃ´i sáº½ tháº£o luáº­n á»Ÿ Ä‘Ã¢y bao gá»“m tá»« cÃ¡c biáº¿n Ä‘á»•i pháº§n tá»­ Ä‘Æ¡n giáº£n (nghÄ©a lÃ  kÃ­ch hoáº¡t) Ä‘áº¿n tÃ­nh toÃ¡n cÃ¡c dáº«n xuáº¥t má»™t pháº§n cá»§a má»™t táº­p há»£p cÃ¡c tham sá»‘ Ä‘á»‘i vá»›i giÃ¡ trá»‹ khÃ¡c. ChÃºng ta cÅ©ng sáº½ triá»ƒn khai má»™t máº¡ng lÆ°á»›i tháº§n kinh Ä‘Æ¡n giáº£n.

### <font color = 'green'> KÃ­ch hoáº¡t phi tuyáº¿n Ä‘Æ°á»£c sá»­ dá»¥ng bá»Ÿi cÃ¡c máº¡ng tháº§n kinh

KÃ­ch hoáº¡t phi tuyáº¿n cho phÃ©p cÃ¡c máº¡ng tháº§n kinh hoáº¡t Ä‘á»™ng tá»‘t á»Ÿ nhiá»u nhiá»‡m vá»¥. ThÃ´ng thÆ°á»ng, cÃ³ má»™t phÃ©p biáº¿n Ä‘á»•i kÃ­ch hoáº¡t phi tuyáº¿n (nghÄ©a lÃ  lá»›p kÃ­ch hoáº¡t) sau má»—i Ä‘áº§u ra lá»›p trong máº¡ng tháº§n kinh (ngoáº¡i trá»« lá»›p cuá»‘i cÃ¹ng). Má»™t phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n giÃºp má»™t máº¡ng lÆ°á»›i tháº§n kinh tÃ¬m hiá»ƒu cÃ¡c máº«u phi tuyáº¿n khÃ¡c nhau cÃ³ trong dá»¯ liá»‡u. Äiá»u nÃ y ráº¥t há»¯u Ã­ch cho cÃ¡c váº¥n Ä‘á» trong tháº¿ giá»›i thá»±c phá»©c táº¡p, trong Ä‘Ã³ dá»¯ liá»‡u thÆ°á»ng cÃ³ cÃ¡c máº«u phi tuyáº¿n phá»©c táº¡p hÆ¡n, trÃ¡i ngÆ°á»£c vá»›i cÃ¡c máº«u tuyáº¿n tÃ­nh. Náº¿u khÃ´ng dÃ nh cho cÃ¡c kÃ­ch hoáº¡t phi tuyáº¿n giá»¯a cÃ¡c lá»›p, má»™t máº¡ng lÆ°á»›i tháº§n kinh sÃ¢u sáº½ lÃ  má»™t loáº¡t cÃ¡c lá»›p tuyáº¿n tÃ­nh Ä‘Æ°á»£c xáº¿p chá»“ng lÃªn nhau. NgoÃ i ra, má»™t táº­p há»£p cÃ¡c lá»›p tuyáº¿n tÃ­nh vá» cÆ¡ báº£n cÃ³ thá»ƒ Ä‘Æ°á»£c nÃ©n vÃ o má»™t lá»›p tuyáº¿n tÃ­nh lá»›n hÆ¡n.

TÃ³m láº¡i, náº¿u khÃ´ng cho cÃ¡c kÃ­ch hoáº¡t phi tuyáº¿n, chÃºng ta khÃ´ng thá»ƒ táº¡o ra má»™t máº¡ng lÆ°á»›i tháº§n kinh vá»›i nhiá»u hÆ¡n má»™t lá»›p.

Táº§m quan trá»ng cá»§a viá»‡c kÃ­ch hoáº¡t phi tuyáº¿n thÃ´ng qua má»™t vÃ­ dá»¥. Äáº§u tiÃªn, hÃ£y nhá»› láº¡i viá»‡c tÃ­nh toÃ¡n cho cÃ¡c máº¡ng tháº§n kinh mÃ  chÃºng ta Ä‘Ã£ tháº¥y trong vÃ­ dá»¥ SigMoid.

```python
h = sigmoid(W*x)
```

Giáº£ sá»­ má»™t máº¡ng lÆ°á»›i tháº§n kinh ba lá»›p (cÃ³ W1, W2 vÃ  W3 lÃ m trá»ng sá»‘ lá»›p) trong Ä‘Ã³ má»—i lá»›p thá»±c hiá»‡n tÃ­nh toÃ¡n trÆ°á»›c Ä‘Ã³; ChÃºng ta cÃ³ thá»ƒ tÃ³m táº¯t tÃ­nh toÃ¡n Ä‘áº§y Ä‘á»§ nhÆ° sau

```python
h = sigmoid(W3*sigmoid(W2*sigmoid(W1*x)))
```

Tuy nhiÃªn, náº¿u chÃºng ta loáº¡i bá» kÃ­ch hoáº¡t phi tuyáº¿n (nghÄ©a lÃ  sigmoid), chÃºng ta sáº½ nháº­n Ä‘Æ°á»£c Ä‘iá»u nÃ y:

```python
h = (W3 * (W2 * (W1 *x))) = (W3*W2*W1)*x
```

VÃ¬ váº­y, khÃ´ng cÃ³ kÃ­ch hoáº¡t phi tuyáº¿n, ba lá»›p cÃ³ thá»ƒ Ä‘Æ°á»£c Ä‘Æ°a xuá»‘ng má»™t lá»›p tuyáº¿n tÃ­nh duy nháº¥t

BÃ¢y giá» chÃºng tÃ´i sáº½ liá»‡t kÃª hai kÃ­ch hoáº¡t phi tuyáº¿n ( nonlinear activations) thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c máº¡ng tháº§n kinh (nÃ³i cÃ¡ch khÃ¡c lÃ  SigMoid vÃ  Relu) vÃ  cÃ¡ch chÃºng cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n trong TensorFlow

```python
# Sigmoid : 1 / (1 + exp(-x))
tf.nn.sigmoid(x,name=None)
# ReLU activation : max(0,x)
tf.nn.relu(x, name=None)
```

![](/assets/img/NLP8.png)
  
### <font color = 'green'> Convolution operation

Má»™t hoáº¡t Ä‘á»™ng tÃ­ch cháº­p lÃ  má»™t ká»¹ thuáº­t xá»­ lÃ½ tÃ­n hiá»‡u Ä‘Æ°á»£c sá»­ dá»¥ng rá»™ng rÃ£i. Äá»‘i vá»›i hÃ¬nh áº£nh, tÃ­ch cháº­p Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ra cÃ¡c hiá»‡u á»©ng khÃ¡c nhau (nhÆ° lÃ m má») hoáº·c trÃ­ch xuáº¥t cÃ¡c tÃ­nh nÄƒng (nhÆ° cÃ¡c cáº¡nh) tá»« má»™t hÃ¬nh áº£nh. Má»™t vÃ­ dá»¥ vá» phÃ¡t hiá»‡n cáº¡nh báº±ng cÃ¡ch sá»­ dá»¥ng tÃ­ch cháº­p Ä‘Æ°á»£c hiá»ƒn thá»‹ trong HÃ¬nh dÆ°á»›i. Äiá»u nÃ y Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch chuyá»ƒn má»™t bá»™ lá»c tÃ­ch cháº­p cá»§a hÃ¬nh áº£nh Ä‘á»ƒ táº¡o ra má»™t Ä‘áº§u ra khÃ¡c nhau á»Ÿ má»—i vá»‹ trÃ­. Cá»¥ thá»ƒ, táº¡i má»—i vá»‹ trÃ­, chÃºng tÃ´i thá»±c hiá»‡n phÃ©p nhÃ¢n pháº§n tá»­ cá»§a cÃ¡c pháº§n tá»­ trong bá»™ lá»c tÃ­ch cháº­p vá»›i báº£n vÃ¡ hÃ¬nh áº£nh (image patch) (cÃ¹ng kÃ­ch thÆ°á»›c vá»›i bá»™ lá»c tÃ­ch cháº­p) trÃ¹ng vá»›i bá»™ lá»c tÃ­ch cháº­p vÃ  láº¥y tá»•ng cá»§a phÃ©p nhÃ¢n
  
![](/assets/img/NLP9.png)
  
Sau Ä‘Ã¢y lÃ  viá»‡c thá»±c hiá»‡n hoáº¡t Ä‘á»™ng tÃ­ch cháº­p

```python
x = tf.constant(
 [[
 [[1],[2],[3],[4]],
 [[4],[3],[2],[1]],
 [[5],[6],[7],[8]],
 [[8],[7],[6],[5]]
 ]],
 dtype=tf.float32)
x_filter = tf.constant(
 [ [ [[0.5]],[[1]] ],
 [ [[0.5]],[[1]] ]
 ],
 dtype=tf.float32)
x_stride = [1,1,1,1]
x_padding = 'VALID'
x_conv = tf.nn.conv2d(
 input=x, filters=x_filter, strides=x_stride, padding=x_padding
)
```
  
Äá»‘i vá»›i hoáº¡t Ä‘á»™ng tf.nn.conv2d (...), TensorFlow yÃªu cáº§u Ä‘áº§u vÃ o, bá»™ lá»c vÃ  sáº£i bÆ°á»›c ( input, filters, and strides ) cÃ³ Ä‘á»‹nh dáº¡ng chÃ­nh xÃ¡c. BÃ¢y giá» chÃºng ta sáº½ Ä‘i qua tá»«ng Ä‘á»‘i sá»‘ trong tf.conv2d (Ä‘áº§u vÃ o, bá»™ lá»c, sáº£i chÃ¢n, Ä‘á»‡m) ((input, filters, strides, padding)) chi tiáº¿t hÆ¡n:

Input : ÄÃ¢y thÆ°á»ng lÃ  má»™t tenxÆ¡ 4D trong Ä‘Ã³ cÃ¡c kÃ­ch thÆ°á»›c nÃªn Ä‘Æ°á»£c Ä‘áº·t dÆ°á»›i dáº¡ng [batch_size, height, width, channels]:
- Batch_Size: ÄÃ¢y lÃ  lÆ°á»£ng dá»¯ liá»‡u (vÃ­ dá»¥: cÃ¡c Ä‘áº§u vÃ o nhÆ° hÃ¬nh áº£nh vÃ  tá»«) trong má»™t lÃ´ dá»¯ liá»‡u. ChÃºng ta thÆ°á»ng xá»­ lÃ½ dá»¯ liá»‡u theo lÃ´ vÃ¬ cÃ¡c bá»™ dá»¯ liá»‡u lá»›n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ há»c. á» má»™t bÆ°á»›c Ä‘Ã o táº¡o nháº¥t Ä‘á»‹nh, chÃºng ta láº¥y máº«u ngáº«u nhiÃªn má»™t lÃ´ dá»¯ liá»‡u nhá» Ä‘áº¡i diá»‡n cho bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§. VÃ  lÃ m Ä‘iá»u nÃ y cho nhiá»u bÆ°á»›c cho phÃ©p chÃºng ta xáº¥p xá»‰ bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ khÃ¡ tá»‘t. Tham sá»‘ Batch_Size nÃ y giá»‘ng nhÆ° tham sá»‘ chÃºng ta Ä‘Ã£ tháº£o luáº­n trong vÃ­ dá»¥ Ä‘Æ°á»ng á»‘ng Ä‘áº§u vÃ o TensorFlow.
- Height and width: ÄÃ¢y lÃ  chiá»u cao vÃ  chiá»u rá»™ng cá»§a Ä‘áº§u vÃ o
- Chanels: ÄÃ¢y lÃ  Ä‘á»™ sÃ¢u cá»§a Ä‘áº§u vÃ o (vÃ­ dá»¥: Ä‘á»‘i vá»›i hÃ¬nh áº£nh RGB, sá»‘ lÆ°á»£ng kÃªnh sáº½ lÃ  3 kÃªnh, má»™t kÃªnh cho má»—i mÃ u).

Bá»™ lá»c: ÄÃ¢y lÃ  má»™t tenxÆ¡ 4D Ä‘áº¡i diá»‡n cho cá»­a sá»• tÃ­ch cháº­p cá»§a hoáº¡t Ä‘á»™ng tÃ­ch cháº­p. KÃ­ch thÆ°á»›c bá»™ lá»c pháº£i lÃ  [height, width, in_channels, out_channels]:
- Height and width: ÄÃ¢y lÃ  chiá»u cao vÃ  chiá»u rá»™ng cá»§a bá»™ lá»c (thÆ°á»ng nhá» hÆ¡n so vá»›i Ä‘áº§u vÃ o)
- in_channels: ÄÃ¢y lÃ  sá»‘ lÆ°á»£ng kÃªnh Ä‘áº§u vÃ o cho lá»›p
- out_channels: ÄÃ¢y lÃ  sá»‘ lÆ°á»£ng kÃªnh Ä‘Æ°á»£c sáº£n xuáº¥t trong Ä‘áº§u ra cá»§a lá»›p

strides: ÄÃ¢y lÃ  danh sÃ¡ch vá»›i bá»‘n yáº¿u tá»‘, trong Ä‘Ã³ cÃ¡c pháº§n tá»­ lÃ  [batch_stride, height_stride, width_stride, channels_stride]. Äá»‘i sá»‘ Strides biá»ƒu thá»‹ cÃ³ bao nhiÃªu pháº§n tá»­ cáº§n bá» qua trong má»™t dá»‹ch chuyá»ƒn cá»§a cá»­a sá»• tÃ­ch cháº­p trÃªn Ä‘áº§u vÃ o. ThÃ´ng thÆ°á»ng, báº¡n khÃ´ng pháº£i lo láº¯ng vá» Batch_Stride vÃ  channels_stride. Náº¿u báº¡n khÃ´ng hoÃ n toÃ n hiá»ƒu strides (bÆ°á»›c tiáº¿n) lÃ  gÃ¬, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng giÃ¡ trá»‹ máº·c Ä‘á»‹nh lÃ  1.

Padding: ÄÃ¢y cÃ³ thá»ƒ lÃ  má»™t trong sá»‘ ['SAME', 'VALID']. NÃ³ quyáº¿t Ä‘á»‹nh lÃ m tháº¿ nÃ o Ä‘á»ƒ xá»­ lÃ½ hoáº¡t Ä‘á»™ng tÃ­ch cháº­p gáº§n ranh giá»›i cá»§a Ä‘áº§u vÃ o. CÃ¡c hoáº¡t Ä‘á»™ng há»£p lá»‡ (VALID) thá»±c hiá»‡n tÃ­ch cháº­p mÃ  khÃ´ng cáº§n Ä‘á»‡m (padding). Náº¿u chÃºng ta káº¿t há»£p má»™t Ä‘áº§u vÃ o cÃ³ Ä‘á»™ dÃ i n vá»›i má»™t cá»­a sá»• tÃ­ch cháº­p cÃ³ kÃ­ch thÆ°á»›c H, Ä‘iá»u nÃ y sáº½ dáº«n Ä‘áº¿n Ä‘áº§u ra cÃ³ kÃ­ch thÆ°á»›c (N-H+1 <N). Viá»‡c giáº£m kÃ­ch thÆ°á»›c Ä‘áº§u ra cÃ³ thá»ƒ háº¡n cháº¿ nghiÃªm trá»ng Ä‘á»™ sÃ¢u cá»§a máº¡ng lÆ°á»›i tháº§n kinh. SAME thÃªm cÃ¡c sá»‘ 0 Ä‘áº¿n ranh giá»›i sao cho Ä‘áº§u ra sáº½ cÃ³ cÃ¹ng chiá»u cao vÃ  chiá»u rá»™ng vá»›i Ä‘áº§u vÃ o.

Äá»ƒ hiá»ƒu rÃµ hÆ¡n vá» kÃ­ch thÆ°á»›c bá»™ lá»c, sáº£i chÃ¢n vÃ  Ä‘á»‡m (filter size, stride, and padding), tham kháº£o hÃ¬nh dÆ°á»›i

![](/assets/img/NLP10.png)

![](/assets/img/NLP11.png)

![](/assets/img/NLP12.png)

### <font color = 'green'> Pooling operation

Má»™t hoáº¡t Ä‘á»™ng gá»™p (pooling operation) hoáº¡t Ä‘á»™ng tÆ°Æ¡ng tá»± nhÆ° hoáº¡t Ä‘á»™ng tÃ­ch cháº­p, nhÆ°ng Ä‘áº§u ra cuá»‘i cÃ¹ng lÃ  khÃ¡c nhau. Thay vÃ¬ xuáº¥t tá»•ng sá»‘ nhÃ¢n cá»§a bá»™ lá»c vÃ  báº£n vÃ¡ hÃ¬nh áº£nh, giá» Ä‘Ã¢y chÃºng ta láº¥y pháº§n tá»­ tá»‘i Ä‘a cá»§a báº£n vÃ¡ hÃ¬nh áº£nh cho vá»‹ trÃ­ Ä‘Ã³.

```python
x = tf.constant(
 [[
 [[1],[2],[3],[4]],
 [[4],[3],[2],[1]],
 [[5],[6],[7],[8]],
 [[8],[7],[6],[5]]
 ]],
 dtype=tf.float32)
x_ksize = [1,2,2,1]
x_stride = [1,2,2,1]
x_padding = 'VALID'
x_pool = tf.nn.max_pool2d(
 input=x, ksize=x_ksize,
 strides=x_stride, padding=x_padding
)
# Returns (out) => [[[[ 4.],[ 4.]],[[ 8.],[ 8.]]]]
```
![](/assets/img/NLP13.png)
  
### <font color = 'green'> Äá»‹nh nghÄ©a máº¥t mÃ¡t

ChÃºng ta biáº¿t ráº±ng, Ä‘á»‘i vá»›i má»™t máº¡ng lÆ°á»›i tháº§n kinh Ä‘á»ƒ há»c má»™t cÃ¡i gÃ¬ Ä‘Ã³ há»¯u Ã­ch, má»™t máº¥t mÃ¡t cáº§n pháº£i Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh. Sá»± máº¥t mÃ¡t thá»ƒ hiá»‡n má»©c Ä‘á»™ gáº§n hoáº·c xa cÃ¡c dá»± Ä‘oÃ¡n tá»« cÃ¡c má»¥c tiÃªu thá»±c táº¿. CÃ³ má»™t sá»‘ chá»©c nÄƒng Ä‘á»ƒ tá»± Ä‘á»™ng tÃ­nh toÃ¡n tá»•n tháº¥t trong tensorflow, hai trong sá»‘ Ä‘Ã³ Ä‘Æ°á»£c hiá»ƒn thá»‹ trong mÃ£ sau. HÃ m tf.nn.l2_loss lÃ  máº¥t lá»—i bÃ¬nh phÆ°Æ¡ng trung bÃ¬nh (mean squared error loss) vÃ  tf.nn.softmax_cross_entropy_with_logits lÃ  má»™t loáº¡i tá»•n tháº¥t khÃ¡c thá»±c sá»± mang láº¡i hiá»‡u suáº¥t tá»‘t hÆ¡n trong cÃ¡c tÃ¡c vá»¥ phÃ¢n loáº¡i. 

```python
# Returns half of L2 norm of t given by sum(t**2)/2
x = tf.constant([[2,4],[6,8]],dtype=tf.float32)
x_hat = tf.constant([[1,2],[3,4]],dtype=tf.float32)
# MSE = (1**2 + 2**2 + 3**2 + 4**2)/2 = 15
MSE = tf.nn.l2_loss(x-x_hat)

y = tf.constant([[1,0],[0,1]],dtype=tf.float32)
y_hat = tf.constant([[3,1],[2,5]],dtype=tf.float32)

CE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_hat,labels=y))
```

## <font color = 'blue'> 5.Keras: API xÃ¢y dá»±ng mÃ´ hÃ¬nh cá»§a Tensorflow

Keras Ä‘Æ°á»£c phÃ¡t triá»ƒn nhÆ° má»™t thÆ° viá»‡n riÃªng biá»‡t cung cáº¥p cÃ¡c khá»‘i xÃ¢y dá»±ng cáº¥p cao Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh má»™t cÃ¡ch thuáº­n tiá»‡n. Ban Ä‘áº§u nÃ³ há»— trá»£ nhiá»u pháº§n má»m (vÃ­ dá»¥: Tensorflow vÃ  Theano). Tuy nhiÃªn, Tensorflow cÃ³ Ä‘Æ°á»£c Keras vÃ  bÃ¢y giá» lÃ  má»™t pháº§n khÃ´ng thá»ƒ thiáº¿u trong TensorFlow Ä‘á»ƒ xÃ¢y dá»±ng cÃ¡c mÃ´ hÃ¬nh má»™t cÃ¡ch dá»… dÃ ng.

Trá»ng tÃ¢m chÃ­nh cá»§a Keras lÃ  xÃ¢y dá»±ng mÃ´ hÃ¬nh. VÃ¬ váº­y, Keras cung cáº¥p má»™t sá»‘ API khÃ¡c nhau vá»›i má»©c Ä‘á»™ linh hoáº¡t vÃ  phá»©c táº¡p khÃ¡c nhau. Chá»n API phÃ¹ há»£p cho cÃ´ng viá»‡c sáº½ yÃªu cáº§u kiáº¿n thá»©c há»£p lÃ½ vá» cÃ¡c háº¡n cháº¿ cá»§a má»—i API cÅ©ng nhÆ° kinh nghiá»‡m. CÃ¡c API Ä‘Æ°á»£c cung cáº¥p bá»Ÿi Keras lÃ :

- API tuáº§n tá»± (Sequential API) : API dá»… sá»­ dá»¥ng nháº¥t. Trong API nÃ y, báº¡n chá»‰ cáº§n xáº¿p cÃ¡c lá»›p lÃªn nhau Ä‘á»ƒ táº¡o má»™t mÃ´ hÃ¬nh. 
- API chá»©c nÄƒng (Functional API) - API chá»©c nÄƒng cung cáº¥p tÃ­nh linh hoáº¡t hÆ¡n báº±ng cÃ¡ch cho phÃ©p báº¡n xÃ¡c Ä‘á»‹nh cÃ¡c mÃ´ hÃ¬nh tÃ¹y chá»‰nh cÃ³ thá»ƒ cÃ³ nhiá»u lá»›p Ä‘áº§u vÃ o/nhiá»u lá»›p Ä‘áº§u ra. 
- API lá»›p phá»¥ (Sub-classing API) : API lá»›p phá»¥ cho phÃ©p báº¡n xÃ¡c Ä‘á»‹nh cÃ¡c lá»›p/ mÃ´ hÃ¬nh cÃ³ thá»ƒ tÃ¡i sá»­ dá»¥ng tÃ¹y chá»‰nh lÃ  cÃ¡c lá»›p Python. ÄÃ¢y lÃ  API linh hoáº¡t nháº¥t, nhÆ°ng nÃ³ Ä‘Ã²i há»i sá»± quen thuá»™c máº¡nh máº½ vá»›i cÃ¡c hoáº¡t Ä‘á»™ng API vÃ  tensorflow thÃ´ Ä‘á»ƒ sá»­ dá»¥ng nÃ³ má»™t cÃ¡ch chÃ­nh xÃ¡c

Má»™t trong nhá»¯ng khÃ¡i niá»‡m báº©m sinh nháº¥t trong Keras lÃ  má»™t mÃ´ hÃ¬nh bao gá»“m má»™t hoáº·c nhiá»u lá»›p Ä‘Æ°á»£c káº¿t ná»‘i theo má»™t cÃ¡ch cá»¥ thá»ƒ. á» Ä‘Ã¢y, chÃºng ta sáº½ ngáº¯n gá»n vá» mÃ£ trÃ´ng nhÆ° tháº¿ nÃ o, sá»­ dá»¥ng cÃ¡c API khÃ¡c nhau Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh. Báº¡n khÃ´ng mong Ä‘á»£i hiá»ƒu Ä‘áº§y Ä‘á»§ mÃ£ dÆ°á»›i Ä‘Ã¢y. Thay vÃ o Ä‘Ã³, táº­p trung vÃ o kiá»ƒu mÃ£ Ä‘á»ƒ phÃ¡t hiá»‡n ra báº¥t ká»³ sá»± khÃ¡c biá»‡t nÃ o giá»¯a ba phÆ°Æ¡ng phÃ¡p
  
### <font color = 'green'> Sequential API

Khi sá»­ dá»¥ng API tuáº§n tá»±, báº¡n chá»‰ cáº§n xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh cá»§a mÃ¬nh lÃ  danh sÃ¡ch cÃ¡c lá»›p. á» Ä‘Ã¢y, pháº§n tá»­ Ä‘áº§u tiÃªn trong danh sÃ¡ch lÃ  gáº§n nháº¥t vá»›i Ä‘áº§u vÃ o, trong Ä‘Ã³ pháº§n cuá»‘i lÃ  lá»›p Ä‘áº§u ra:

```python
model = tf.keras.Sequential([
 tf.keras.layers.Dense(500, activation='relu', shape=(784, )),
 tf.keras.layers.Dense(250, activation='relu'),
 tf.keras.layers.Dense(10, activation='softmax')
 ])
```

Trong mÃ£ trÆ°á»›c, chÃºng tÃ´i cÃ³ ba lá»›p. Lá»›p Ä‘áº§u tiÃªn cÃ³ 500 nÃºt Ä‘áº§u ra vÃ  láº¥y má»™t vectÆ¡ gá»“m 784 pháº§n tá»­ lÃ m Ä‘áº§u vÃ o. Lá»›p thá»© hai Ä‘Æ°á»£c tá»± Ä‘á»™ng káº¿t ná»‘i vá»›i lá»›p thá»© nháº¥t, trong khi lá»›p cuá»‘i cÃ¹ng Ä‘Æ°á»£c káº¿t ná»‘i vá»›i lá»›p thá»© hai. Táº¥t cáº£ cÃ¡c lá»›p nÃ y lÃ  cÃ¡c lá»›p Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§, trong Ä‘Ã³ táº¥t cáº£ cÃ¡c nÃºt Ä‘áº§u vÃ o Ä‘Æ°á»£c káº¿t ná»‘i vá»›i táº¥t cáº£ cÃ¡c nÃºt Ä‘áº§u ra.

### <font color = 'green'> Functional API

Trong API chá»©c nÄƒng, chÃºng ta lÃ m má»i thá»© khÃ¡c nhau. TrÆ°á»›c tiÃªn chÃºng ta xÃ¡c Ä‘á»‹nh má»™t hoáº·c nhiá»u lá»›p Ä‘áº§u vÃ o vÃ  cÃ¡c lá»›p khÃ¡c mang tÃ­nh toÃ¡n. Sau Ä‘Ã³, chÃºng tÃ´i káº¿t ná»‘i cÃ¡c Ä‘áº§u vÃ o vá»›i Ä‘áº§u ra, nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong mÃ£ sau:

```python
inp = tf.keras.layers.Input(shape=(784,))
out_1 = tf.keras.layers.Dense(500, activation='relu')(inp)
out_2 = tf.keras.layers.Dense(250, activation='relu')(out_1)
out = tf.keras.layers.Dense(10, activation='softmax')(out_2)
model = tf.keras.models.Model(inputs=inp, outputs=out)
```

Trong mÃ£, chÃºng ta báº¯t Ä‘áº§u vá»›i má»™t lá»›p Ä‘áº§u vÃ o cháº¥p nháº­n vectÆ¡ dÃ i 784 pháº§n tá»­. Äáº§u vÃ o Ä‘Æ°á»£c truyá»n Ä‘áº¿n má»™t lá»›p dÃ y Ä‘áº·c cÃ³ 500 nÃºt. Äáº§u ra cá»§a lá»›p Ä‘Ã³ Ä‘Æ°á»£c gÃ¡n cho out_1. Sau Ä‘Ã³ out_1 Ä‘Æ°á»£c chuyá»ƒn cho má»™t lá»›p dÃ y Ä‘áº·c khÃ¡c, xuáº¥t ra out_2. Tiáº¿p theo, má»™t lá»›p dÃ y Ä‘áº·c vá»›i 10 nÃºt Ä‘áº§u ra Ä‘áº§u ra cuá»‘i cÃ¹ng. Cuá»‘i cÃ¹ng, mÃ´ hÃ¬nh Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  Ä‘á»‘i tÆ°á»£ng tf.keras.models.Model cÃ³ hai Ä‘á»‘i sá»‘:

- inputs - má»™t hoáº·c nhiá»u lá»›p Ä‘áº§u vÃ o  
- outputs - má»™t hoáº·c nhiá»u Ä‘áº§u ra Ä‘Æ°á»£c táº¡o bá»Ÿi báº¥t ká»³ tf.keras.layers loáº¡i Ä‘á»‘i tÆ°á»£ng

MÃ´ hÃ¬nh giá»‘ng há»‡t vá»›i nhá»¯ng gÃ¬ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trong pháº§n trÆ°á»›c. Má»™t trong nhá»¯ng lá»£i Ã­ch cá»§a API chá»©c nÄƒng lÃ  báº¡n cÃ³ thá»ƒ táº¡o cÃ¡c mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n nhiá»u vÃ¬ báº¡n khÃ´ng bá»‹ rÃ ng buá»™c Ä‘á»ƒ cÃ³ cÃ¡c lá»›p nhÆ° má»™t danh sÃ¡ch. VÃ¬ sá»± tá»± do nÃ y, báº¡n cÃ³ thá»ƒ cÃ³ nhiá»u Ä‘áº§u vÃ o káº¿t ná»‘i vá»›i nhiá»u lá»›p theo nhiá»u cÃ¡ch khÃ¡c nhau vÃ  cÃ³ kháº£ nÄƒng táº¡o ra nhiá»u Ä‘áº§u ra.



### <font color = 'green'> Sub-classing API

Cuá»‘i cÃ¹ng, chÃºng ta sáº½ sá»­ dá»¥ng API lá»›p phá»¥ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh. Vá»›i lá»›p phá»¥, báº¡n xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh cá»§a mÃ¬nh lÃ  má»™t Ä‘á»‘i tÆ°á»£ng Python káº¿ thá»«a tá»« Ä‘á»‘i tÆ°á»£ng cÆ¡ sá»Ÿ tf.keras.model. Khi sá»­ dá»¥ng lá»›p phá»¥, báº¡n cáº§n xÃ¡c Ä‘á»‹nh hai hÃ m quan trá»ng: __init __ (), sáº½ chá»‰ Ä‘á»‹nh báº¥t ká»³ tham sá»‘, lá»›p Ä‘áº·c biá»‡t nÃ o, vÃ  do Ä‘Ã³ cáº§n thiáº¿t Ä‘á»ƒ thá»±c hiá»‡n thÃ nh cÃ´ng cÃ¡c tÃ­nh toÃ¡n vÃ  hÃ m  call() xÃ¡c Ä‘á»‹nh cÃ¡c tÃ­nh toÃ¡n cáº§n pháº£i xáº£y ra trong mÃ´ hÃ¬nh:

```python
class MyModel(tf.keras.Model):
    def __init__(self, num_classes):
        super().__init__()
        self.hidden1_layer = tf.keras.layers.Dense(500, activation='relu')
        self.hidden2_layer = tf.keras.layers.Dense(250, activation='relu')
        self.final_layer = tf.keras.layers.Dense(num_classes,
        activation='softmax')
    def call(self, inputs):
        h = self.hidden1_layer(inputs)
        h = self.hidden2_layer(h)
        y = self.final_layer(h)
        return y


model = MyModel(num_classes=10)
```
  
á» Ä‘Ã¢y, báº¡n cÃ³ thá»ƒ tháº¥y ráº±ng mÃ´ hÃ¬nh cá»§a chÃºng ta cÃ³ ba lá»›p, giá»‘ng nhÆ° táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh trÆ°á»›c Ä‘Ã³ chÃºng ta Ä‘Ã£ xÃ¡c Ä‘á»‹nh. Tiáº¿p theo, hÃ m call() xÃ¡c Ä‘á»‹nh cÃ¡ch cÃ¡c lá»›p nÃ y káº¿t ná»‘i Ä‘á»ƒ táº¡o ra Ä‘áº§u ra cuá»‘i cÃ¹ng. API lá»›p phá»¥ Ä‘Æ°á»£c coi lÃ  khÃ³ khÄƒn nháº¥t Ä‘á»ƒ lÃ m chá»§, chá»§ yáº¿u lÃ  do sá»± tá»± do. Tuy nhiÃªn, pháº§n thÆ°á»Ÿng lÃ  ráº¥t lá»›n khi báº¡n tÃ¬m hiá»ƒu API vÃ¬ nÃ³ cho phÃ©p báº¡n xÃ¡c Ä‘á»‹nh cÃ¡c mÃ´ hÃ¬nh/lá»›p ráº¥t phá»©c táº¡p lÃ  cÃ¡c tÃ­nh toÃ¡n Ä‘Æ¡n vá»‹ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng láº¡i sau Ä‘Ã³. BÃ¢y giá» báº¡n Ä‘Ã£ hiá»ƒu cÃ¡ch má»—i API hoáº¡t Ä‘á»™ng, hÃ£y Ä‘á»ƒ thá»±c hiá»‡n má»™t máº¡ng lÆ°á»›i tháº§n kinh báº±ng cÃ¡ch sá»­ dá»¥ng Keras vÃ  Ä‘Ã o táº¡o nÃ³ trÃªn má»™t bá»™ dá»¯ liá»‡u.
 
## <font color = 'blue'> 6.Thá»±c hiá»‡n máº¡ng neural network Ä‘áº§u tiÃªn cá»§a chÃºng ta

Má»™t trong nhá»¯ng bÆ°á»›c Ä‘á»‡m Ä‘á»ƒ giá»›i thiá»‡u cÃ¡c máº¡ng tháº§n kinh lÃ  triá»ƒn khai má»™t máº¡ng lÆ°á»›i tháº§n kinh cÃ³ kháº£ nÄƒng phÃ¢n loáº¡i cÃ¡c chá»¯ sá»‘. Äá»‘i vá»›i nhiá»‡m vá»¥ nÃ y, chÃºng tÃ´i sáº½ sá»­ dá»¥ng bá»™ dá»¯ liá»‡u MNIST ná»•i tiáº¿ng Ä‘Æ°á»£c cung cáº¥p táº¡i http://yann.lecun.com/exdb/mnist/.

Báº¡n cÃ³ thá»ƒ cáº£m tháº¥y má»™t chÃºt hoÃ i nghi vá» viá»‡c chÃºng ta sá»­ dá»¥ng nhiá»‡m vá»¥ táº§m nhÃ¬n mÃ¡y tÃ­nh hÆ¡n lÃ  má»™t nhiá»‡m vá»¥ NLP. Tuy nhiÃªn, cÃ¡c nhiá»‡m vá»¥ táº§m nhÃ¬n cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n vá»›i Ã­t tiá»n xá»­ lÃ½ hÆ¡n vÃ  dá»… hiá»ƒu.

VÃ¬ Ä‘Ã¢y lÃ  cuá»™c gáº·p gá»¡ Ä‘áº§u tiÃªn cá»§a chÃºng ta vá»›i cÃ¡c máº¡ng tháº§n kinh, chÃºng ta sáº½ tháº¥y cÃ¡ch thá»±c hiá»‡n mÃ´ hÃ¬nh nÃ y báº±ng cÃ¡ch sá»­ dá»¥ng Keras. Keras lÃ  mÃ´ hÃ¬nh con cáº¥p cao cung cáº¥p má»™t lá»›p trá»«u tÆ°á»£ng qua tensorflow. Do Ä‘Ã³, báº¡n cÃ³ thá»ƒ triá»ƒn khai cÃ¡c máº¡ng tháº§n kinh vá»›i Ã­t ná»— lá»±c hÆ¡n vá»›i Keras hÆ¡n lÃ  sá»­ dá»¥ng cÃ¡c hoáº¡t Ä‘á»™ng thÃ´ cá»§a TensorFlow. 
  
### <font color = 'green'> Chuáº©n bá»‹ dá»¯ liá»‡u

Äáº§u tiÃªn, chÃºng ta cáº§n táº£i xuá»‘ng bá»™ dá»¯ liá»‡u. TensorFlow cung cáº¥p cÃ¡c chá»©c nÄƒng thuáº­n tiá»‡n Ä‘á»ƒ táº£i xuá»‘ng dá»¯ liá»‡u vÃ  MNIST lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c há»— trá»£ Ä‘Ã³. ChÃºng tÃ´i sáº½ thá»±c hiá»‡n bá»‘n bÆ°á»›c quan trá»ng trong quÃ¡ trÃ¬nh chuáº©n bá»‹ dá»¯ liá»‡u:

- Táº£i xuá»‘ng dá»¯ liá»‡u vÃ  lÆ°u trá»¯ nÃ³ dÆ°á»›i dáº¡ng cÃ¡c Ä‘á»‘i tÆ°á»£ng numpy.ndarray. 
- Äá»‹nh hÃ¬nh láº¡i cÃ¡c hÃ¬nh áº£nh Ä‘á»ƒ hÃ¬nh áº£nh thang Ä‘á»™ xÃ¡m 2D trong bá»™ dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c chuyá»ƒn Ä‘á»•i thÃ nh vectÆ¡ 1D. 
- TiÃªu chuáº©n hÃ³a cÃ¡c hÃ¬nh áº£nh cÃ³ trung bÃ¬nh khÃ´ng vÃ  Ä‘Æ¡n vá»‹ (zero-mean and unit-variance) (cÃ²n Ä‘Æ°á»£c gá»i lÃ  lÃ m tráº¯ng). 
- One-hot encoding nhÃ£n lá»›p sá»‘ nguyÃªn. MÃ£ hÃ³a má»™t láº§n Ä‘á» cáº­p Ä‘áº¿n quÃ¡ trÃ¬nh biá»ƒu diá»…n nhÃ£n lá»›p sá»‘ nguyÃªn dÆ°á»›i dáº¡ng vectÆ¡. VÃ­ dá»¥: náº¿u báº¡n cÃ³ 10 lá»›p vÃ  nhÃ£n lá»›p 3 (trong Ä‘Ã³ cÃ¡c nhÃ£n náº±m trong khoáº£ng tá»« 0-9), vectÆ¡ Ä‘Æ°á»£c mÃ£ hÃ³a má»™t láº§n nÃ³ng (One-hot encoding) cá»§a báº¡n sáº½ lÃ  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0 , 0].

MÃ£ sau Ä‘Ã¢y thá»±c hiá»‡n cÃ¡c chá»©c nÄƒng nÃ y cho chÃºng tÃ´i:

```python
os.makedirs('data', exist_ok=True)
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(
 path=os.path.join(os.getcwd(), 'data', 'mnist.npz')
)
# Reshaping x_train and x_test tensors so that each image is represented
# as a 1D vector
x_train = x_train.reshape(x_train.shape[0], -1)
x_test = x_test.reshape(x_test.shape[0], -1)
# Standardizing x_train and x_test tensors
x_train = ( 
    x_train - np.mean(x_train, axis=1, keepdims=True)
)/np.std(x_train, axis=1, keepdims=True)
x_test = ( 
    x_test - np.mean(x_test, axis=1, keepdims=True)
)/np.std(x_test, axis=1, keepdims=True)
# One hot encoding y_train and y_test
y_onehot_train = np.zeros((y_train.shape[0], num_labels),
dtype=np.float32)
y_onehot_train[np.arange(y_train.shape[0]), y_train] = 1.0
y_onehot_test = np.zeros((y_test.shape[0], num_labels), dtype=np.float32)
y_onehot_test[np.arange(y_test.shape[0]), y_test] = 1.0
```

Báº¡n cÃ³ thá»ƒ tháº¥y ráº±ng chÃºng ta Ä‘ang sá»­ dá»¥ng chá»©c nÄƒng tf.keras.datasets.mnist.load_data() do TensorFlow cung cáº¥p Ä‘á»ƒ táº£i xuá»‘ng dá»¯ liá»‡u Ä‘Ã o táº¡o vÃ  kiá»ƒm tra. Äiá»u nÃ y sáº½ cung cáº¥p bá»‘n tensors Ä‘áº§u ra

```python
- x_train - Má»™t tensor cÃ³ kÃ­ch thÆ°á»›c 60000 x 28 x 28 trong Ä‘Ã³ má»—i hÃ¬nh áº£nh lÃ  28 x 28
- y_train - Má»™t vectÆ¡ cÃ³ kÃ­ch thÆ°á»›c 60000, trong Ä‘Ã³ má»—i pháº§n tá»­ lÃ  má»™t nhÃ£n lá»›p tá»« 0-9 
- x_test - Tensor cÃ³ kÃ­ch thÆ°á»›c 10000 x 28 x 28 
- y_test - VectÆ¡ cÃ³ kÃ­ch thÆ°á»›c 10000
```

Khi dá»¯ liá»‡u Ä‘Æ°á»£c táº£i xuá»‘ng, chÃºng ta Ä‘á»‹nh hÃ¬nh láº¡i hÃ¬nh áº£nh cÃ³ kÃ­ch thÆ°á»›c 28 x 28 thÃ nh má»™t vectÆ¡ 1D. Äiá»u nÃ y lÃ  do chÃºng ta sáº½ triá»ƒn khai má»™t máº¡ng lÆ°á»›i tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§. CÃ¡c máº¡ng tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§ láº¥y má»™t vectÆ¡ 1D lÃ m Ä‘áº§u vÃ o. Do Ä‘Ã³, táº¥t cáº£ cÃ¡c pixel trong hÃ¬nh áº£nh sáº½ Ä‘Æ°á»£c sáº¯p xáº¿p nhÆ° má»™t chuá»—i cÃ¡c pixel Ä‘á»ƒ Ä‘Æ°a vÃ o mÃ´ hÃ¬nh. Cuá»‘i cÃ¹ng, náº¿u báº¡n nhÃ¬n vÃ o pháº¡m vi cá»§a cÃ¡c giÃ¡ trá»‹ cÃ³ trong cÃ¡c tensor X_Train vÃ  X_Test, chÃºng sáº½ náº±m trong pháº¡m vi 0-255 (pháº¡m vi thang Ä‘á»™ xÃ¡m Ä‘iá»ƒn hÃ¬nh). ChÃºng ta sáº½ Ä‘Æ°a cÃ¡c giÃ¡ trá»‹ nÃ y vÃ o pháº¡m vi phÆ°Æ¡ng sai Ä‘Æ¡n vá»‹ trung bÃ¬nh báº±ng khÃ´ng báº±ng cÃ¡ch trá»« trung bÃ¬nh cá»§a má»—i hÃ¬nh áº£nh vÃ  chia cho Ä‘á»™ lá»‡ch chuáº©n.
 
### <font color = 'green'> Triá»ƒn khai neural network vá»›i Keras

Máº¡ng tháº§n kinh Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§ vá»›i 3 lá»›p cÃ³ 500, 250 vÃ  10 nÃºt tÆ°Æ¡ng á»©ng. Hai lá»›p Ä‘áº§u tiÃªn sáº½ sá»­ dá»¥ng kÃ­ch hoáº¡t Relu, trong khi lá»›p cuá»‘i cÃ¹ng sá»­ dá»¥ng SoftMax. Äá»ƒ thá»±c hiá»‡n Ä‘iá»u nÃ y, chÃºng tÃ´i sáº½ sá»­ dá»¥ng cÃ¡c API KERAS Ä‘Æ¡n giáº£n nháº¥t cÃ³ sáºµn cho chÃºng ta - API tuáº§n tá»±.

```python
model = tf.keras.Sequential([
 tf.keras.layers.Dense(500, activation='relu'),
 tf.keras.layers.Dense(250, activation='relu'),
 tf.keras.layers.Dense(10, activation='softmax')
 ])
```

Báº¡n cÃ³ thá»ƒ tháº¥y ráº±ng táº¥t cáº£ nhá»¯ng gÃ¬ nÃ³ cáº§n lÃ  má»™t dÃ²ng duy nháº¥t trong API tuáº§n tá»± Keras Ä‘á»ƒ xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh mÃ  chÃºng ta vá»«a xÃ¡c Ä‘á»‹nh. Keras cung cáº¥p nhiá»u loáº¡i lá»›p khÃ¡c nhau. Báº¡n cÃ³ thá»ƒ tháº¥y danh sÃ¡ch Ä‘áº§y Ä‘á»§ cÃ¡c lá»›p cÃ³ sáºµn cho báº¡n táº¡i https://www.tensorflow.org/api_docs/python/tf/keras/layers. Äá»‘i vá»›i má»™t máº¡ng Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§, chÃºng ta chá»‰ cáº§n cÃ¡c lá»›p dÃ y Ä‘áº·c báº¯t chÆ°á»›c cÃ¡c tÃ­nh toÃ¡n cá»§a má»™t lá»›p áº©n trong má»™t máº¡ng Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§. Vá»›i mÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh, báº¡n cáº§n biÃªn dá»‹ch mÃ´ hÃ¬nh nÃ y vá»›i chá»©c nÄƒng tá»•n tháº¥t phÃ¹ há»£p, trÃ¬nh tá»‘i Æ°u hÃ³a vÃ  hiá»‡u suáº¥t:

```python
optimizer = tf.keras.optimizers.RMSprop()
loss_fn = tf.keras.losses.CategoricalCrossentropy()
model.compile(optimizer=optimizer, loss=loss_fn, metrics=['acc'])
```

Vá»›i mÃ´ hÃ¬nh Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh vÃ  biÃªn dá»‹ch, giá» Ä‘Ã¢y chÃºng ta cÃ³ thá»ƒ Ä‘Ã o táº¡o mÃ´ hÃ¬nh cá»§a mÃ¬nh trÃªn dá»¯ liá»‡u Ä‘Ã£ chuáº©n bá»‹.

#### <font color = 'pink'> Training the model

ÄÃ o táº¡o má»™t mÃ´ hÃ¬nh khÃ´ng thá»ƒ dá»… dÃ ng hÆ¡n vá»›i Keras. Khi dá»¯ liá»‡u Ä‘Æ°á»£c chuáº©n bá»‹, táº¥t cáº£ nhá»¯ng gÃ¬ báº¡n cáº§n lÃ m lÃ  gá»i hÃ m model.fit () vá»›i cÃ¡c Ä‘á»‘i sá»‘ cáº§n thiáº¿t:

```python
batch_size = 100
num_epochs = 10
train_history = model.fit(
 x=x_train,
 y=y_onehot_train,
 batch_size=batch_size,
 epochs= num_epochs,
 validation_split=0.2
)
```
  
model.fit () cháº¥p nháº­n má»™t sá»‘ Ä‘á»‘i sá»‘ quan trá»ng. ChÃºng ta sáº½ Ä‘i qua chÃºng chi tiáº¿t hÆ¡n á»Ÿ Ä‘Ã¢y:

- X - Má»™t tenxÆ¡ Ä‘áº§u vÃ o. Trong trÆ°á»ng há»£p cá»§a chÃºng ta, Ä‘Ã¢y lÃ  má»™t tenxÆ¡ cÃ³ kÃ­ch thÆ°á»›c 60000 x 784.
- Y - NhÃ£n Ä‘Æ°á»£c mÃ£ hÃ³a má»™t láº§n nÃ³ng (one-hot encoded). Trong trÆ°á»ng há»£p cá»§a chÃºng ta, Ä‘Ã¢y lÃ  má»™t tenxÆ¡ cÃ³ kÃ­ch thÆ°á»›c 60000 x 10.
- batch_size - CÃ¡c mÃ´ hÃ¬nh há»c táº­p sÃ¢u Ä‘Æ°á»£c Ä‘Ã o táº¡o vá»›i cÃ¡c lÃ´ dá»¯ liá»‡u (nÃ³i cÃ¡ch khÃ¡c, má»™t cÃ¡ch ngáº«u nhiÃªn) trÃ¡i ngÆ°á»£c vá»›i viá»‡c cung cáº¥p cho bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ cÃ¹ng má»™t lÃºc. KÃ­ch thÆ°á»›c lÃ´ xÃ¡c Ä‘á»‹nh cÃ³ bao nhiÃªu vÃ­ dá»¥ Ä‘Æ°á»£c bao gá»“m trong má»™t lÃ´. KÃ­ch thÆ°á»›c lÃ´ cÃ ng lá»›n, Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh cá»§a báº¡n sáº½ cÃ ng tá»‘t.

- Epochs - CÃ¡c mÃ´ hÃ¬nh há»c táº­p sÃ¢u láº·p láº¡i thÃ´ng qua bá»™ dá»¯ liá»‡u theo cÃ¡c lÃ´ nhiá»u láº§n. Sá»‘ láº§n láº·p láº¡i thÃ´ng qua bá»™ dá»¯ liá»‡u Ä‘Æ°á»£c gá»i lÃ  sá»‘ lÆ°á»£ng ká»· nguyÃªn. Trong vÃ­ dá»¥ cá»§a chÃºng ta, Ä‘iá»u nÃ y Ä‘Æ°á»£c Ä‘áº·t thÃ nh 10.
- validation_split - Khi Ä‘Ã o táº¡o cÃ¡c mÃ´ hÃ¬nh há»c táº­p sÃ¢u, má»™t bá»™ xÃ¡c nháº­n Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ theo dÃµi hiá»‡u suáº¥t, trong Ä‘Ã³ bá»™ xÃ¡c thá»±c hoáº¡t Ä‘á»™ng nhÆ° má»™t proxy cho hiá»‡u suáº¥t trong tháº¿ giá»›i thá»±c. validation_split xÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng bá»™ dá»¯ liá»‡u Ä‘áº§y Ä‘á»§ sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng lÃ m táº­p há»£p con xÃ¡c thá»±c. Trong vÃ­ dá»¥ cá»§a chÃºng ta, Ä‘iá»u nÃ y Ä‘Æ°á»£c Ä‘áº·t thÃ nh 20% tá»•ng kÃ­ch thÆ°á»›c táº­p dá»¯ liá»‡u

á» Ä‘Ã¢y, nhá»¯ng gÃ¬ training loss vÃ  validation accuracy trÃ´ng giá»‘ng nhÆ° sá»‘ lÆ°á»£ng ká»· nguyÃªn mÃ  chÃºng ta Ä‘Ã£ Ä‘Ã o táº¡o mÃ´ hÃ¬nh

![](/assets/img/NLP14.png)

Tiáº¿p theo lÃ  kiá»ƒm tra mÃ´ hÃ¬nh cá»§a chÃºng tÃ´i trÃªn má»™t sá»‘ dá»¯ liá»‡u chÆ°a tá»«ng tháº¥y

#### <font color = 'pink'> Kiá»ƒm tra model

Kiá»ƒm tra mÃ´ hÃ¬nh cÅ©ng Ä‘Æ¡n giáº£n. Trong quÃ¡ trÃ¬nh thá»­ nghiá»‡m, chÃºng ta Ä‘o lÆ°á»ng sá»± máº¥t mÃ¡t vÃ  Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh trÃªn bá»™ dá»¯ liá»‡u thá»­ nghiá»‡m. Äá»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn bá»™ dá»¯ liá»‡u, cÃ¡c mÃ´ hÃ¬nh Keras cung cáº¥p chá»©c nÄƒng thuáº­n tiá»‡n gá»i lÃ  evaluate():

```python
test_res = model.evaluate(
    x=x_test,
    y=y_onehot_test,
    batch_size=batch_size
)
```

CÃ¡c Ä‘á»‘i sá»‘ Ä‘Æ°á»£c mong Ä‘á»£i bá»Ÿi hÃ m evaluate() Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» cáº­p trong quÃ¡ trÃ¬nh tháº£o luáº­n cá»§a chÃºng ta vá» model.fit ():

- X - má»™t tenxÆ¡ Ä‘áº§u vÃ o. Trong trÆ°á»ng há»£p cá»§a chÃºng ta, Ä‘Ã¢y lÃ  má»™t tenxÆ¡ cÃ³ kÃ­ch thÆ°á»›c 10000 x 784. 
- Y - NhÃ£n Ä‘Æ°á»£c mÃ£ hÃ³a má»™t láº§n nÃ³ng. Trong trÆ°á»ng há»£p cá»§a chÃºng ta, Ä‘Ã¢y lÃ  má»™t tensor kÃ­ch thÆ°á»›c 10000 x 10. 
- Batch_size - KÃ­ch thÆ°á»›c lÃ´ xÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng vÃ­ dá»¥ Ä‘Æ°á»£c bao gá»“m trong má»™t lÃ´. KÃ­ch thÆ°á»›c lÃ´ cÃ ng lá»›n thÃ¬ Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh cá»§a báº¡n sáº½ cÃ ng tá»‘t

Báº¡n sáº½ bá»‹ loss 0,138 vÃ  Ä‘á»™ chÃ­nh xÃ¡c lÃ  98%. Báº¡n sáº½ khÃ´ng nháº­n Ä‘Æ°á»£c cÃ¡c giÃ¡ trá»‹ chÃ­nh xÃ¡c giá»‘ng nhau do sá»± ngáº«u nhiÃªn khÃ¡c nhau trong mÃ´ hÃ¬nh, cÅ©ng nhÆ° trong quÃ¡ trÃ¬nh Ä‘Ã o táº¡o

# <font color = 'red'> III.Word2vec
  
## <font color = 'yellow'> 1.Giá»›i thiá»‡u

Word2vec lÃ  má»™t mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n vÃ  ná»•i tiáº¿ng giÃºp táº¡o ra cÃ¡c biá»ƒu diá»…n embedding cá»§a tá»« trong má»™t khÃ´ng gian cÃ³ sá»‘ chiá»u tháº¥p hÆ¡n nhiá»u láº§n so vá»›i sá»‘ tá»« trong tá»« Ä‘iá»ƒn.

Ã tÆ°á»Ÿng cÆ¡ báº£n cá»§a word2vec cÃ³ thá»ƒ Ä‘Æ°á»£c gÃ³i gá»n trong cÃ¡c Ã½ sau:

- Hai tá»« xuáº¥t hiá»‡n trong nhá»¯ng vÄƒn cáº£nh giá»‘ng nhau thÆ°á»ng cÃ³ Ã½ nghÄ©a gáº§n vá»›i nhau.

- Ta cÃ³ thá»ƒ Ä‘oÃ¡n Ä‘Æ°á»£c má»™t tá»« náº¿u biáº¿t cÃ¡c tá»« xung quanh nÃ³ trong cÃ¢u. VÃ­ dá»¥, vá»›i cÃ¢u â€œHÃ  Ná»™i lÃ  â€¦ cá»§a Viá»‡t Namâ€ thÃ¬ tá»« trong dáº¥u ba cháº¥m kháº£ nÄƒng cao lÃ  â€œthá»§ Ä‘Ã´â€. Vá»›i cÃ¢u hoÃ n chá»‰nh â€œHÃ  Ná»™i lÃ  thá»§ Ä‘Ã´ cá»§a Viá»‡t Namâ€, mÃ´ hÃ¬nh word2vec sáº½ xÃ¢y dá»±ng ra embeding cá»§a cÃ¡c tá»« sao cho xÃ¡c suáº¥t Ä‘á»ƒ tá»« trong dáº¥u ba cháº¥m lÃ  â€œthá»§ Ä‘Ã´â€ lÃ  cao nháº¥t.

## <font color = 'blue'> 2.Má»™t vÃ i Ä‘á»‹nh nghÄ©a

Trong vÃ­ dá»¥ trÃªn Ä‘Ã¢y, tá»« â€œthá»§ Ä‘Ã´â€ Ä‘ang Ä‘Æ°á»£c xÃ©t vÃ  Ä‘Æ°á»£c gá»i lÃ  target word hay tá»« Ä‘Ã­ch. Nhá»¯ng tá»« xung quanh nÃ³ Ä‘Æ°á»£c gá»i lÃ  context words hay tá»« ngá»¯ cáº£nh. Vá»›i má»—i tá»« Ä‘Ã­ch trong má»™t cÃ¢u cá»§a cÆ¡ sá»Ÿ dá»¯ liá»‡u, cÃ¡c tá»« ngá»¯ cáº£nh Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a lÃ  cÃ¡c tá»« trong cÃ¹ng cÃ¢u cÃ³ vá»‹ trÃ­ cÃ¡ch tá»« Ä‘Ã­ch má»™t khoáº£ng khÃ´ng quÃ¡ C/2 vá»›i C lÃ  má»™t sá»‘ tá»± nhiÃªn dÆ°Æ¡ng. NhÆ° váº­y, vá»›i má»—i tá»« Ä‘Ã­ch, ta sáº½ cÃ³ má»™t bá»™ khÃ´ng quÃ¡ C tá»« ngá»¯ cáº£nh.

XÃ©t vÃ­ dá»¥ sau Ä‘Ã¢y vá»›i cÃ¢u tiáº¿ng Anh: â€œThe quick brown fox jump over the lazy dogâ€ vá»›i C=4.

![](/assets/img/NLP15.png)

Khi â€œtheâ€ lÃ  tá»« Ä‘Ã­ch, ta cÃ³ cáº·p dá»¯ liá»‡u huáº¥n luyá»‡n lÃ  (the, quick) vÃ  (the, brown). Khi â€œbrownâ€ lÃ  tá»« Ä‘Ã­ch, ta cÃ³ cáº·p dá»¯ liá»‡u huáº¥n luyá»‡n lÃ  (brown, the), (brown, quick), (brown, fox) vÃ  (brown, jumps).

Word2vec Ä‘á»‹nh nghÄ©a hai embedding vector cÃ¹ng chiá»u cho má»—i tá»« w trong tá»« Ä‘iá»ƒn. Khi nÃ³ lÃ  má»™t tá»« Ä‘Ã­ch, embedding vector cá»§a nÃ³ lÃ  u; khi nÃ³ lÃ  má»™t tá»« ngá»¯ cáº£nh, embedding cá»§a nÃ³ lÃ  v. Sá»Ÿ dÄ© ta cáº§n hai embedding khÃ¡c nhau vÃ¬ Ã½ nghÄ©a cá»§a tá»« Ä‘Ã³ khi nÃ³ lÃ  tá»« Ä‘Ã­ch vÃ  tá»« ngá»¯ cáº£nh lÃ  khÃ¡c nhau. TÆ°Æ¡ng á»©ng vá»›i Ä‘Ã³, ta cÃ³ hai ma tráº­n embedding U vÃ  V cho cÃ¡c tá»« Ä‘Ã­ch vÃ  cÃ¡c tá»« ngá»¯ cáº£nh.

CÃ³ hai cÃ¡ch khÃ¡c nhau xÃ¢y dá»±ng mÃ´ hÃ¬nh word2vec:

- Skip-gram: Dá»± Ä‘oÃ¡n nhá»¯ng tá»« ngá»¯ cáº£nh náº¿u biáº¿t trÆ°á»›c tá»« Ä‘Ã­ch.

- CBOW (Continuous Bag of Words): Dá»±a vÃ o nhá»¯ng tá»« ngá»¯ cáº£nh Ä‘á»ƒ dá»± Ä‘oÃ¡n tá»« Ä‘Ã­ch.

Má»—i cÃ¡ch cÃ³ nhá»¯ng Æ°u nhÆ°á»£c Ä‘iá»ƒm khÃ¡c nhau vÃ  Ã¡p dá»¥ng vá»›i nhá»¯ng loáº¡i dá»¯ liá»‡u khÃ¡c nhau.

## <font color = 'blue'> 3.Skip-gram 

MÃ´ hÃ¬nh skip-gram liÃªn tá»¥c há»c báº±ng cÃ¡ch dá»± Ä‘oÃ¡n cÃ¡c tá»« xung quanh Ä‘Æ°á»£c Ä‘Æ°a ra má»™t tá»« hiá»‡n táº¡i. NÃ³i cÃ¡ch khÃ¡c, MÃ´ hÃ¬nh Skip-Gram liÃªn tá»¥c dá»± Ä‘oÃ¡n cÃ¡c tá»« trong má»™t pháº¡m vi nháº¥t Ä‘á»‹nh trÆ°á»›c vÃ  sau tá»« hiá»‡n táº¡i trong cÃ¹ng má»™t cÃ¢u.

skip-gram dá»± Ä‘oÃ¡n ngá»¯ cáº£nh hoáº·c cÃ¡c tá»« lÃ¢n cáº­n cho má»™t tá»« nháº¥t Ä‘á»‹nh. MÃ´ hÃ¬nh Skip-Gram Ä‘Æ°á»£c Ä‘Ã o táº¡o trÃªn cÃ¡c cáº·p n-gram (target_word, context_word) vá»›i mÃ£ thÃ´ng bÃ¡o lÃ  1 vÃ  0. MÃ£ thÃ´ng bÃ¡o chá»‰ Ä‘á»‹nh xem context_words Ä‘áº¿n tá»« cÃ¹ng má»™t cá»­a sá»• hay Ä‘Æ°á»£c táº¡o ngáº«u nhiÃªn. Cáº·p cÃ³ mÃ£ thÃ´ng bÃ¡o 0 bá»‹ bá» qua.

### <font color = 'green'> MÃ£ triá»ƒn khai mÃ´ hÃ¬nh Skip-Gram

CÃ¡c bÆ°á»›c cáº§n tuÃ¢n theo:

- XÃ¢y dá»±ng vá»‘n tá»« vá»±ng corpus
- XÃ¢y dá»±ng trÃ¬nh táº¡o skip-gram [(má»¥c tiÃªu, ngá»¯ cáº£nh), má»©c Ä‘á»™ liÃªn quan]
- XÃ¢y dá»±ng kiáº¿n trÃºc mÃ´ hÃ¬nh skip-gram
- ÄÃ o táº¡o mÃ´ hÃ¬nh
- Nháº­n nhÃºng Word
 
### <font color = 'green'> 1. XÃ¢y dá»±ng vá»‘n tá»« vá»±ng corpus:

BÆ°á»›c thiáº¿t yáº¿u trong khi xÃ¢y dá»±ng báº¥t ká»³ mÃ´ hÃ¬nh dá»±a trÃªn NLP nÃ o lÃ  táº¡o ra má»™t kho tÃ i liá»‡u trong Ä‘Ã³ chÃºng tÃ´i trÃ­ch xuáº¥t tá»«ng tá»« duy nháº¥t tá»« vá»±ng vÃ  gÃ¡n má»™t sá»‘ nháº­n dáº¡ng duy nháº¥t cho nÃ³.

Kho tÆ° liá»‡u chÃºng ta Ä‘ang sá»­ dá»¥ng lÃ  'The King James Version of the Bible', tá»« Dá»± Ã¡n Gutenberg, cÃ³ sáºµn miá»…n phÃ­ thÃ´ng qua mÃ´ hÃ¬nh corpus trong nltk.

```python
from nltk.corpus import gutenberg # to get bible corpus
from string import punctuation # to remove punctuation from corpus
import nltk 
import numpy as np
from keras.preprocessing import text
from keras.preprocessing.sequence import skipgrams 
from keras.layers import *
from keras.layers.core import Dense, Reshape
from keras.layers.embeddings import Embedding
from keras.models import Model,Sequential 
```
```python
nltk.download('gutenberg')
nltk.download('punkt')
nltk.download('stopwords')
# english lÃ  ngÃ´n ngá»¯ báº¡n chá»n
stop_words = nltk.corpus.stopwords.words('english')
```

*QuÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u sang má»™t thá»© mÃ  mÃ¡y tÃ­nh cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c gá»i lÃ  tiá»n xá»­ lÃ½. Má»™t trong nhá»¯ng hÃ¬nh thá»©c xá»­ lÃ½ trÆ°á»›c chÃ­nh lÃ  lá»c ra nhá»¯ng dá»¯ liá»‡u vÃ´ dá»¥ng. Trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn, nhá»¯ng tá»« vÃ´ Ã­ch (dá»¯ liá»‡u), Ä‘Æ°á»£c gá»i lÃ  nhá»¯ng tá»« dá»«ng(stop words). Tá»« dá»«ng lÃ  má»™t tá»« thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng (cháº³ng háº¡n nhÆ° â€œtheâ€, â€œaâ€, â€œanâ€, â€œinâ€) mÃ  cÃ´ng cá»¥ tÃ¬m kiáº¿m Ä‘Ã£ Ä‘Æ°á»£c láº­p trÃ¬nh Ä‘á»ƒ bá» qua.*

![](/assest/img/NLP16.png)
  
ChÃºng ta sá»­ dá»¥ng chá»©c nÄƒng do ngÆ°á»i dÃ¹ng xÃ¡c Ä‘á»‹nh Ä‘á»ƒ xá»­ lÃ½ sÆ¡ bá»™ vÄƒn báº£n giÃºp loáº¡i bá» cÃ¡c khoáº£ng tráº¯ng, chá»¯ sá»‘, tá»« dá»«ng vÃ  viáº¿t táº¯t thÃ¢n vÄƒn báº£n

```python
import re
bible = gutenberg.sents("bible-kjv.txt")
remove_terms = punctuation + '0123456789'
wpt = nltk.WordPunctTokenizer()
def normalize_document(doc):
    # lower case and remove special characters\whitespaces
    doc = re.sub(r'[^a-zA-Z\s]', '', doc,re.I|re.A)
    doc = doc.lower()
    doc = doc.strip()
    # tokenize document
    tokens = wpt.tokenize(doc)
    # filter stopwords out of document
    filtered_tokens = [token for token in tokens if token not in stop_words]
    # re-create document from filtered tokens
    doc = ' '.join(filtered_tokens)
    return doc
normalize_corpus = np.vectorize(normalize_document)
```
